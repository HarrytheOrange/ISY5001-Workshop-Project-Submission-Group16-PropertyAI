{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5924ee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Inference / Validation (Cleaned)\n",
    "#  - Neutral defaults & small utils\n",
    "#  - Budget-banded candidate retrieval\n",
    "#  - Feature computation (same as training, no masking)\n",
    "#  - Feature alignment to model columns\n",
    "#  - Optional location-sensitive re-ranking\n",
    "#  - Recommend & pretty-print\n",
    "# ============================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from joblib import load as joblib_load\n",
    "from typing import Optional, Dict, Union\n",
    "\n",
    "# ---- import the mapping funcs used at training time ----\n",
    "# from mappings import (\n",
    "#     budget_affinity_score, compute_match_scores_gaussian,\n",
    "#     compute_env_priority_scores, load_pa_similarity_matrix,\n",
    "#     pa_location_similarity_with_sensitivity\n",
    "# )\n",
    "\n",
    "# =========================================================\n",
    "# 0) Utils\n",
    "# =========================================================\n",
    "def _norm_text(x) -> Optional[str]:\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    return str(x).strip().upper()\n",
    "\n",
    "def gaussian_sim(user_val: float, item_val: float, sigma: float = 1.0) -> float:\n",
    "    \"\"\"Smooth 'closeness is better' similarity in [0,1].\"\"\"\n",
    "    u, v = float(user_val), float(item_val)\n",
    "    if sigma <= 0:\n",
    "        return 1.0 if np.isclose(u, v) else 0.0\n",
    "    d = u - v\n",
    "    return float(np.exp(-(d * d) / (2.0 * sigma * sigma)))\n",
    "\n",
    "def _clip_area(a: float, lo: float = 30.0, hi: float = 200.0) -> float:\n",
    "    \"\"\"Clamp area into the valid domain.\"\"\"\n",
    "    if pd.isna(a):\n",
    "        return np.nan\n",
    "    return float(np.clip(float(a), lo, hi))\n",
    "\n",
    "def gaussian_rel(delta: float, sigma: float) -> float:\n",
    "    \"\"\"Gaussian on a relative delta; returns score in [0,1].\"\"\"\n",
    "    if sigma <= 0:\n",
    "        return 1.0 if np.isclose(delta, 0.0) else 0.0\n",
    "    return float(np.exp(-(delta * delta) / (2.0 * sigma * sigma)))\n",
    "\n",
    "def norm_priority(priority_raw: float) -> float:\n",
    "    \"\"\"Map raw priority in [1,5] → [0,1].\"\"\"\n",
    "    if pd.isna(priority_raw):\n",
    "        return 0.5\n",
    "    return float(np.clip((float(priority_raw) - 1.0) / 4.0, 0.0, 1.0))\n",
    "\n",
    "def sat_count(x: float, alpha: float = 1.0) -> float:\n",
    "    \"\"\"Monotonic saturation in [0,1]: s=1-exp(-alpha*x).\"\"\"\n",
    "    if pd.isna(x) or x <= 0:\n",
    "        return 0.0\n",
    "    return float(1.0 - np.exp(-alpha * float(x)))\n",
    "\n",
    "def blend_with_priority(item_score: float, priority_raw: float, neutral: float = 0.5, contrast: float = 1.0) -> float:\n",
    "    \"\"\"\n",
    "    Make priority effect stronger:\n",
    "      - map item_score from [0,1] to [-1,1] by s' = 2*s - 1\n",
    "      - interpolate between neutral' (=0) and s' by p (0..1), then map back.\n",
    "      - contrast>1 slightly amplifies the effect.\n",
    "    \"\"\"\n",
    "    p = norm_priority(priority_raw)      # 0..1\n",
    "    s = float(np.clip(item_score, 0.0, 1.0))\n",
    "    s_ = (2*s - 1) * contrast            # [-contrast, +contrast]\n",
    "    out_ = p * s_                        # 0→neutral(0), 1→s_\n",
    "    out = (out_ / contrast + 1) / 2      # back to [0,1]\n",
    "    # 混一点点原本 neutral，避免极端：\n",
    "    return float(0.15 * neutral + 0.85 * out)\n",
    "\n",
    "# =========================================================\n",
    "# 1) Feature mappings — flat / floor / newhome (Gaussian)\n",
    "# =========================================================\n",
    "# ============================================\n",
    "# 2) storey_range ↔ Floor_Preference (Gaussian)\n",
    "#    HDB storey buckets expanded to 1..5 scale\n",
    "# ============================================\n",
    "\n",
    "_STOREY_TO_LEVEL = {\n",
    "    \"01 TO 03\": 1.0,\n",
    "    \"04 TO 06\": 1.2,\n",
    "    \"07 TO 09\": 1.5,\n",
    "    \"10 TO 12\": 1.7,\n",
    "    \"13 TO 15\": 2.0,\n",
    "    \"16 TO 18\": 2.4,\n",
    "    \"19 TO 21\": 2.8,\n",
    "    \"22 TO 24\": 3.0,\n",
    "    \"25 TO 27\": 3.3,\n",
    "    \"28 TO 30\": 3.7,\n",
    "    \"31 TO 33\": 4.0,\n",
    "    \"34 TO 36\": 4.0,\n",
    "    \"37 TO 39\": 4.5,\n",
    "    \"40 TO 42\": 4.5,\n",
    "    \"43 TO 45\": 5.0,\n",
    "    \"46 TO 48\": 5.0,\n",
    "    \"49 TO 51\": 5.0,\n",
    "    \"52 TO 54\": 5.0,\n",
    "    \"55 TO 57\": 5.0\n",
    "}\n",
    "\n",
    "# --- 相对高斯：越接近越好（仅保留 rel_sigma 一个参数） ---\n",
    "def score_area_closeness(user_area: float,\n",
    "                         item_area: float,\n",
    "                         rel_sigma: float = 0.12) -> float:\n",
    "    \"\"\"\n",
    "    Return a similarity in [0,1] using a relative Gaussian on percentage diff:\n",
    "        rel = (item - user) / user\n",
    "        sim = exp( - rel^2 / (2 * rel_sigma^2) )\n",
    "    仅一个超参数：rel_sigma（相对容差），默认 0.12 ≈ 12%。\n",
    "    \"\"\"\n",
    "    # ——最小清洗：转成数值并裁剪到[30,200]，避免字符串/越界导致NaN——\n",
    "    ua = pd.to_numeric(user_area, errors=\"coerce\")\n",
    "    ia = pd.to_numeric(item_area, errors=\"coerce\")\n",
    "    if not pd.isna(ua):\n",
    "        ua = float(np.clip(ua, 30.0, 200.0))\n",
    "    if not pd.isna(ia):\n",
    "        ia = float(np.clip(ia, 30.0, 200.0))\n",
    "\n",
    "    # === 临时调试：打印并“打断” ===\n",
    "    # print(f\"[DEBUG] area inputs -> user_area(ua)={ua}, item_area(ia)={ia}\")\n",
    "    # 方式A（推荐在notebook/脚本临时用）：打印后直接返回一个占位分数，观察输入是否为NaN\n",
    "    # return 0.5  # ← 调试完成后删掉这一行\n",
    "\n",
    "    # 方式B（强力中断）：打印后直接中止执行\n",
    "    #raise SystemExit(\"DEBUG BREAK after printing ua/ia\")\n",
    "\n",
    "    # ——正式计算——\n",
    "    if pd.isna(ua) or pd.isna(ia) or ua <= 0:\n",
    "        return 0.5  # 缺值兜底（这就是你之前看到全是0.5的触发条件）\n",
    "\n",
    "    rel = (ia - ua) / ua\n",
    "    if rel_sigma <= 0:\n",
    "        return 1.0 if np.isclose(rel, 0.0) else 0.0\n",
    "    return float(np.exp(-(rel * rel) / (2.0 * rel_sigma * rel_sigma)))\n",
    "\n",
    "def storey_to_level(storey_range: str, default_level: float = 2.0) -> float:\n",
    "    \"\"\"\n",
    "    Map textual 'storey_range' to a continuous level in {1..5}.\n",
    "    Unknown/missing values → default_level (mid-level = 2.5).\n",
    "    \"\"\"\n",
    "    key = _norm_text(storey_range)\n",
    "    if key in _STOREY_TO_LEVEL:\n",
    "        return _STOREY_TO_LEVEL[key]\n",
    "    # Try partial match (e.g. \"35 TO 37\" not in dict but similar)\n",
    "    if isinstance(key, str):\n",
    "        try:\n",
    "            low = int(key.split(\" TO \")[0])\n",
    "            if low <= 6: return 1.0\n",
    "            elif low <= 12: return 2.0\n",
    "            elif low <= 21: return 3.0\n",
    "            elif low <= 33: return 4.0\n",
    "            else: return 5.0\n",
    "        except Exception:\n",
    "            return default_level\n",
    "    return default_level\n",
    "\n",
    "def score_floor(user_floor_pref: float,\n",
    "                item_storey_range: str,\n",
    "                sigma: float = 1.2) -> float:\n",
    "    \"\"\"\n",
    "    Gaussian similarity between user's floor preference (1..5)\n",
    "    and property's level (1..5).\n",
    "    Slightly larger sigma to tolerate close floors.\n",
    "    Returns a value in [0, 1].\n",
    "    \"\"\"\n",
    "    item_level = storey_to_level(item_storey_range)\n",
    "    return gaussian_sim(user_floor_pref, item_level, sigma=sigma)\n",
    "\n",
    "def score_newhome(user_newhome_pref: float, sigma: float = 0.25) -> float:\n",
    "    \"\"\"\n",
    "    NewHome_Preference: 1=new, 0.5=neutral, 0=resale.\n",
    "    For HDB resale, item=0.0; neutral returns 1.0.\n",
    "    \"\"\"\n",
    "    if pd.isna(user_newhome_pref):\n",
    "        return 1.0\n",
    "    val = float(user_newhome_pref)\n",
    "    if np.isclose(val, 0.5):\n",
    "        return 1.0\n",
    "    return gaussian_sim(val, 0.0, sigma=sigma)\n",
    "\n",
    "def compute_match_scores_gaussian(user_row: dict | pd.Series,\n",
    "                                  item_row: dict | pd.Series,\n",
    "                                  sigmas: dict | None = None) -> dict:\n",
    "    \"\"\"Return sim_area, sim_floor, sim_newhome in [0,1]（接口保持原样）.\"\"\"\n",
    "    s = sigmas or {\"area\": 0.12, \"floor\": 1.0, \"newhome\": 0.25}\n",
    "\n",
    "    return {\n",
    "        # 注意：你说用户侧字段现在叫 Preferred_Flat_Area（若你改叫 floor_area_sqm，就把这里同步一下）\n",
    "        \"sim_area\":    score_area_closeness(user_row[\"Preferred_Flat_Area\"],\n",
    "                                            item_row[\"floor_area_sqm\"],\n",
    "                                            s[\"area\"]),\n",
    "        \"sim_floor\":   score_floor(user_row[\"Floor_Preference\"],\n",
    "                                   item_row[\"storey_range\"],\n",
    "                                   s[\"floor\"]),\n",
    "        \"sim_newhome\": score_newhome(user_row[\"NewHome_Preference\"],\n",
    "                                     s[\"newhome\"]),\n",
    "    }\n",
    "\n",
    "# =========================================================\n",
    "# 2) Feature mappings — facility accessibility environment (higher is better)\n",
    "# =========================================================\n",
    "def score_park_access(priority_park_access: float, pk_500m_in: float) -> float:\n",
    "    item_score = 1.0 if (not pd.isna(pk_500m_in) and pk_500m_in > 0) else 0.0\n",
    "    return blend_with_priority(item_score, priority_park_access, neutral=0.5)\n",
    "\n",
    "def score_bus_access(priority_bus_access: float, bus_200: float, bus_500: float,\n",
    "                     alpha_200: float = 0.8, alpha_500: float = 0.4) -> float:\n",
    "    s200 = sat_count(bus_200, alpha_200)\n",
    "    s500 = sat_count(bus_500, alpha_500)\n",
    "    item_score = float(np.clip((2.0/3.0)*s200 + (1.0/3.0)*s500, 0.0, 1.0))\n",
    "    return blend_with_priority(item_score, priority_bus_access, neutral=0.5)\n",
    "\n",
    "def score_mrt_access(priority_mrt_access: float, mrt_200: float, mrt_500: float,\n",
    "                     alpha_200: float = 2.0, alpha_500: float = 1.2) -> float:\n",
    "    s200 = sat_count(mrt_200, alpha_200)\n",
    "    s500 = sat_count(mrt_500, alpha_500)\n",
    "    item_score = float(np.clip((2.0/3.0)*s200 + (1.0/3.0)*s500, 0.0, 1.0))\n",
    "    return blend_with_priority(item_score, priority_mrt_access, neutral=0.5)\n",
    "\n",
    "def score_amenities(priority_amenities: float, hwkr_500m: float, mall_500m: float,\n",
    "                    alpha_hwkr: float = 0.7, alpha_mall: float = 0.6) -> float:\n",
    "    s_h = sat_count(hwkr_500m, alpha_hwkr)\n",
    "    s_m = sat_count(mall_500m, alpha_mall)\n",
    "    item_score = float(np.clip(0.25*s_h + 0.75*s_m, 0.0, 1.0))\n",
    "    return blend_with_priority(item_score, priority_amenities, neutral=0.5)\n",
    "\n",
    "def score_school_proximity(priority_school: float, gp_sch_1k: float, gp_sch_2k: float,\n",
    "                           alpha_1k: float = 0.9, alpha_2k: float = 0.5) -> float:\n",
    "    s1 = sat_count(gp_sch_1k, alpha_1k)\n",
    "    s2 = sat_count(gp_sch_2k, alpha_2k)\n",
    "    item_score = float(np.clip((2.0/3.0)*s1 + (1.0/3.0)*s2, 0.0, 1.0))\n",
    "    return blend_with_priority(item_score, priority_school, neutral=0.5)\n",
    "\n",
    "def compute_env_priority_scores(user_row: dict | pd.Series,\n",
    "                                item_row: dict | pd.Series,\n",
    "                                alphas: dict | None = None) -> dict:\n",
    "    \"\"\"\n",
    "    Safe version: all user priorities fetched via .get(..., np.nan),\n",
    "    so missing priorities are treated as neutral inside blend_with_priority().\n",
    "    \"\"\"\n",
    "    alphas = alphas or {\n",
    "        \"bus_200\": 0.8, \"bus_500\": 0.4,\n",
    "        \"mrt_200\": 2.0, \"mrt_500\": 1.2,\n",
    "        \"hwkr\": 0.7, \"mall\": 0.6,\n",
    "        \"sch_1k\": 0.9, \"sch_2k\": 0.5\n",
    "    }\n",
    "\n",
    "    # ---- safely get user priorities (missing -> NaN -> neutral 0.5) ----\n",
    "    p_park = user_row.get(\"Priority_Park_Access\", np.nan)\n",
    "    p_bus  = user_row.get(\"Priority_Bus_Access\", np.nan)\n",
    "    p_mrt  = user_row.get(\"Priority_MRT_Access\", np.nan)\n",
    "    p_am   = user_row.get(\"Priority_Amenities\", np.nan)\n",
    "    p_sch  = user_row.get(\"Priority_School_Proximity\", np.nan)\n",
    "\n",
    "    # ---- items (already .get with defaults) ----\n",
    "    s_park = score_park_access(\n",
    "        p_park,\n",
    "        item_row.get(\"PK_500M_IN\", 0)\n",
    "    )\n",
    "\n",
    "    s_bus = score_bus_access(\n",
    "        p_bus,\n",
    "        item_row.get(\"bus_200\", 0),\n",
    "        item_row.get(\"bus_500\", 0),\n",
    "        alpha_200=alphas[\"bus_200\"],\n",
    "        alpha_500=alphas[\"bus_500\"]\n",
    "    )\n",
    "\n",
    "    s_mrt = score_mrt_access(\n",
    "        p_mrt,\n",
    "        item_row.get(\"mrt_200\", 0),\n",
    "        item_row.get(\"mrt_500\", 0),\n",
    "        alpha_200=alphas[\"mrt_200\"],\n",
    "        alpha_500=alphas[\"mrt_500\"]\n",
    "    )\n",
    "\n",
    "    s_am = score_amenities(\n",
    "        p_am,\n",
    "        item_row.get(\"HWKR_500M\", 0),\n",
    "        item_row.get(\"MALL_500M\", 0),\n",
    "        alpha_hwkr=alphas[\"hwkr\"],\n",
    "        alpha_mall=alphas[\"mall\"]\n",
    "    )\n",
    "\n",
    "    s_sch = score_school_proximity(\n",
    "        p_sch,\n",
    "        item_row.get(\"GP_SCH_1K\", 0),\n",
    "        item_row.get(\"GP_SCH_2K\", 0),\n",
    "        alpha_1k=alphas[\"sch_1k\"],\n",
    "        alpha_2k=alphas[\"sch_2k\"]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"sim_park_access\": s_park,\n",
    "        \"sim_bus_access\":  s_bus,\n",
    "        \"sim_mrt_access\":  s_mrt,\n",
    "        \"sim_amenities\":   s_am,\n",
    "        \"sim_school\":      s_sch,\n",
    "    }\n",
    "\n",
    "# =========================================================\n",
    "# 3) Budget affinity (asymmetric Gaussian)\n",
    "# =========================================================\n",
    "def _asymmetric_gaussian(x: float, center: float, sigma_left: float, sigma_right: float) -> float:\n",
    "    dx = float(x) - float(center)\n",
    "    sigma = float(sigma_right if dx >= 0 else sigma_left)\n",
    "    if sigma <= 0:\n",
    "        return 1.0 if np.isclose(dx, 0.0) else 0.0\n",
    "    return float(np.exp(-(dx * dx) / (2.0 * sigma * sigma)))\n",
    "\n",
    "def budget_affinity_score(budget_sgd: float, resale_price: float, #always low a bit\n",
    "                          target_under: float = 0.01, # bis a little\n",
    "                          sigma_below: float = 0.08,\n",
    "                          sigma_above: float = 0.12,\n",
    "                          hard_clip: float = 0.60) -> float:\n",
    "    \"\"\"Smooth satisfaction between budget and price in [0,1].\"\"\"\n",
    "    if pd.isna(budget_sgd) or budget_sgd <= 0 or pd.isna(resale_price) or resale_price <= 0:\n",
    "        return 0.0\n",
    "    d = (float(resale_price) - float(budget_sgd)) / float(budget_sgd)\n",
    "    d = float(np.clip(d, -hard_clip, hard_clip))\n",
    "    center = -abs(float(target_under))\n",
    "    score = _asymmetric_gaussian(d, center, sigma_below, sigma_above)\n",
    "    return float(np.clip(score, 0.0, 1.0))\n",
    "\n",
    "# =========================================================\n",
    "# 4) Location similarity with sensitivity\n",
    "# =========================================================\n",
    "def _norm_place(x: Optional[Union[str, float]]) -> Optional[str]:\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "        return None\n",
    "    return str(x).strip().upper()\n",
    "\n",
    "def load_pa_similarity_matrix(path: str) -> pd.DataFrame:\n",
    "    if path.lower().endswith(\".csv\"):\n",
    "        df = pd.read_csv(path, index_col=0)\n",
    "    else:\n",
    "        df = pd.read_excel(path, index_col=0)\n",
    "    df.index = df.index.to_series().map(_norm_place)\n",
    "    df.columns = pd.Index([_norm_place(c) for c in df.columns])\n",
    "    common = df.index.intersection(df.columns)\n",
    "    df = df.loc[common, common].copy()\n",
    "    df = df.clip(0.0, 1.0)\n",
    "    df = 0.5 * (df + df.T)\n",
    "    np.fill_diagonal(df.values, 1.0)\n",
    "    return df\n",
    "\n",
    "def _temperature_blend(base_sim: float, sensitivity: float,\n",
    "                       neutral: float = 0.6, tau_low: float = 0.6, tau_high: float = 3.0) -> float:\n",
    "    p = float(np.clip(0.0 if sensitivity is None else sensitivity, 0.0, 1.0))\n",
    "    s = float(np.clip(0.0 if base_sim is None else base_sim, 0.0, 1.0))\n",
    "    tau = tau_low + (tau_high - tau_low) * p\n",
    "    s_temp = s ** tau\n",
    "    return float(np.clip((1.0 - p) * neutral + p * s_temp, 0.0, 1.0))\n",
    "\n",
    "def pa_location_similarity_with_sensitivity(\n",
    "    user_place: Optional[str],\n",
    "    item_place: Optional[str],\n",
    "    sim_df: pd.DataFrame,\n",
    "    distance_sensitivity: Optional[float],\n",
    "    alias_map_user: Optional[Dict[str, str]] = None,\n",
    "    alias_map_item: Optional[Dict[str, str]] = None,\n",
    "    default_when_missing: float = 0.0,\n",
    "    neutral: float = 0.6,\n",
    "    tau_low: float = 0.6,\n",
    "    tau_high: float = 3.0\n",
    ") -> float:\n",
    "    u = _norm_place(user_place)\n",
    "    v = _norm_place(item_place)\n",
    "    if alias_map_user and u is not None:\n",
    "        u = _norm_place(alias_map_user.get(u, u))\n",
    "    if alias_map_item and v is not None:\n",
    "        v = _norm_place(alias_map_item.get(v, v))\n",
    "    if u is None or v is None:\n",
    "        base = float(default_when_missing)\n",
    "    elif (u in sim_df.index) and (v in sim_df.columns):\n",
    "        base = float(np.clip(sim_df.loc[u, v], 0.0, 1.0))\n",
    "    else:\n",
    "        base = float(default_when_missing)\n",
    "    return _temperature_blend(base, distance_sensitivity, neutral, tau_low, tau_high)\n",
    "\n",
    "\n",
    "def _norm_place(x: Optional[Union[str, float]]) -> Optional[str]:\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "        return None\n",
    "    return str(x).strip().upper()\n",
    "\n",
    "def load_pa_similarity_matrix(path: str) -> pd.DataFrame:\n",
    "    if path.lower().endswith(\".csv\"):\n",
    "        df = pd.read_csv(path, index_col=0)\n",
    "    else:\n",
    "        df = pd.read_excel(path, index_col=0)\n",
    "    df.index = df.index.to_series().map(_norm_place)\n",
    "    df.columns = pd.Index([_norm_place(c) for c in df.columns])\n",
    "    common = df.index.intersection(df.columns)\n",
    "    df = df.loc[common, common].copy()\n",
    "    df = df.clip(0.0, 1.0)\n",
    "    df = 0.5 * (df + df.T)\n",
    "    np.fill_diagonal(df.values, 1.0)\n",
    "    return df\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 0) Small utilities\n",
    "# --------------------------------------------------------\n",
    "def _neutral_defaults() -> dict:\n",
    "    \"\"\"Neutral fallbacks when a feature is missing at inference.\"\"\"\n",
    "    return {\"sim_budget\": 0.8, \"sim_location\": 0.6, \"default\": 0.5}\n",
    "\n",
    "def _pick(row, *candidates, default=\"\"):\n",
    "    \"\"\"Pick the first present column from candidates.\"\"\"\n",
    "    for c in candidates:\n",
    "        if c in row and pd.notna(row[c]):\n",
    "            return row[c]\n",
    "    return default\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 1) Candidate retrieval (budget band ±20%)\n",
    "# --------------------------------------------------------\n",
    "def build_inference_candidates(items_df: pd.DataFrame,\n",
    "                               budget: float,\n",
    "                               k_candidates: int = 300,\n",
    "                               seed: int = 2025) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Retrieve k candidates within ±20% of budget; fallback to global sample.\n",
    "    \"\"\"\n",
    "    band = items_df[(items_df[\"resale_price\"] >= 0.80 * budget) &\n",
    "                    (items_df[\"resale_price\"] <= 1.20 * budget)]\n",
    "    if len(band) < k_candidates:\n",
    "        return items_df.sample(min(k_candidates, len(items_df)), random_state=seed)\n",
    "    return band.sample(k_candidates, random_state=seed)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 2) Feature computation (same sims as training; no masking)\n",
    "# --------------------------------------------------------\n",
    "def compute_features_for_user_items(user_row: pd.Series | dict,\n",
    "                                    items_df: pd.DataFrame,\n",
    "                                    sim_df_pa: pd.DataFrame,\n",
    "                                    item_place_col: str = \"Plan\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build the sim_* features on each (user, item) and keep rich item attributes\n",
    "    for explanation. No masking at inference.\n",
    "    \"\"\"\n",
    "    user = pd.Series(user_row) if not isinstance(user_row, pd.Series) else user_row\n",
    "    rows = []\n",
    "    neutr = _neutral_defaults()\n",
    "\n",
    "    for _, it in items_df.iterrows():\n",
    "        # --- sims used by model ---\n",
    "        feats = {}\n",
    "        feats[\"sim_budget\"] = budget_affinity_score(user.get(\"Budget_SGD\"), it[\"resale_price\"])\n",
    "        feats |= compute_match_scores_gaussian(user, it)     # sim_area, sim_floor, sim_newhome\n",
    "        feats |= compute_env_priority_scores(user, it)       # sim_park_access, sim_bus_access, sim_mrt_access, sim_amenities, sim_school\n",
    "        feats[\"sim_location\"] = pa_location_similarity_with_sensitivity(\n",
    "            user_place=user.get(\"Preferred_Place\", None),\n",
    "            item_place=it.get(item_place_col, None),\n",
    "            sim_df=sim_df_pa,\n",
    "            distance_sensitivity=user.get(\"Priority_Distance_Proximity\", None),\n",
    "            default_when_missing=0.0,\n",
    "            neutral=neutr[\"sim_location\"]\n",
    "        )\n",
    "\n",
    "        # --- carry item attributes for printing ---\n",
    "        block  = _pick(it, \"block\")\n",
    "        street = _pick(it, \"street_name\", \"street_nam\")\n",
    "        town   = _pick(it, \"town\")\n",
    "        pa     = _pick(it, item_place_col)\n",
    "        storey = _pick(it, \"storey_range\")\n",
    "        area   = _pick(it, \"floor_area_sqm\")\n",
    "        lease  = _pick(it, \"remaining_lease\", \"remaining_lease_mths\", \"remaining_lease_months\")\n",
    "\n",
    "        # nearby facility counts / flags\n",
    "        def _int(x): \n",
    "            return int(x) if pd.notna(x) else 0\n",
    "        rows.append({\n",
    "            \"item_id\": it.get(\"item_id\", it.get(\"id\", _)),\n",
    "            \"block\": block, \"street\": street, \"town\": town, \"pa\": pa,\n",
    "            \"storey_range\": storey,\n",
    "            \"floor_area_sqm\": area, \"remaining_lease\": lease,\n",
    "            \"resale_price\": it.get(\"resale_price\", np.nan),\n",
    "            \"mrt_200\": _int(it.get(\"mrt_200\", np.nan)),\n",
    "            \"mrt_500\": _int(it.get(\"mrt_500\", np.nan)),\n",
    "            \"bus_200\": _int(it.get(\"bus_200\", np.nan)),\n",
    "            \"bus_500\": _int(it.get(\"bus_500\", np.nan)),\n",
    "            \"MALL_500M\": _int(it.get(\"MALL_500M\", np.nan)),\n",
    "            \"HWKR_500M\": _int(it.get(\"HWKR_500M\", np.nan)),\n",
    "            \"HOSP_1K\": _int(it.get(\"HOSP_1K\", np.nan)),\n",
    "            \"GP_SCH_1K\": _int(it.get(\"GP_SCH_1K\", np.nan)),\n",
    "            \"GP_SCH_2K\": _int(it.get(\"GP_SCH_2K\", np.nan)),\n",
    "            \"PK_500M_IN\": _int(it.get(\"PK_500M_IN\", np.nan)),\n",
    "            # model features (no masking at inference)\n",
    "            **feats,\n",
    "            \"sim_budget_missing\": 0,\n",
    "            \"sim_location_missing\": 0,\n",
    "            \"sim_mrt_access_missing\": 0,\n",
    "            \"sim_bus_access_missing\": 0,\n",
    "            \"sim_amenities_missing\": 0,\n",
    "            \"sim_school_missing\": 0,\n",
    "            \"sim_area_missing\": 0,\n",
    "            \"sim_floor_missing\": 0,\n",
    "            \"sim_newhome_missing\": 0,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 3) Ensure feature alignment to model columns\n",
    "# --------------------------------------------------------\n",
    "def ensure_feature_alignment(df_feats: pd.DataFrame, feature_cols: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Guarantee df contains every model feature; fill sims with neutrals and flags with 0.\n",
    "    \"\"\"\n",
    "    neutr = _neutral_defaults()\n",
    "    for c in feature_cols:\n",
    "        if c not in df_feats.columns:\n",
    "            if c.endswith(\"_missing\"):\n",
    "                df_feats[c] = 0\n",
    "            elif c == \"sim_budget\":\n",
    "                df_feats[c] = neutr[\"sim_budget\"]\n",
    "            elif c == \"sim_location\":\n",
    "                df_feats[c] = neutr[\"sim_location\"]\n",
    "            else:\n",
    "                df_feats[c] = neutr[\"default\"]\n",
    "    return df_feats[feature_cols]\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 4) Optional: location-sensitive re-ranking (inference-time)\n",
    "# --------------------------------------------------------\n",
    "def rerank_with_location_sensitivity(df_scored: pd.DataFrame,\n",
    "                                     user_distance_sensitivity: float,\n",
    "                                     loc_col: str = \"sim_location\",\n",
    "                                     pred_col: str = \"score\",\n",
    "                                     out_col: str = \"score_final\",\n",
    "                                     hard_pref_place: str | None = None,\n",
    "                                     boost_threshold: float = 0.75,\n",
    "                                     boost_value: float = 0.05):\n",
    "    \"\"\"\n",
    "    Blend model score with location similarity:\n",
    "        score_final = (1 - alpha) * score + alpha * sim_location\n",
    "    where alpha grows with user sensitivity. Optionally boost near-preferred places.\n",
    "    \"\"\"\n",
    "    alpha = 0.3 + 0.5 * float(np.clip(user_distance_sensitivity or 0.0, 0.0, 1.0))\n",
    "    df = df_scored.copy()\n",
    "    df[out_col] = (1.0 - alpha) * df[pred_col] + alpha * df[loc_col]\n",
    "\n",
    "    if hard_pref_place is not None:\n",
    "        mask = df[loc_col] >= float(boost_threshold)\n",
    "        df.loc[mask, out_col] += float(boost_value)\n",
    "    return df.sort_values(out_col, ascending=False), alpha\n",
    "\n",
    "\n",
    "\n",
    "# ---------- Utility helpers ----------\n",
    "def _pick_metric(row: pd.Series, candidates: list[str]) -> float:\n",
    "    \"\"\"Try several possible column names; return the first valid float value.\"\"\"\n",
    "    for c in candidates:\n",
    "        if c in row and pd.notna(row[c]):\n",
    "            try:\n",
    "                return float(row[c])\n",
    "            except Exception:\n",
    "                pass\n",
    "    return np.nan\n",
    "\n",
    "def _should_block_top1(row: pd.Series,\n",
    "                       sim_threshold: float = 0.30,\n",
    "                       model_threshold: float = 1.0,\n",
    "                       na_counts_as_fail: bool = True) -> tuple[bool, dict]:\n",
    "    \"\"\"Return (should_block, value_dict).\"\"\"\n",
    "    budget = _pick_metric(row, [\"sim_budget\", \"budget\", \"budget_sim\"])\n",
    "    loc    = _pick_metric(row, [\"sim_location\", \"location\", \"loc\"])\n",
    "    area   = _pick_metric(row, [\"sim_area\", \"area\", \"area_sim\"])\n",
    "    model  = _pick_metric(row, [\"score\", \"Model\", \"model\", \"pred\", \"predict_score\"])\n",
    "\n",
    "    vals = {\"budget\": budget, \"loc\": loc, \"area\": area, \"model\": model}\n",
    "\n",
    "    if na_counts_as_fail and (np.isnan(model) or any(np.isnan(v) for v in [budget, loc, area])):\n",
    "        return True, vals\n",
    "\n",
    "    bad_sim   = any(v < sim_threshold for v in [budget, loc, area] if not np.isnan(v))\n",
    "    bad_model = (not np.isnan(model)) and (model < model_threshold)\n",
    "    return (bad_sim or bad_model), vals\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 5) Recommend & pretty-print\n",
    "# --------------------------------------------------------\n",
    "# ---------- Helper functions ----------\n",
    "def _pick_metric(row: pd.Series, candidates: list[str]) -> float:\n",
    "    \"\"\"Try multiple candidate column names and return the first valid float value.\"\"\"\n",
    "    for c in candidates:\n",
    "        if c in row and pd.notna(row[c]):\n",
    "            try:\n",
    "                return float(row[c])\n",
    "            except Exception:\n",
    "                pass\n",
    "    return np.nan\n",
    "\n",
    "def _should_block_top1(row: pd.Series,\n",
    "                       sim_threshold: float = 0.30,\n",
    "                       model_threshold: float = 1.0,\n",
    "                       na_counts_as_fail: bool = True) -> tuple[bool, dict]:\n",
    "    \"\"\"Check whether Top-1 should be blocked based on similarity and model thresholds.\"\"\"\n",
    "    budget = _pick_metric(row, [\"sim_budget\", \"budget\", \"budget_sim\"])\n",
    "    loc    = _pick_metric(row, [\"sim_location\", \"location\", \"loc\"])\n",
    "    area   = _pick_metric(row, [\"sim_area\", \"area\", \"area_sim\"])\n",
    "    model  = _pick_metric(row, [\"score\", \"Model\", \"model\", \"pred\", \"predict_score\"])\n",
    "    vals = {\"budget\": budget, \"loc\": loc, \"area\": area, \"model\": model}\n",
    "\n",
    "    # If NaNs exist, optionally count as failure\n",
    "    if na_counts_as_fail and (np.isnan(model) or any(np.isnan(v) for v in [budget, loc, area])):\n",
    "        return True, vals\n",
    "\n",
    "    bad_sim   = any(v < sim_threshold for v in [budget, loc, area] if not np.isnan(v))\n",
    "    bad_model = (not np.isnan(model)) and (model < model_threshold)\n",
    "    return (bad_sim or bad_model), vals\n",
    "\n",
    "\n",
    "# ---------- Main function ----------\n",
    "def recommend_for_user(model,\n",
    "                       feature_cols: list[str],\n",
    "                       user_input: dict,\n",
    "                       items_df: pd.DataFrame,\n",
    "                       sim_df_pa: pd.DataFrame,\n",
    "                       item_place_col: str = \"Plan\",\n",
    "                       topn: int = 5,\n",
    "                       k_candidates: int = 300,\n",
    "                       seed: int = 2025,\n",
    "                       use_location_rerank: bool = True,\n",
    "                       sim_threshold=0.4,\n",
    "                       model_threshold=1.0,\n",
    "                       warn_threshold: float = 0.30) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Full inference pipeline:\n",
    "      1. Retrieve candidate properties\n",
    "      2. Compute user-item features\n",
    "      3. Predict ranking scores\n",
    "      4. (Optional) location-sensitive re-ranking\n",
    "      5. Produce a structured JSON-like payload for LLMs (and print summary)\n",
    "    \"\"\"\n",
    "    # 1) Candidate retrieval\n",
    "    budget = float(user_input[\"Budget_SGD\"])\n",
    "    cand = build_inference_candidates(items_df, budget, k_candidates=k_candidates, seed=seed)\n",
    "\n",
    "    # 2) Feature computation\n",
    "    feats_df = compute_features_for_user_items(user_input, cand, sim_df_pa, item_place_col=item_place_col)\n",
    "\n",
    "    # 3) Model prediction\n",
    "    X = ensure_feature_alignment(feats_df.copy(), feature_cols)\n",
    "    feats_df[\"score\"] = model.predict(X)\n",
    "\n",
    "    # 4) Optional location re-ranking\n",
    "    if use_location_rerank:\n",
    "        user_p = float(user_input.get(\"Priority_Distance_Proximity\", 0.0))\n",
    "        pref_place = user_input.get(\"Preferred_Place\", None)\n",
    "        feats_df, alpha_used = rerank_with_location_sensitivity(\n",
    "            feats_df, user_distance_sensitivity=user_p,\n",
    "            loc_col=\"sim_location\", pred_col=\"score\", out_col=\"score_final\",\n",
    "            hard_pref_place=pref_place, boost_threshold=0.75, boost_value=0.05\n",
    "        )\n",
    "        rank_col = \"score_final\"\n",
    "    else:\n",
    "        alpha_used = None\n",
    "        rank_col = \"score\"\n",
    "\n",
    "    recs = feats_df.sort_values(rank_col, ascending=False).head(topn).copy()\n",
    "\n",
    "    # ---------- Construct base structured payload ----------\n",
    "    user_summary = {\n",
    "        k: user_input.get(k, None) for k in [\n",
    "            \"Budget_SGD\",\"Preferred_Flat_Area\",\"Preferred_Place\",\"Floor_Preference\",\"NewHome_Preference\",\n",
    "            \"Priority_MRT_Access\",\"Priority_Bus_Access\",\"Priority_Amenities\",\n",
    "            \"Priority_School_Proximity\",\"Priority_Park_Access\",\"Priority_Distance_Proximity\"\n",
    "        ]\n",
    "    }\n",
    "    result_payload = {\n",
    "        \"status\": None,\n",
    "        \"meta\": {\n",
    "            \"topn\": int(topn),\n",
    "            \"use_location_rerank\": bool(use_location_rerank),\n",
    "            \"location_alpha\": float(alpha_used) if alpha_used is not None else None,\n",
    "            \"thresholds\": {\n",
    "                \"block_sim_threshold\": float(sim_threshold),\n",
    "                \"block_model_threshold\": float(model_threshold),\n",
    "                \"warn_threshold\": float(warn_threshold),\n",
    "            },\n",
    "            \"user\": user_summary,\n",
    "        },\n",
    "        \"fail_reasons\": None,   # Explanation if blocked or no result\n",
    "        \"items\": []        # Structured property results\n",
    "    }\n",
    "\n",
    "    # ---------- Step 1: No candidates ----------\n",
    "    if recs.empty:\n",
    "        result_payload[\"status\"] = \"no_result\"\n",
    "        result_payload[\"fail_reasons\"] = {\n",
    "            \"type\": \"no_candidates_after_rerank\",\n",
    "            \"message\": \"No suitable properties found under current preferences. Try increasing budget or relaxing filters.\"\n",
    "        }\n",
    "        print(json.dumps(result_payload, ensure_ascii=False, indent=2))\n",
    "        return recs\n",
    "\n",
    "    # ---------- Step 2: Top-1 fails quality threshold ----------\n",
    "    need_block, vals = _should_block_top1(recs.iloc[0],\n",
    "                                          sim_threshold=sim_threshold,\n",
    "                                          model_threshold=model_threshold)\n",
    "    if need_block:\n",
    "        result_payload[\"status\"] = \"blocked_top1\"\n",
    "        result_payload[\"reasons\"] = {\n",
    "            \"type\": \"top1_fails_quality_threshold\",\n",
    "            \"triggered_values\": {k: (None if np.isnan(v) else float(v)) for k, v in vals.items()},\n",
    "            \"required\": {\"sim_min\": float(sim_threshold), \"model_min\": float(model_threshold)},\n",
    "            \"message\": \"Top-1 fails quality threshold; consider increasing budget, expanding preferred location, or loosening size/type preference.\"\n",
    "        }\n",
    "        print(json.dumps(result_payload, ensure_ascii=False, indent=2))\n",
    "        return recs.head(0)\n",
    "\n",
    "    # ---------- Step 3: Build structured items ----------\n",
    "    def _safe_get(obj, name, default=None):\n",
    "        try:\n",
    "            v = getattr(obj, name)\n",
    "            return v if v is not None else default\n",
    "        except Exception:\n",
    "            return default\n",
    "\n",
    "    sim_fields = [\n",
    "        \"sim_budget\",\"sim_location\",\"sim_area\",\n",
    "        \"sim_mrt_access\",\"sim_bus_access\",\"sim_amenities\",\"sim_school\",\"sim_floor\",\"sim_newhome\"\n",
    "    ]\n",
    "\n",
    "    # Small helper to pack nearby-facilities info\n",
    "    nearby_pack = lambda r: {\n",
    "        \"mrt_200\": int(_safe_get(r, \"mrt_200\", 0) or 0),\n",
    "        \"mrt_500\": int(_safe_get(r, \"mrt_500\", 0) or 0),\n",
    "        \"bus_200\": int(_safe_get(r, \"bus_200\", 0) or 0),\n",
    "        \"bus_500\": int(_safe_get(r, \"bus_500\", 0) or 0),\n",
    "        \"hawker_500m\": int(_safe_get(r, \"HWKR_500M\", 0) or 0),\n",
    "        \"mall_500m\": int(_safe_get(r, \"MALL_500M\", 0) or 0),\n",
    "        \"school_1km\": int(_safe_get(r, \"GP_SCH_1K\", 0) or 0),\n",
    "        \"school_2km\": int(_safe_get(r, \"GP_SCH_2K\", 0) or 0),\n",
    "        \"park_500m_in\": int(_safe_get(r, \"PK_500M_IN\", 0) or 0),\n",
    "    }\n",
    "\n",
    "    items_struct = []\n",
    "    for i, r in enumerate(recs.itertuples(index=False), 1):\n",
    "        addr = \" \".join(str(x) for x in [_safe_get(r, \"block\", \"\"), _safe_get(r, \"street\", \"\")] if str(x))\n",
    "        loc  = _safe_get(r, \"pa\", \"\") or _safe_get(r, \"town\", \"\")\n",
    "\n",
    "        # Collect similarity scores\n",
    "        sims = {}\n",
    "        for s in sim_fields:\n",
    "            if s in recs.columns:\n",
    "                val = getattr(r, s, np.nan)\n",
    "                sims[s.replace(\"sim_\", \"\")] = None if pd.isna(val) else float(val)\n",
    "\n",
    "        base_score  = _safe_get(r, \"score\", np.nan)\n",
    "        final_score = _safe_get(r, rank_col, np.nan)\n",
    "\n",
    "        # Identify features below warn threshold\n",
    "        warn_keys = [\"mrt_access\", \"bus_access\", \"amenities\", \"school\", \"floor\"]\n",
    "        low_flags = [k for k in warn_keys if (k in sims and sims[k] is not None and sims[k] < float(warn_threshold))]\n",
    "\n",
    "        item_entry = {\n",
    "            \"rank\": i,\n",
    "            \"attributes\": {\n",
    "                \"address\": addr,\n",
    "                \"location\": loc,\n",
    "                \"flat_type\": _safe_get(r, \"flat_type\", \"\"),\n",
    "                \"storey_range\": _safe_get(r, \"storey_range\", \"\"),\n",
    "                \"floor_area_sqm\": _safe_get(r, \"floor_area_sqm\", None),\n",
    "                \"remaining_lease\": _safe_get(r, \"remaining_lease\", None),\n",
    "                \"resale_price\": None if pd.isna(_safe_get(r, \"resale_price\", np.nan)) else float(_safe_get(r, \"resale_price\", np.nan)),\n",
    "                \"nearby\": nearby_pack(r),\n",
    "            },\n",
    "            \"scores\": {\n",
    "                \"model\": None if pd.isna(base_score) else float(base_score),\n",
    "                \"final\": None if pd.isna(final_score) else float(final_score),\n",
    "                \"loc\": None if pd.isna(_safe_get(r, \"sim_location\", np.nan)) else float(_safe_get(r, \"sim_location\", np.nan)),\n",
    "                \"sims\": sims,\n",
    "                \"low_flags\": low_flags,  # which features fall below warn_threshold\n",
    "            }\n",
    "        }\n",
    "        items_struct.append(item_entry)\n",
    "\n",
    "    result_payload[\"status\"] = \"ok\"\n",
    "    result_payload[\"items\"] = items_struct\n",
    "\n",
    "\n",
    "    lines = []\n",
    "    # lines.append(\"\\n=== Human-readable preview ===\")\n",
    "    lines.append(\n",
    "        f\"User: budget={user_summary.get('Budget_SGD')}, \"\n",
    "        f\"place={user_summary.get('Preferred_Place')}, \"\n",
    "        f\"flat_type={user_summary.get('Preferred_Room_Num')}, \"\n",
    "        f\"floor_pref={user_summary.get('Floor_Preference')}, \"\n",
    "        f\"newhome_pref={user_summary.get('NewHome_Preference')}\"\n",
    "    )\n",
    "    if use_location_rerank:\n",
    "        lines.append(f\"Location alpha: {alpha_used:.2f}\")\n",
    "    lines.append(f\"TOP-{topn} recommendations\")\n",
    "\n",
    "    for item in items_struct:\n",
    "        a, s = item[\"attributes\"], item[\"scores\"]\n",
    "        lines.append(f\"\\n#{item['rank']} | {a['address']} [{a['location']}]\")\n",
    "        lines.append(f\"   Type/Floor: {a['flat_type']} / {a['storey_range']}\")\n",
    "\n",
    "        resale_price = a.get(\"resale_price\")\n",
    "        resale_price_str = f\"${resale_price:,.0f}\" if resale_price else \"$0\"\n",
    "\n",
    "        lines.append(\n",
    "            f\"   Price: {resale_price_str} | \"\n",
    "            f\"Model: {s.get('model', 0):.4f} | \"\n",
    "            f\"Loc: {0 if s.get('loc') is None else s['loc']:.2f} | \"\n",
    "            f\"Final: {s.get('final', 0):.4f}\"\n",
    "        )\n",
    "\n",
    "        # Similarity evaluations\n",
    "        eval_keys = [\"mrt_access\", \"bus_access\", \"amenities\", \"school\", \"floor\"]\n",
    "        eval_pairs = []\n",
    "        for k in eval_keys:\n",
    "            val = s[\"sims\"].get(k)\n",
    "            if val is None:\n",
    "                eval_pairs.append(f\"{k}: NA\")\n",
    "            else:\n",
    "                eval_pairs.append(f\"{k}: {val:.2f}\")\n",
    "        lines.append(\"   match eval → \" + \" | \".join(eval_pairs))\n",
    "\n",
    "        if s.get(\"low_flags\"):\n",
    "            lines.append(\n",
    "                f\"   ⚠ unmet features (sim<{warn_threshold:.2f}): \"\n",
    "                + \", \".join(s[\"low_flags\"])\n",
    "            )\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "    # ---------- Print structured payload and human-readable preview ----------\n",
    "    # print(json.dumps(result_payload, ensure_ascii=False, indent=2))\n",
    "\n",
    "    print(\"\\n=== Human-readable preview ===\")\n",
    "    print(f\"User: budget={user_summary['Budget_SGD']}, place={user_summary['Preferred_Place']}, \"\n",
    "          f\"area={user_summary['Preferred_Flat_Area']}, floor_pref={user_summary['Floor_Preference']}, \"\n",
    "          f\"newhome_pref={user_summary['NewHome_Preference']}\")\n",
    "    if use_location_rerank:\n",
    "        print(f\"location alpha: {alpha_used:.2f}\")\n",
    "    print(f\"TOP-{topn} recommendations\")\n",
    "\n",
    "    for item in items_struct:\n",
    "        a, s = item[\"attributes\"], item[\"scores\"]\n",
    "        print(f\"\\n#{item['rank']} | {a['address']} [{a['location']}]\")\n",
    "        print(f\"   Type/Floor: {a['flat_type']} / {a['storey_range']}\")\n",
    "        if a[\"floor_area_sqm\"] or a[\"remaining_lease\"]:\n",
    "            print(f\"   Area: {a['floor_area_sqm']} sqm   Lease: {a['remaining_lease']}\")\n",
    "        print(f\"   Price: ${0 if a['resale_price'] is None else a['resale_price']:,.0f} | \"\n",
    "              f\"Model: {s['model']:.4f} | Loc: {0 if s['loc'] is None else s['loc']:.2f} | Final: {s['final']:.4f}\")\n",
    "\n",
    "        eval_keys = [\"mrt_access\",\"bus_access\",\"amenities\",\"school\",\"floor\"]\n",
    "        eval_pairs = []\n",
    "        for k in eval_keys:\n",
    "            val = s[\"sims\"].get(k)\n",
    "            if val is None:\n",
    "                eval_pairs.append(f\"{k}: NA\")\n",
    "            else:\n",
    "                eval_pairs.append(f\"{k}: {val:.2f}\")\n",
    "\n",
    "        print(\"   match eval → \" + \" | \".join(eval_pairs))\n",
    "        if s[\"low_flags\"]:\n",
    "            print(f\"   ⚠ unmet features (sim<{warn_threshold:.2f}): {', '.join(s['low_flags'])}\")\n",
    "\n",
    "    # Return DataFrame (you can change to 'return result_payload' if you want to return structured data directly)\n",
    "    return recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f51ed77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Inference main\n",
    "# =========================\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from joblib import load as joblib_load\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parents[0]      # 例如：notebook 的上一层当作项目根\n",
    "sys.path.insert(0, str(PROJECT_ROOT))     # 这样就能 `from utils ...` 了\n",
    "\n",
    "# sys.path.insert(0, str(Path(__file__).resolve().parents[1] / \"utils\"))\n",
    "from utils.condo_recommendation_utils import main_infer\n",
    "import pandas as pd\n",
    "\n",
    "def main_infer(\n",
    "    # Data sources:\n",
    "    items_path: str,\n",
    "    pa_sim_path: str,\n",
    "    # Fallback paths if artifacts is None:\n",
    "    model_path: str | None = None,              # e.g. \"ranker_lgbm.joblib\"\n",
    "    feature_cols: str | None = None,\n",
    "    item_place_col: str = \"PLAN\",\n",
    "    # Inference options:\n",
    "    topn: int = 10,\n",
    "    k_candidates: int = 300,\n",
    "    seed: int = 2025,\n",
    "    use_location_rerank: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run a full inference pass with a partially specified user profile.\n",
    "    - If `artifacts` is provided (from training), it uses it directly.\n",
    "    - Otherwise it loads model and feature_cols from disk.\n",
    "    \"\"\"\n",
    "    # 1) Load model + feature_cols\n",
    "    model = joblib_load(model_path)\n",
    "            \n",
    "    # 2) Load item matrix & PA similarity\n",
    "    items_df = pd.read_csv(items_path)\n",
    "    sim_df_pa = load_pa_similarity_matrix(pa_sim_path)\n",
    "\n",
    "    # 3) Mock a partially specified user (some fields intentionally omitted)\n",
    "    #    - Missing fields will be handled by neutral defaults inside feature builders.\n",
    "    user_input = {\n",
    "        \"Budget_SGD\": 4000000,                 # known & reliable\n",
    "        \"Preferred_Flat_Area\": 100,              # wants 90 sqr\n",
    "        \"Preferred_Place\": \"JURONG EAST\",      # explicit place\n",
    "        \"Priority_Distance_Proximity\": 0.8,  # very distance-sensitive\n",
    "        # The following are partially specified / masked on purpose:\n",
    "        \"Floor_Preference\": 2,                # provided\n",
    "        \"NewHome_Preference\": 0.5,            # neutral on new vs resale\n",
    "        # priorities: leave some missing to test neutral handling\n",
    "        \"Priority_MRT_Access\": 5,\n",
    "        \"Priority_Bus_Access\": 5,\n",
    "        \"Priority_Amenities\": 5,\n",
    "        \"Priority_School_Proximity\": 5,\n",
    "        \"Priority_Park_Access\": 5\n",
    "    }\n",
    "\n",
    "    # 4) Run recommendation (this calls: retrieval → features → predict → rerank → print)\n",
    "    recs = recommend_for_user(\n",
    "        model=model,\n",
    "        feature_cols=feature_cols,\n",
    "        user_input=user_input,\n",
    "        items_df=items_df,\n",
    "        sim_df_pa=sim_df_pa,\n",
    "        item_place_col=item_place_col,\n",
    "        topn=topn,\n",
    "        k_candidates=k_candidates,\n",
    "        seed=seed,\n",
    "        use_location_rerank=True,\n",
    "    )\n",
    "\n",
    "    \n",
    "    #fi = pd.DataFrame({\"feature\": feature_cols, \"gain\": model.feature_importances_}).sort_values(\"gain\", ascending=False)\n",
    "    \n",
    "    imp_gain  = model.booster_.feature_importance(importance_type=\"gain\")\n",
    "    imp_split = model.booster_.feature_importance(importance_type=\"split\")\n",
    "    names     = model.booster_.feature_name()\n",
    "\n",
    "    importance_df = pd.DataFrame({\n",
    "    \"feature\": names,\n",
    "    \"gain\": imp_gain,\n",
    "    \"split\": imp_split\n",
    "    }).sort_values(\"gain\", ascending=False)\n",
    "\n",
    "#     print(\"\\n============================\")\n",
    "#     print(\"Feature Importance (sorted by gain)\")\n",
    "#     print(\"============================\")\n",
    "#     print(importance_df.to_string(index=False))\n",
    "\n",
    "    return {\"user_input\": user_input, \"recs\": recs, \"feature_cols\": feature_cols, \"model\": model}\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Script entry (example)\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":       \n",
    "    feature_cols=['sim_budget', 'sim_budget_missing', 'sim_location', 'sim_location_missing', 'sim_mrt_access', 'sim_mrt_access_missing', 'sim_bus_access', 'sim_bus_access_missing', 'sim_amenities', 'sim_amenities_missing', 'sim_school', 'sim_school_missing', 'sim_area', 'sim_area_missing', 'sim_floor', 'sim_floor_missing', 'sim_newhome', 'sim_newhome_missing', 'sim_park_access', 'sim_park_access_missing']\n",
    "    deploy_path = r\"ranker_lgbm.joblib\"\n",
    "    result = main_infer(\n",
    "        model_path=deploy_path,\n",
    "        feature_cols=feature_cols,\n",
    "        items_path=r\"../../../data/item_matrix_merged_condo_reordered_20251019_180809.csv\",\n",
    "        pa_sim_path=r\"../../../data/PA_centroid_similarity_0_1_condo.csv\", # Call the distance matrix table\n",
    "        item_place_col=\"Plan\",\n",
    "        topn=10,\n",
    "        k_candidates=300,\n",
    "        use_location_rerank=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776b300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parents[0]\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# sys.path.insert(0, str(Path(__file__).resolve().parents[1] / \"utils\"))\n",
    "from utils.condo_recommendation_utils import main_infer_condo\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":       \n",
    "    feature_cols=['sim_budget', 'sim_budget_missing', 'sim_location', 'sim_location_missing', 'sim_mrt_access', 'sim_mrt_access_missing', 'sim_bus_access', 'sim_bus_access_missing', 'sim_amenities', 'sim_amenities_missing', 'sim_school', 'sim_school_missing', 'sim_area', 'sim_area_missing', 'sim_floor', 'sim_floor_missing', 'sim_newhome', 'sim_newhome_missing', 'sim_park_access', 'sim_park_access_missing']\n",
    "    deploy_path = r\"ranker_lgbm.joblib\"\n",
    "    result = main_infer_condo(\n",
    "        model_path=deploy_path,\n",
    "        feature_cols=feature_cols,\n",
    "        items_path=r\"../../../data/item_matrix_merged_condo_reordered_20251019_180809.csv\",\n",
    "        pa_sim_path=r\"../../../data/PA_centroid_similarity_0_1_condo.csv\", # Call the distance matrix table\n",
    "        item_place_col=\"Plan\",\n",
    "        topn=10,\n",
    "        k_candidates=300,\n",
    "        use_location_rerank=True\n",
    "    )\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d4535c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
