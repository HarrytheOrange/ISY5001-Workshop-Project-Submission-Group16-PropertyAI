{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "r1PQ8pKAATZQ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ShfQmnzWp1Cy"
   },
   "outputs": [],
   "source": [
    "# PART 1: DATA LOADING\n",
    "# ============================================================================\n",
    "\n",
    "geo_path = \"/Users/user/Downloads/HDB_All_GeoInfo.csv\"\n",
    "resale_path = \"/Users/user/Downloads/Resale flat prices based on registration date from Jan-2017 onwards.csv\"\n",
    "user_profiles_path = \"/Users/user/Downloads/Singapore_Homebuyer_Profiles_Updated.xlsx\"\n",
    "\n",
    "geo = pd.read_csv(geo_path)\n",
    "resale = pd.read_csv(resale_path)\n",
    "\n",
    "def norm_street(s):\n",
    "    if pd.isna(s): return s\n",
    "    return \" \".join(str(s).upper().split())\n",
    "\n",
    "def norm_block(b):\n",
    "    if pd.isna(b): return b\n",
    "    return str(b).strip().upper()\n",
    "\n",
    "geo[\"block_norm\"] = geo[\"block\"].apply(norm_block)\n",
    "geo[\"street_norm\"] = geo[\"street_nam\"].apply(norm_street)\n",
    "resale[\"block_norm\"] = resale[\"block\"].apply(norm_block)\n",
    "resale[\"street_norm\"] = resale[\"street_name\"].apply(norm_street)\n",
    "resale[\"month\"] = pd.to_datetime(resale[\"month\"], format=\"%Y-%m\", errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-cWp-oNSp0xs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9659 properties\n"
     ]
    }
   ],
   "source": [
    "grp = resale.groupby([\"block_norm\", \"street_norm\"], as_index=False)\n",
    "agg_alltime = grp.agg(\n",
    "    resale_txn_count=(\"resale_price\", \"size\"),\n",
    "    resale_price_median_alltime=(\"resale_price\", \"median\"),\n",
    "    resale_price_mean_alltime=(\"resale_price\", \"mean\"),\n",
    "    first_txn_month=(\"month\", \"min\"),\n",
    "    last_txn_month=(\"month\", \"max\"),\n",
    ")\n",
    "\n",
    "last_month_map = agg_alltime.set_index([\"block_norm\", \"street_norm\"])[\"last_txn_month\"]\n",
    "resale_with_last = resale.merge(last_month_map.rename(\"group_last_month\"),\n",
    "                                on=[\"block_norm\", \"street_norm\"], how=\"left\")\n",
    "latest_rows = resale_with_last[resale_with_last[\"month\"] == resale_with_last[\"group_last_month\"]]\n",
    "latest_prices = latest_rows.groupby([\"block_norm\", \"street_norm\"], as_index=False).agg(\n",
    "    latest_resale_price_median=(\"resale_price\", \"median\"),\n",
    "    latest_resale_price_mean=(\"resale_price\", \"mean\"),\n",
    "    latest_month=(\"month\", \"max\"),\n",
    ")\n",
    "\n",
    "resale_summary = agg_alltime.merge(latest_prices, on=[\"block_norm\", \"street_norm\"], how=\"left\")\n",
    "HDB_All_GeoInfo_enriched = geo.merge(resale_summary, on=[\"block_norm\", \"street_norm\"], how=\"left\")\n",
    "\n",
    "orig_cols = [c for c in geo.columns if c not in [\"block_norm\", \"street_norm\"]]\n",
    "enrich_cols = [\n",
    "    \"resale_txn_count\", \"first_txn_month\", \"last_txn_month\",\n",
    "    \"resale_price_median_alltime\", \"resale_price_mean_alltime\",\n",
    "    \"latest_month\", \"latest_resale_price_median\", \"latest_resale_price_mean\",\n",
    "]\n",
    "final_cols = orig_cols + [\"block_norm\", \"street_norm\"] + enrich_cols\n",
    "HDB_All_GeoInfo_enriched = HDB_All_GeoInfo_enriched[final_cols]\n",
    "\n",
    "df = HDB_All_GeoInfo_enriched[~HDB_All_GeoInfo_enriched['latest_resale_price_mean'].isna()].copy()\n",
    "df = df.loc[:, ~df.columns.duplicated(keep='first')]\n",
    "\n",
    "print(f\"Loaded {len(df)} properties\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 10 features\n"
     ]
    }
   ],
   "source": [
    "# PART 2: FEATURE PREPARATION\n",
    "# ============================================================================\n",
    "\n",
    "candidate_features = [\n",
    "    'mrt_200', 'mrt_500', 'bus_200', 'bus_500',\n",
    "    'HWKR_500M', 'MALL_500M', 'HOSP_1K', 'PK_500M_IN',\n",
    "    'GP_SCH_1K', 'GP_SCH_2K',\n",
    "]\n",
    "\n",
    "features = [c for c in candidate_features if c in df.columns]\n",
    "for c in features:\n",
    "    df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0)\n",
    "\n",
    "print(f\"Using {len(features)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 101 user profiles\n"
     ]
    }
   ],
   "source": [
    "# PART 3: LOAD USER PROFILES\n",
    "# ============================================================================\n",
    "\n",
    "user_profiles = pd.read_excel(user_profiles_path, sheet_name='Homebuyers')\n",
    "print(f\"Loaded {len(user_profiles)} user profiles\")\n",
    "\n",
    "priority_cols = ['Priority_School_Proximity', 'Priority_Park_Access', \n",
    "                 'Priority_Affordability', 'Priority_MRT_Access', \n",
    "                 'Priority_Bus_Access', 'Priority_Amenities']  # ADDED Bus\n",
    "\n",
    "for col in priority_cols:\n",
    "    if col in user_profiles.columns:  # Check if column exists\n",
    "        user_profiles[f'{col}_norm'] = (user_profiles[col] - 1) / 4.0\n",
    "    else:\n",
    "        print(f\"Warning: {col} not found in user profiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 4: PERSONALIZED WEAK LABELING\n",
    "# ============================================================================\n",
    "\n",
    "def personalized_weak_label(row, user_profile):\n",
    "    score = 0.0\n",
    "    budget = user_profile['Budget_SGD']\n",
    "    \n",
    "    # 1. Affordability\n",
    "    affordability_weight = user_profile['Priority_Affordability_norm']\n",
    "    if row['latest_resale_price_mean'] <= budget:\n",
    "        score += 5.0 * affordability_weight\n",
    "    elif row['latest_resale_price_mean'] <= 1.1 * budget:\n",
    "        score += 2.0 * affordability_weight\n",
    "    else:\n",
    "        score -= 3.0 * affordability_weight\n",
    "    \n",
    "    # 2. MRT Access\n",
    "    mrt_weight = user_profile['Priority_MRT_Access_norm']\n",
    "    if user_profile['Has_Car'] == 'No':\n",
    "        mrt_weight *= 1.3\n",
    "    \n",
    "    if row.get('mrt_200', 0) == 1:\n",
    "        score += 3.0 * mrt_weight\n",
    "    elif row.get('mrt_500', 0) == 1:\n",
    "        score += 2.0 * mrt_weight\n",
    "    \n",
    "    # 3. BUS ACCESS (NEW)\n",
    "    bus_weight = user_profile.get('Priority_Bus_Access_norm', 0)\n",
    "    if user_profile['Has_Car'] == 'No':\n",
    "        bus_weight *= 1.3\n",
    "    \n",
    "    bus_200 = row.get('bus_200', 0)\n",
    "    bus_500 = row.get('bus_500', 0)\n",
    "    \n",
    "    if bus_200 >= 3:  # 3+ bus stops within 200m\n",
    "        score += 2.5 * bus_weight\n",
    "    elif bus_200 >= 1:  # 1-2 bus stops\n",
    "        score += 1.5 * bus_weight\n",
    "    elif bus_500 >= 5:  # 5+ bus stops within 500m\n",
    "        score += 1.0 * bus_weight\n",
    "    \n",
    "    # 4. School Proximity\n",
    "    school_weight = user_profile['Priority_School_Proximity_norm']\n",
    "    score += row.get('GP_SCH_1K', 0) * 3.0 * school_weight\n",
    "    score += row.get('GP_SCH_2K', 0) * 1.5 * school_weight\n",
    "    \n",
    "    # 5. Park Access\n",
    "    park_weight = user_profile['Priority_Park_Access_norm']\n",
    "    score += row.get('PK_500M_IN', 0) * 2.5 * park_weight\n",
    "    \n",
    "    # 6. Amenities\n",
    "    amenity_weight = user_profile['Priority_Amenities_norm']\n",
    "    score += row.get('HWKR_500M', 0) * 1.0 * amenity_weight\n",
    "    score += row.get('MALL_500M', 0) * 0.8 * amenity_weight\n",
    "    score += row.get('HOSP_1K', 0) * 0.5 * amenity_weight\n",
    "    \n",
    "    # 7. Price curve\n",
    "    price_diff = (budget - row['latest_resale_price_mean']) / (0.25 * budget)\n",
    "    score += np.tanh(price_diff) * 2.0\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating training data...\n",
      "Generated 15150 training examples\n"
     ]
    }
   ],
   "source": [
    "# PART 5: GENERATE TRAINING DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nGenerating training data...\")\n",
    "rows = []\n",
    "for idx, user in user_profiles.iterrows():\n",
    "    budget_max = user['Budget_SGD'] * 1.2\n",
    "    cand = df[df['latest_resale_price_mean'] <= budget_max].copy()\n",
    "    \n",
    "    n_samples = min(150, len(cand))\n",
    "    if n_samples > 0:\n",
    "        cand_sample = cand.sample(n=n_samples, random_state=idx)\n",
    "        cand_sample['label'] = cand_sample.apply(\n",
    "            lambda r: personalized_weak_label(r, user), axis=1\n",
    "        )\n",
    "        cand_sample['query_id'] = idx + 1\n",
    "        rows.append(cand_sample)\n",
    "\n",
    "train_df = pd.concat(rows, ignore_index=True)\n",
    "print(f\"Generated {len(train_df)} training examples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train size: 12000, Validation size: 3150\n"
     ]
    }
   ],
   "source": [
    "# PART 6: TRAIN/TEST SPLIT\n",
    "# ============================================================================\n",
    "\n",
    "qids = train_df['query_id'].unique()\n",
    "q_train, q_valid = train_test_split(qids, test_size=0.2, random_state=123)\n",
    "train_mask = train_df['query_id'].isin(q_train)\n",
    "valid_mask = train_df['query_id'].isin(q_valid)\n",
    "\n",
    "X_train = train_df.loc[train_mask, features]\n",
    "y_train = train_df.loc[train_mask, 'label']\n",
    "X_valid = train_df.loc[valid_mask, features]\n",
    "y_valid = train_df.loc[valid_mask, 'label']\n",
    "\n",
    "print(f\"\\nTrain size: {len(X_train)}, Validation size: {len(X_valid)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 7: EVALUATION METRICS\n",
    "# ============================================================================\n",
    "\n",
    "def ndcg_at_k(labels, scores, k=10):\n",
    "    order = np.argsort(-scores)\n",
    "    gains = (2**labels[order] - 1)[:k]\n",
    "    discounts = np.log2(np.arange(2, k + 2))\n",
    "    dcg = np.sum(gains / discounts)\n",
    "    ideal_order = np.argsort(-labels)\n",
    "    ideal_gains = (2**labels[ideal_order] - 1)[:k]\n",
    "    ideal_dcg = np.sum(ideal_gains / discounts)\n",
    "    return dcg / ideal_dcg if ideal_dcg > 0 else 0.0\n",
    "\n",
    "def evaluate_model(model, X_valid, y_valid, train_df_valid, model_name):\n",
    "    \"\"\"Evaluate model with multiple metrics\"\"\"\n",
    "    predictions = model.predict(X_valid)\n",
    "    \n",
    "    # Regression metrics\n",
    "    mae = mean_absolute_error(y_valid, predictions)\n",
    "    rmse = np.sqrt(mean_squared_error(y_valid, predictions))\n",
    "    \n",
    "    # Ranking metric (NDCG@10 per query)\n",
    "    val_df = train_df_valid.copy()\n",
    "    val_df['pred'] = predictions\n",
    "    \n",
    "    ndcgs = []\n",
    "    for qid in val_df['query_id'].unique():\n",
    "        chunk = val_df[val_df['query_id'] == qid]\n",
    "        ndcgs.append(ndcg_at_k(chunk['label'].values, chunk['pred'].values, 10))\n",
    "    avg_ndcg = np.mean(ndcgs)\n",
    "    \n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'NDCG@10': avg_ndcg\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING AND COMPARING MULTIPLE MODELS\n",
      "================================================================================\n",
      "\n",
      "1. Training LightGBM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "        \"wmic CPU Get NumberOfCores /Format:csv\".split(),\n",
      "        capture_output=True,\n",
      "        text=True,\n",
      "    )\n",
      "  File \"C:\\Users\\user\\anaconda3\\Lib\\subprocess.py\", line 554, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user\\anaconda3\\Lib\\subprocess.py\", line 1039, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        pass_fds, cwd, env,\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "                        gid, gids, uid, umask,\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        start_new_session, process_group)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user\\anaconda3\\Lib\\subprocess.py\", line 1554, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "                             # no special security\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "                             cwd,\n",
      "                             ^^^^\n",
      "                             startupinfo)\n",
      "                             ^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Completed in 0.29s\n",
      "\n",
      "2. Training XGBoost...\n",
      "   Completed in 0.11s\n",
      "\n",
      "3. Training Random Forest...\n",
      "   Completed in 0.18s\n"
     ]
    }
   ],
   "source": [
    "# PART 8: TRAIN MULTIPLE MODELS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING AND COMPARING MULTIPLE MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results = []\n",
    "trained_models = {}\n",
    "\n",
    "# MODEL 1: LightGBM (Gradient Boosting)\n",
    "print(\"\\n1. Training LightGBM...\")\n",
    "start = time.time()\n",
    "lgb_model = lgb.LGBMRegressor(\n",
    "    objective='regression_l1',\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=200,\n",
    "    num_leaves=63,\n",
    "    min_child_samples=20,\n",
    "    verbose=-1,\n",
    "    random_state=42\n",
    ")\n",
    "lgb_model.fit(X_train, y_train)\n",
    "lgb_time = time.time() - start\n",
    "trained_models['LightGBM'] = lgb_model\n",
    "result = evaluate_model(lgb_model, X_valid, y_valid, train_df.loc[valid_mask], 'LightGBM')\n",
    "result['train_time'] = lgb_time\n",
    "results.append(result)\n",
    "print(f\"   Completed in {lgb_time:.2f}s\")\n",
    "\n",
    "# MODEL 2: XGBoost (Gradient Boosting)\n",
    "print(\"\\n2. Training XGBoost...\")\n",
    "start = time.time()\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    min_child_weight=20,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    verbosity=0\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_time = time.time() - start\n",
    "trained_models['XGBoost'] = xgb_model\n",
    "result = evaluate_model(xgb_model, X_valid, y_valid, train_df.loc[valid_mask], 'XGBoost')\n",
    "result['train_time'] = xgb_time\n",
    "results.append(result)\n",
    "print(f\"   Completed in {xgb_time:.2f}s\")\n",
    "\n",
    "# MODEL 3: Random Forest\n",
    "print(\"\\n3. Training Random Forest...\")\n",
    "start = time.time()\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_time = time.time() - start\n",
    "trained_models['RandomForest'] = rf_model\n",
    "result = evaluate_model(rf_model, X_valid, y_valid, train_df.loc[valid_mask], 'RandomForest')\n",
    "result['train_time'] = rf_time\n",
    "results.append(result)\n",
    "print(f\"   Completed in {rf_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL COMPARISON RESULTS\n",
      "================================================================================\n",
      "\n",
      "Performance Metrics (sorted by NDCG@10):\n",
      "       model      MAE     RMSE  NDCG@10  train_time\n",
      "RandomForest 2.875382 3.638341 0.391155    0.181684\n",
      "     XGBoost 2.865324 3.613228 0.371465    0.114970\n",
      "    LightGBM 2.884139 3.788974 0.347945    0.286501\n",
      "\n",
      "================================================================================\n",
      "BEST MODEL: RandomForest\n",
      "================================================================================\n",
      "NDCG@10: 0.3912\n",
      "MAE: 2.8754\n",
      "RMSE: 3.6383\n",
      "Training Time: 0.18s\n",
      "\n",
      "Feature Importance (RandomForest):\n",
      "   feature  importance\n",
      " GP_SCH_1K    0.219178\n",
      "   bus_500    0.150328\n",
      "   mrt_500    0.139599\n",
      " GP_SCH_2K    0.117640\n",
      " HWKR_500M    0.106249\n",
      "   bus_200    0.090294\n",
      "PK_500M_IN    0.067740\n",
      " MALL_500M    0.063597\n",
      "   mrt_200    0.030185\n",
      "   HOSP_1K    0.015190\n"
     ]
    }
   ],
   "source": [
    "# PART 9: COMPARE RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('NDCG@10', ascending=False)\n",
    "\n",
    "print(\"\\nPerformance Metrics (sorted by NDCG@10):\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Select best model\n",
    "best_model_name = results_df.iloc[0]['model']\n",
    "best_model = trained_models[best_model_name]\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"BEST MODEL: {best_model_name}\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"NDCG@10: {results_df.iloc[0]['NDCG@10']:.4f}\")\n",
    "print(f\"MAE: {results_df.iloc[0]['MAE']:.4f}\")\n",
    "print(f\"RMSE: {results_df.iloc[0]['RMSE']:.4f}\")\n",
    "print(f\"Training Time: {results_df.iloc[0]['train_time']:.2f}s\")\n",
    "\n",
    "# Feature importance for best model\n",
    "if best_model_name in ['LightGBM', 'XGBoost', 'RandomForest', 'GradientBoosting']:\n",
    "    print(f\"\\nFeature Importance ({best_model_name}):\")\n",
    "    if hasattr(best_model, 'feature_importances_'):\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': features,\n",
    "            'importance': best_model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        print(importance_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "AI Model recommendations WITH EXPLANATIONS lesgo - BEST MODEL: RandomForest\n",
      "================================================================================\n",
      "\n",
      "User Profile:\n",
      "  ID: HB0101\n",
      "  Name: Thun Zhen Hong\n",
      "  Type: Single\n",
      "  Budget: $320,000\n",
      "  Has Car: No\n",
      "  Work: CBD (Raffles Place/Marina Bay)\n",
      "  Top Priorities:\n",
      "    • Affordability: 5/5\n",
      "    • MRT Access: 5/5\n",
      "    • Bus Access: 2/5\n",
      "    • School Proximity: 1/5\n",
      "    • Park Access: 1/5\n",
      "    • Amenities: 4/5\n",
      "\n",
      "================================================================================\n",
      "TOP 5 RECOMMENDED PROPERTIES\n",
      "================================================================================\n",
      "\n",
      "#1 | 46 OWEN RD\n",
      "    Price: $370,000 | Score: 12.10\n",
      "\n",
      "    Good match (2 features align with your priorities)\n",
      "\n",
      "    Why this property?\n",
      "      ✓ Good MRT access (within 500m) - matches your high priority\n",
      "      ✓ Good amenities: 1 hawker centre(s) within 500m\n",
      "\n",
      "    Quick stats: MRT <500m | 1 schools | 1 hawkers\n",
      "\n",
      "    ----------------------------------------------------------------------------\n",
      "\n",
      "#2 | 118 LOR 1 TOA PAYOH\n",
      "    Price: $350,000 | Score: 11.62\n",
      "\n",
      "    Good match (2 features align with your priorities)\n",
      "\n",
      "    Why this property?\n",
      "      ⚠ Slightly over budget by $30,000 (9.4% over)\n",
      "      ✓ Good MRT access (within 500m) - matches your high priority\n",
      "      ✓ Good amenities: 1 hawker centre(s) within 500m\n",
      "\n",
      "    Quick stats: MRT <500m | 1 schools | 1 hawkers\n",
      "\n",
      "    ----------------------------------------------------------------------------\n",
      "\n",
      "#3 | 119 LOR 1 TOA PAYOH\n",
      "    Price: $378,000 | Score: 11.50\n",
      "\n",
      "    Good match (2 features align with your priorities)\n",
      "\n",
      "    Why this property?\n",
      "      ✓ Good MRT access (within 500m) - matches your high priority\n",
      "      ✓ Good amenities: 1 hawker centre(s) within 500m\n",
      "\n",
      "    Quick stats: MRT <500m | 1 schools | 1 hawkers\n",
      "\n",
      "    ----------------------------------------------------------------------------\n",
      "\n",
      "#4 | 96 LOR 3 TOA PAYOH\n",
      "    Price: $378,000 | Score: 11.38\n",
      "\n",
      "    Good match (2 features align with your priorities)\n",
      "\n",
      "    Why this property?\n",
      "      ✓ Good MRT access (within 500m) - matches your high priority\n",
      "      ✓ Good amenities: 2 hawker centre(s) within 500m\n",
      "\n",
      "    Quick stats: MRT <500m | 2 schools | 2 hawkers\n",
      "\n",
      "    ----------------------------------------------------------------------------\n",
      "\n",
      "#5 | 258 ANG MO KIO AVE 4\n",
      "    Price: $360,000 | Score: 10.96\n",
      "\n",
      "    Good match (2 features align with your priorities)\n",
      "\n",
      "    Why this property?\n",
      "      ✓ Good MRT access (within 500m) - matches your high priority\n",
      "      ✓ Good amenities: 2 hawker centre(s) within 500m\n",
      "\n",
      "    Quick stats: MRT <500m | 1 schools | 2 hawkers\n",
      "\n",
      "================================================================================\n",
      "MODEL SELECTION COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Best model 'RandomForest' is ready for production use.\n",
      "\n",
      "To use the best model for any user:\n",
      "  user = user_profiles.iloc[INDEX]\n",
      "  recs = get_recommendations_for_user(best_model, df, features, user)\n"
     ]
    }
   ],
   "source": [
    "# PART 10: EXPLANATION GENERATION\n",
    "# ============================================================================\n",
    "\n",
    "def explain_recommendation(property_row, user_profile):\n",
    "\n",
    "    explanations = []\n",
    "    budget = user_profile['Budget_SGD']\n",
    "    price = property_row['latest_resale_price_mean']\n",
    "    \n",
    "    # 1. Price/Affordability\n",
    "    price_diff_pct = ((price - budget) / budget) * 100\n",
    "    if price <= budget:\n",
    "        explanations.append(f\"✓ Within budget by ${budget - price:,.0f} ({abs(price_diff_pct):.1f}% under)\")\n",
    "    elif price <= budget * 1.1:\n",
    "        explanations.append(f\"⚠ Slightly over budget by ${price - budget:,.0f} ({price_diff_pct:.1f}% over)\")\n",
    "    \n",
    "    # 2. MRT Access\n",
    "    if user_profile['Priority_MRT_Access'] >= 4:\n",
    "        if property_row.get('mrt_200', 0) == 1:\n",
    "            explanations.append(\"✓ Excellent MRT access (within 200m) - matches your high priority\")\n",
    "        elif property_row.get('mrt_500', 0) == 1:\n",
    "            explanations.append(\"✓ Good MRT access (within 500m) - matches your high priority\")\n",
    "        else:\n",
    "            explanations.append(\"⚠ No nearby MRT - may not suit your preference\")\n",
    "    \n",
    "    # 3. BUS ACCESS (NEW)\n",
    "    if user_profile.get('Priority_Bus_Access', 0) >= 4:\n",
    "        bus_200 = property_row.get('bus_200', 0)\n",
    "        bus_500 = property_row.get('bus_500', 0)\n",
    "        \n",
    "        if bus_200 >= 3:\n",
    "            explanations.append(f\"✓ Excellent bus access ({int(bus_200)} stops within 200m) - matches your high priority\")\n",
    "        elif bus_200 >= 1:\n",
    "            explanations.append(f\"✓ Good bus access ({int(bus_200)} stops within 200m) - matches your high priority\")\n",
    "        elif bus_500 >= 5:\n",
    "            explanations.append(f\"✓ Decent bus coverage ({int(bus_500)} stops within 500m)\")\n",
    "        else:\n",
    "            explanations.append(\"⚠ Limited bus access - may not suit your preference\")\n",
    "    \n",
    "    # 4. School Proximity\n",
    "    if user_profile['Priority_School_Proximity'] >= 4:\n",
    "        school_1k = property_row.get('GP_SCH_1K', 0)\n",
    "        if school_1k > 0:\n",
    "            explanations.append(f\"✓ {int(school_1k)} primary school(s) within 1km - ideal for families\")\n",
    "        else:\n",
    "            explanations.append(\"⚠ No primary schools within 1km\")\n",
    "    \n",
    "    # 5. Park Access\n",
    "    if user_profile['Priority_Park_Access'] >= 4:\n",
    "        if property_row.get('PK_500M_IN', 0) > 0:\n",
    "            explanations.append(\"✓ Park within 500m - great for outdoor activities\")\n",
    "        else:\n",
    "            explanations.append(\"⚠ No nearby parks\")\n",
    "    \n",
    "    # 6. Amenities\n",
    "    if user_profile['Priority_Amenities'] >= 4:\n",
    "        hawkers = int(property_row.get('HWKR_500M', 0))\n",
    "        malls = int(property_row.get('MALL_500M', 0))\n",
    "        amenity_details = []\n",
    "        if hawkers > 0:\n",
    "            amenity_details.append(f\"{hawkers} hawker centre(s)\")\n",
    "        if malls > 0:\n",
    "            amenity_details.append(f\"{malls} mall(s)\")\n",
    "        \n",
    "        if amenity_details:\n",
    "            explanations.append(f\"✓ Good amenities: {', '.join(amenity_details)} within 500m\")\n",
    "        else:\n",
    "            explanations.append(\"⚠ Limited nearby amenities\")\n",
    "    \n",
    "    # 7. Overall match score\n",
    "    match_reasons = len([e for e in explanations if e.startswith(\"✓\")])\n",
    "    warning_reasons = len([e for e in explanations if e.startswith(\"⚠\")])\n",
    "    \n",
    "    if match_reasons >= 3:\n",
    "        summary = f\"Strong match ({match_reasons} key features align with your priorities)\"\n",
    "    elif match_reasons >= 2:\n",
    "        summary = f\"Good match ({match_reasons} features align with your priorities)\"\n",
    "    else:\n",
    "        summary = f\"Moderate match ({match_reasons} features align, {warning_reasons} areas to consider)\"\n",
    "    \n",
    "    return {\n",
    "        'summary': summary,\n",
    "        'details': explanations\n",
    "    }\n",
    "\n",
    "def get_recommendations_with_explanations(model, df, features, user_profile, top_k=20):\n",
    "    \"\"\"\n",
    "    Get recommendations with detailed explanations\n",
    "    \"\"\"\n",
    "    cand = df[df['latest_resale_price_mean'] <= user_profile['Budget_SGD'] * 1.2].copy()\n",
    "    \n",
    "    # Check if no properties found\n",
    "    if len(cand) == 0:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"NO SUITABLE PROPERTIES FOUND\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        print(f\"\\nUnable to find properties matching your criteria.\")\n",
    "        print(f\"\\nYour Budget: ${user_profile['Budget_SGD']:,}\")\n",
    "        print(f\"Search Range: Up to ${budget_threshold:,.0f} (150% of budget)\")\n",
    "        \n",
    "        # Analyze why no matches\n",
    "        reasons = []\n",
    "        \n",
    "        # Check budget constraints\n",
    "        min_price = df['latest_resale_price_mean'].min()\n",
    "        if budget_threshold < min_price:\n",
    "            reasons.append(f\"Budget constraint: Lowest available property is ${min_price:,.0f}, which exceeds your search range\")\n",
    "        \n",
    "        # Check how many properties are within various budget multiples\n",
    "        within_budget = len(df[df['latest_resale_price_mean'] <= user_profile['Budget_SGD']])\n",
    "        within_120 = len(df[df['latest_resale_price_mean'] <= user_profile['Budget_SGD'] * 1.2])\n",
    "        within_150 = len(df[df['latest_resale_price_mean'] <= user_profile['Budget_SGD'] * 1.5])\n",
    "        within_200 = len(df[df['latest_resale_price_mean'] <= user_profile['Budget_SGD'] * 2.0])\n",
    "        \n",
    "        print(f\"\\nProperty Availability by Price Range:\")\n",
    "        print(f\"  Within budget (${user_profile['Budget_SGD']:,}): {within_budget} properties\")\n",
    "        print(f\"  Up to 120% (${user_profile['Budget_SGD']*1.2:,.0f}): {within_120} properties\")\n",
    "        print(f\"  Up to 150% (${user_profile['Budget_SGD']*1.5:,.0f}): {within_150} properties\")\n",
    "        print(f\"  Up to 200% (${user_profile['Budget_SGD']*2.0:,.0f}): {within_200} properties\")\n",
    "        \n",
    "        if within_budget == 0 and within_120 == 0:\n",
    "            reasons.append(\"Your budget may be too low for current market prices\")\n",
    "        \n",
    "        # Show criteria that might be too restrictive\n",
    "        print(f\"\\nYour Priority Requirements (4-5 out of 5):\")\n",
    "        high_priorities = []\n",
    "        if user_profile['Priority_MRT_Access'] >= 4:\n",
    "            high_priorities.append(f\"MRT Access ({user_profile['Priority_MRT_Access']}/5)\")\n",
    "            mrt_props = len(df[(df['mrt_500'] == 1) | (df['mrt_200'] == 1)])\n",
    "            print(f\"  - MRT Access: {mrt_props} properties have MRT within 500m\")\n",
    "        \n",
    "        if user_profile.get('Priority_Bus_Access', 0) >= 4:\n",
    "            high_priorities.append(f\"Bus Access ({user_profile['Priority_Bus_Access']}/5)\")\n",
    "            bus_props = len(df[df['bus_200'] >= 1])\n",
    "            print(f\"  - Bus Access: {bus_props} properties have bus stops within 200m\")\n",
    "        \n",
    "        if user_profile['Priority_School_Proximity'] >= 4:\n",
    "            high_priorities.append(f\"School Proximity ({user_profile['Priority_School_Proximity']}/5)\")\n",
    "            school_props = len(df[df['GP_SCH_1K'] > 0])\n",
    "            print(f\"  - School Proximity: {school_props} properties have schools within 1km\")\n",
    "        \n",
    "        if user_profile['Priority_Park_Access'] >= 4:\n",
    "            high_priorities.append(f\"Park Access ({user_profile['Priority_Park_Access']}/5)\")\n",
    "            park_props = len(df[df['PK_500M_IN'] > 0])\n",
    "            print(f\"  - Park Access: {park_props} properties have parks within 500m\")\n",
    "        \n",
    "        if user_profile['Priority_Amenities'] >= 4:\n",
    "            high_priorities.append(f\"Amenities ({user_profile['Priority_Amenities']}/5)\")\n",
    "            amenity_props = len(df[(df['HWKR_500M'] > 0) | (df['MALL_500M'] > 0)])\n",
    "            print(f\"  - Amenities: {amenity_props} properties have hawkers/malls nearby\")\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"SUGGESTIONS TO FIND PROPERTIES\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(\"\\n1. Increase your budget or search range\")\n",
    "        print(f\"   Try searching up to ${user_profile['Budget_SGD']*2.0:,.0f} (200% of budget)\")\n",
    "        \n",
    "        if len(high_priorities) > 2:\n",
    "            print(\"\\n2. Consider relaxing some priority requirements\")\n",
    "            print(f\"   You have {len(high_priorities)} high priorities, which may be too restrictive\")\n",
    "        \n",
    "        print(\"\\n3. Consider different locations or HDB towns\")\n",
    "        print(\"   Some areas may offer better value for your budget\")\n",
    "        \n",
    "        if user_profile['Has_Car'] == 'No' and user_profile['Priority_MRT_Access'] >= 4:\n",
    "            print(\"\\n4. Consider bus access as alternative to MRT\")\n",
    "            print(\"   Many areas have excellent bus connectivity without MRT stations\")\n",
    "        \n",
    "        return pd.DataFrame()  # Return empty DataFrame\n",
    "    \n",
    "    cand_scores = model.predict(cand[features])\n",
    "    cand['score'] = cand_scores\n",
    "    \n",
    "    if user_profile['Priority_MRT_Access'] >= 4:\n",
    "        cand['score'] += cand['mrt_500'] * 0.5\n",
    "    if user_profile['Priority_School_Proximity'] >= 4:\n",
    "        cand['score'] += cand.get('GP_SCH_1K', 0) * 0.3\n",
    "    \n",
    "    result = cand.sort_values('score', ascending=False).head(top_k)\n",
    "    \n",
    "    # Add explanations\n",
    "    explanations = []\n",
    "    for idx, row in result.iterrows():\n",
    "        exp = explain_recommendation(row, user_profile)\n",
    "        explanations.append(exp)\n",
    "    \n",
    "    result['explanation_summary'] = [e['summary'] for e in explanations]\n",
    "    result['explanation_details'] = [e['details'] for e in explanations]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Legacy function for backwards compatibility\n",
    "def get_recommendations_for_user(model, df, features, user_profile, top_k=20):\n",
    "    return get_recommendations_with_explanations(model, df, features, user_profile, top_k)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"AI Model recommendations WITH EXPLANATIONS lesgo - BEST MODEL: {best_model_name}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Show detailed recommendations for first user only\n",
    "user = user_profiles.iloc[100]\n",
    "\n",
    "print(f\"\\nUser Profile:\")\n",
    "print(f\"  ID: {user['Buyer_ID']}\")\n",
    "print(f\"  Name: {user['Name']}\")\n",
    "print(f\"  Type: {user['Household_Type']}\")\n",
    "print(f\"  Budget: ${user['Budget_SGD']:,}\")\n",
    "print(f\"  Has Car: {user['Has_Car']}\")\n",
    "print(f\"  Work: {user['Work_Location']}\")\n",
    "print(f\"  Top Priorities:\")\n",
    "print(f\"    • Affordability: {user['Priority_Affordability']}/5\")\n",
    "print(f\"    • MRT Access: {user['Priority_MRT_Access']}/5\")\n",
    "print(f\"    • Bus Access: {user.get('Priority_Bus_Access', 'N/A')}/5\")  # NEW\n",
    "print(f\"    • School Proximity: {user['Priority_School_Proximity']}/5\")\n",
    "print(f\"    • Park Access: {user['Priority_Park_Access']}/5\")\n",
    "print(f\"    • Amenities: {user['Priority_Amenities']}/5\")\n",
    "\n",
    "recs = get_recommendations_with_explanations(best_model, df, features, user, top_k=5)\n",
    "\n",
    "if len(recs) > 0:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"TOP 5 RECOMMENDED PROPERTIES\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    for i, (idx, row) in enumerate(recs.iterrows(), 1):\n",
    "        print(f\"\\n#{i} | {row['block']} {row['street_nam']}\")\n",
    "        print(f\"    Price: ${row['latest_resale_price_mean']:,.0f} | Score: {row['score']:.2f}\")\n",
    "        print(f\"\\n    {row['explanation_summary']}\")\n",
    "        print(f\"\\n    Why this property?\")\n",
    "        for detail in row['explanation_details']:\n",
    "            print(f\"      {detail}\")\n",
    "        \n",
    "        # Show property features\n",
    "        features_list = []\n",
    "        if row.get('mrt_200', 0) == 1:\n",
    "            features_list.append(\"MRT <200m\")\n",
    "        elif row.get('mrt_500', 0) == 1:\n",
    "            features_list.append(\"MRT <500m\")\n",
    "        if row.get('GP_SCH_1K', 0) > 0:\n",
    "            features_list.append(f\"{int(row['GP_SCH_1K'])} schools\")\n",
    "        if row.get('HWKR_500M', 0) > 0:\n",
    "            features_list.append(f\"{int(row['HWKR_500M'])} hawkers\")\n",
    "        if row.get('MALL_500M', 0) > 0:\n",
    "            features_list.append(f\"{int(row['MALL_500M'])} malls\")\n",
    "        \n",
    "        if features_list:\n",
    "            print(f\"\\n    Quick stats: {' | '.join(features_list)}\")\n",
    "        \n",
    "        if i < len(recs):\n",
    "            print(f\"\\n    {'-'*76}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL SELECTION COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nBest model '{best_model_name}' is ready for production use.\")\n",
    "print(\"\\nTo use the best model for any user:\")\n",
    "print(\"  user = user_profiles.iloc[INDEX]\")\n",
    "print(\"  recs = get_recommendations_for_user(best_model, df, features, user)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
