{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dd8e2bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Built pairs: (35050, 23) → saved to D:\\SelfStudy\\NUS_ISS\\Practise_Moudle\\Recommdation_Model\\train_pairs.csv\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[50]\tvalid_0's ndcg@5: 0.844311\tvalid_0's ndcg@10: 0.914442\n",
      "[100]\tvalid_0's ndcg@5: 0.871404\tvalid_0's ndcg@10: 0.929911\n",
      "[150]\tvalid_0's ndcg@5: 0.872897\tvalid_0's ndcg@10: 0.934255\n",
      "[200]\tvalid_0's ndcg@5: 0.875254\tvalid_0's ndcg@10: 0.935197\n",
      "Early stopping, best iteration is:\n",
      "[185]\tvalid_0's ndcg@5: 0.875379\tvalid_0's ndcg@10: 0.93632\n",
      "[RESULT] Mean NDCG@5=0.8754, NDCG@10=0.9363\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Reco Baseline (Cleaned)\n",
    "#  - Core similarities\n",
    "#  - Feature mappings (flat/floor/newhome, env, budget)\n",
    "#  - Location similarity with sensitivity\n",
    "#  - Candidate sampling & feature masking\n",
    "#  - Pair building, label shaping, training, evaluation\n",
    "# ============================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from typing import Optional, Dict, Union\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 0) Utils\n",
    "# =========================================================\n",
    "def _norm_text(x) -> Optional[str]:\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    return str(x).strip().upper()\n",
    "\n",
    "def gaussian_sim(user_val: float, item_val: float, sigma: float = 1.0) -> float:\n",
    "    \"\"\"Smooth 'closeness is better' similarity in [0,1].\"\"\"\n",
    "    u, v = float(user_val), float(item_val)\n",
    "    if sigma <= 0:\n",
    "        return 1.0 if np.isclose(u, v) else 0.0\n",
    "    d = u - v\n",
    "    return float(np.exp(-(d * d) / (2.0 * sigma * sigma)))\n",
    "\n",
    "def _clip_area(a: float, lo: float = 30.0, hi: float = 200.0) -> float:\n",
    "    \"\"\"Clamp area into the valid domain.\"\"\"\n",
    "    if pd.isna(a):\n",
    "        return np.nan\n",
    "    return float(np.clip(float(a), lo, hi))\n",
    "\n",
    "def gaussian_rel(delta: float, sigma: float) -> float:\n",
    "    \"\"\"Gaussian on a relative delta; returns score in [0,1].\"\"\"\n",
    "    if sigma <= 0:\n",
    "        return 1.0 if np.isclose(delta, 0.0) else 0.0\n",
    "    return float(np.exp(-(delta * delta) / (2.0 * sigma * sigma)))\n",
    "\n",
    "\n",
    "def norm_priority(priority_raw: float) -> float:\n",
    "    \"\"\"Map raw priority in [1,5] → [0,1].\"\"\"\n",
    "    if pd.isna(priority_raw):\n",
    "        return 0.5\n",
    "    return float(np.clip((float(priority_raw) - 1.0) / 4.0, 0.0, 1.0))\n",
    "\n",
    "def sat_count(x: float, alpha: float = 1.0) -> float:\n",
    "    \"\"\"Monotonic saturation in [0,1]: s=1-exp(-alpha*x).\"\"\"\n",
    "    if pd.isna(x) or x <= 0:\n",
    "        return 0.0\n",
    "    return float(1.0 - np.exp(-alpha * float(x)))\n",
    "\n",
    "# def blend_with_priority(item_score: float, priority_raw: float, neutral: float = 0.5) -> float:\n",
    "#     \"\"\"\n",
    "#     Combine item_score with user's priority strength:\n",
    "#       priority=0 → neutral, priority=1 → item_score.\n",
    "#     \"\"\"\n",
    "#     p = norm_priority(priority_raw)\n",
    "#     return float(neutral * (1.0 - p) + item_score * p)\n",
    "\n",
    "def blend_with_priority(item_score: float, priority_raw: float, neutral: float = 0.5, contrast: float = 1.0) -> float:\n",
    "    \"\"\"\n",
    "    Make priority effect stronger:\n",
    "      - map item_score from [0,1] to [-1,1] by s' = 2*s - 1\n",
    "      - interpolate between neutral' (=0) and s' by p (0..1), then map back.\n",
    "      - contrast>1 slightly amplifies the effect.\n",
    "    \"\"\"\n",
    "    p = norm_priority(priority_raw)      # 0..1\n",
    "    s = float(np.clip(item_score, 0.0, 1.0))\n",
    "    s_ = (2*s - 1) * contrast            # [-contrast, +contrast]\n",
    "    out_ = p * s_                        # 0→neutral(0), 1→s_\n",
    "    out = (out_ / contrast + 1) / 2      # back to [0,1]\n",
    "    # 混一点点原本 neutral，避免极端：\n",
    "    return float(0.15 * neutral + 0.85 * out)\n",
    "\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 1) Feature mappings — flat / floor / newhome (Gaussian)\n",
    "# =========================================================\n",
    "# ============================================\n",
    "# 2) storey_range ↔ Floor_Preference (Gaussian)\n",
    "#    HDB storey buckets expanded to 1..5 scale\n",
    "# ============================================\n",
    "\n",
    "_STOREY_TO_LEVEL = {\n",
    "    \"01 TO 03\": 1.0,\n",
    "    \"04 TO 06\": 1.2,\n",
    "    \"07 TO 09\": 1.5,\n",
    "    \"10 TO 12\": 1.7,\n",
    "    \"13 TO 15\": 2.0,\n",
    "    \"16 TO 18\": 2.4,\n",
    "    \"19 TO 21\": 2.8,\n",
    "    \"22 TO 24\": 3.0,\n",
    "    \"25 TO 27\": 3.3,\n",
    "    \"28 TO 30\": 3.7,\n",
    "    \"31 TO 33\": 4.0,\n",
    "    \"34 TO 36\": 4.0,\n",
    "    \"37 TO 39\": 4.5,\n",
    "    \"40 TO 42\": 4.5,\n",
    "    \"43 TO 45\": 5.0,\n",
    "    \"46 TO 48\": 5.0,\n",
    "    \"49 TO 51\": 5.0,\n",
    "    \"52 TO 54\": 5.0,\n",
    "    \"55 TO 57\": 5.0\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_match_scores_gaussian(user_row: dict | pd.Series,\n",
    "                                  item_row: dict | pd.Series,\n",
    "                                  sigmas: dict | None = None) -> dict:\n",
    "    \"\"\"Return sim_flat_type, sim_floor, sim_newhome in [0,1].\"\"\"\n",
    "    s = sigmas or {\"area\": 0.12, \"floor\": 1.0, \"newhome\": 0.25}\n",
    "    return {\n",
    "        \"sim_area\": score_area_closeness(user_row[\"Preferred_Flat_Area\"], item_row[\"floor_area_sqm\"], s[\"area\"]),\n",
    "        \"sim_floor\":     score_floor(user_row[\"Floor_Preference\"], item_row[\"storey_range\"], s[\"floor\"]),\n",
    "        \"sim_newhome\":   score_newhome(user_row[\"NewHome_Preference\"], s[\"newhome\"]),\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# def score_area_closeness(user_area: float,\n",
    "#                          item_area: float,\n",
    "#                          rel_sigma: float = 0.12,\n",
    "#                          asym_left_scale: float = 0.6,\n",
    "#                          asym_right_scale: float = 1.0) -> float:\n",
    "#     \"\"\"\n",
    "#     Smooth 'closer is better' for floor area using RELATIVE Gaussian on percentage diff.\n",
    "#     - rel_sigma: tolerance (e.g., 0.12 means ~12% deviation still ~0.8+ score)\n",
    "#     - prefer_min: if True, penalize smaller-than-preference harder (asymmetric)\n",
    "#     - asym_left_scale: shrink sigma on the LEFT side (item < user) when prefer_min=True\n",
    "#     \"\"\"\n",
    "#     ua = _clip_area(user_area)\n",
    "#     ia = _clip_area(item_area)\n",
    "#     if pd.isna(ua) or pd.isna(ia) or ua <= 0:\n",
    "#         return 0.5  # neutral if missing\n",
    "\n",
    "#     # relative difference: (item - user) / user\n",
    "#     rel = (ia - ua) / ua\n",
    "\n",
    "#     if prefer_min:\n",
    "#         # item smaller than desired → harsher penalty\n",
    "#         sigma_left  = max(1e-6, rel_sigma * asym_left_scale)  # e.g., 0.12 * 0.6\n",
    "#         sigma_right = max(1e-6, rel_sigma * asym_right_scale) # e.g., 0.12 * 1.0\n",
    "#         sigma = sigma_right if rel >= 0 else sigma_left\n",
    "#         return gaussian_rel(rel, sigma)\n",
    "#     else:\n",
    "#         return gaussian_rel(rel, rel_sigma)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- 相对高斯：越接近越好（仅保留 rel_sigma 一个参数） ---\n",
    "def score_area_closeness(user_area: float,\n",
    "                         item_area: float,\n",
    "                         rel_sigma: float = 0.12) -> float:\n",
    "    \"\"\"\n",
    "    Return a similarity in [0,1] using a relative Gaussian on percentage diff:\n",
    "        rel = (item - user) / user\n",
    "        sim = exp( - rel^2 / (2 * rel_sigma^2) )\n",
    "    仅一个超参数：rel_sigma（相对容差），默认 0.12 ≈ 12%。\n",
    "    \"\"\"\n",
    "    # ——最小清洗：转成数值并裁剪到[30,200]，避免字符串/越界导致NaN——\n",
    "    ua = pd.to_numeric(user_area, errors=\"coerce\")\n",
    "    ia = pd.to_numeric(item_area, errors=\"coerce\")\n",
    "    if not pd.isna(ua):\n",
    "        ua = float(np.clip(ua, 30.0, 200.0))\n",
    "    if not pd.isna(ia):\n",
    "        ia = float(np.clip(ia, 30.0, 200.0))\n",
    "\n",
    "    # === 临时调试：打印并“打断” ===\n",
    "    # print(f\"[DEBUG] area inputs -> user_area(ua)={ua}, item_area(ia)={ia}\")\n",
    "    # 方式A（推荐在notebook/脚本临时用）：打印后直接返回一个占位分数，观察输入是否为NaN\n",
    "    # return 0.5  # ← 调试完成后删掉这一行\n",
    "\n",
    "    # 方式B（强力中断）：打印后直接中止执行\n",
    "    #raise SystemExit(\"DEBUG BREAK after printing ua/ia\")\n",
    "\n",
    "    # ——正式计算——\n",
    "    if pd.isna(ua) or pd.isna(ia) or ua <= 0:\n",
    "        return 0.5  # 缺值兜底（这就是你之前看到全是0.5的触发条件）\n",
    "\n",
    "    rel = (ia - ua) / ua\n",
    "    if rel_sigma <= 0:\n",
    "        return 1.0 if np.isclose(rel, 0.0) else 0.0\n",
    "    return float(np.exp(-(rel * rel) / (2.0 * rel_sigma * rel_sigma)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def storey_to_level(storey_range: str, default_level: int = 2) -> int:\n",
    "#     key = _norm_text(storey_range)\n",
    "#     return _STOREY_TO_LEVEL.get(key, default_level)\n",
    "\n",
    "def storey_to_level(storey_range: str, default_level: float = 2.0) -> float:\n",
    "    \"\"\"\n",
    "    Map textual 'storey_range' to a continuous level in {1..5}.\n",
    "    Unknown/missing values → default_level (mid-level = 2.5).\n",
    "    \"\"\"\n",
    "    key = _norm_text(storey_range)\n",
    "    if key in _STOREY_TO_LEVEL:\n",
    "        return _STOREY_TO_LEVEL[key]\n",
    "    # Try partial match (e.g. \"35 TO 37\" not in dict but similar)\n",
    "    if isinstance(key, str):\n",
    "        try:\n",
    "            low = int(key.split(\" TO \")[0])\n",
    "            if low <= 6: return 1.0\n",
    "            elif low <= 12: return 2.0\n",
    "            elif low <= 21: return 3.0\n",
    "            elif low <= 33: return 4.0\n",
    "            else: return 5.0\n",
    "        except Exception:\n",
    "            return default_level\n",
    "    return default_level\n",
    "\n",
    "\n",
    "# def score_floor(user_floor_pref: float, item_storey_range: str, sigma: float = 1.0) -> float:\n",
    "#     \"\"\"Floor_Preference (1..5) vs storey_range (1..3) → [0,1].\"\"\"\n",
    "#     item_level = storey_to_level(item_storey_range)\n",
    "#     return gaussian_sim(user_floor_pref, item_level, sigma=sigma)\n",
    "\n",
    "def score_floor(user_floor_pref: float,\n",
    "                item_storey_range: str,\n",
    "                sigma: float = 1.2) -> float:\n",
    "    \"\"\"\n",
    "    Gaussian similarity between user's floor preference (1..5)\n",
    "    and property's level (1..5).\n",
    "    Slightly larger sigma to tolerate close floors.\n",
    "    Returns a value in [0, 1].\n",
    "    \"\"\"\n",
    "    item_level = storey_to_level(item_storey_range)\n",
    "    return gaussian_sim(user_floor_pref, item_level, sigma=sigma)\n",
    "\n",
    "\n",
    "def score_newhome(user_newhome_pref: float, sigma: float = 0.25) -> float:\n",
    "    \"\"\"\n",
    "    NewHome_Preference: 1=new, 0.5=neutral, 0=resale.\n",
    "    For HDB resale, item=0.0; neutral returns 1.0.\n",
    "    \"\"\"\n",
    "    if pd.isna(user_newhome_pref):\n",
    "        return 1.0\n",
    "    val = float(user_newhome_pref)\n",
    "    if np.isclose(val, 0.5):\n",
    "        return 1.0\n",
    "    return gaussian_sim(val, 0.0, sigma=sigma)\n",
    "\n",
    "\n",
    "\n",
    "# def compute_match_scores_gaussian(user_row: dict | pd.Series,\n",
    "#                                   item_row: dict | pd.Series,\n",
    "#                                   sigmas: dict | None = None) -> dict:\n",
    "#     \"\"\"Return sim_flat_type, sim_floor, sim_newhome in [0,1].\"\"\"\n",
    "#     s = sigmas or {\"area\": 0.12, \"floor\": 1.0, \"newhome\": 0.25}\n",
    "#     return {\n",
    "#         \"sim_area\": score_area_closeness(user_row[\"Preferred_Flat_Area\"], item_row[\"floor_area_sqm\"], s[\"area\"]),\n",
    "#         \"sim_floor\":     score_floor(user_row[\"Floor_Preference\"], item_row[\"storey_range\"], s[\"floor\"]),\n",
    "#         \"sim_newhome\":   score_newhome(user_row[\"NewHome_Preference\"], s[\"newhome\"]),\n",
    "#     }\n",
    "\n",
    "\n",
    "def compute_match_scores_gaussian(user_row: dict | pd.Series,\n",
    "                                  item_row: dict | pd.Series,\n",
    "                                  sigmas: dict | None = None) -> dict:\n",
    "    \"\"\"Return sim_area, sim_floor, sim_newhome in [0,1]（接口保持原样）.\"\"\"\n",
    "    s = sigmas or {\"area\": 0.12, \"floor\": 1.0, \"newhome\": 0.25}\n",
    "\n",
    "    return {\n",
    "        # 注意：你说用户侧字段现在叫 Preferred_Flat_Area（若你改叫 floor_area_sqm，就把这里同步一下）\n",
    "        \"sim_area\":    score_area_closeness(user_row[\"Preferred_Flat_Area\"],\n",
    "                                            item_row[\"floor_area_sqm\"],\n",
    "                                            s[\"area\"]),\n",
    "        \"sim_floor\":   score_floor(user_row[\"Floor_Preference\"],\n",
    "                                   item_row[\"storey_range\"],\n",
    "                                   s[\"floor\"]),\n",
    "        \"sim_newhome\": score_newhome(user_row[\"NewHome_Preference\"],\n",
    "                                     s[\"newhome\"]),\n",
    "    }\n",
    "\n",
    "\n",
    "# def compute_match_scores_gaussian(user_row: dict | pd.Series,\n",
    "#                                   item_row: dict | pd.Series,\n",
    "#                                   sigmas: dict | None = None) -> dict:\n",
    "#     \"\"\"\n",
    "#     Returns Gaussian-like similarities in [0,1]:\n",
    "#       - sim_area   : user['floor_area_sqm'] vs item['floor_area_sqm'] (relative Gaussian)\n",
    "#       - sim_floor  : Floor_Preference vs storey_range (unchanged)\n",
    "#       - sim_newhome: NewHome_Preference vs resale (unchanged)\n",
    "#     \"\"\"\n",
    "#     s = sigmas or {\"area\": 0.12, \"floor\": 1.0, \"newhome\": 0.25}\n",
    "\n",
    "#     sim_area = score_area_closeness(\n",
    "#         user_area=user_row.get(\"Preferred_Flat_Area\"),\n",
    "#         item_area=item_row.get(\"floor_area_sqm\"),\n",
    "#         sigmas=s[\"area\"],\n",
    "#     )\n",
    "\n",
    "#     sim_floor = score_floor(\n",
    "#         user_row.get(\"Floor_Preference\"),\n",
    "#         item_row.get(\"storey_range\"),\n",
    "#         sigma=s[\"floor\"]\n",
    "#     )\n",
    "\n",
    "#     sim_new = score_newhome(\n",
    "#         user_row.get(\"NewHome_Preference\"),\n",
    "#         sigma=s[\"newhome\"]\n",
    "#     )\n",
    "\n",
    "#     return {\n",
    "#         \"sim_area\": sim_area,          # <-- new key\n",
    "#         \"sim_floor\": sim_floor,\n",
    "#         \"sim_newhome\": sim_new,\n",
    "#     }\n",
    "\n",
    "# =========================================================\n",
    "# 2) Feature mappings — facility accessibility environment (higher is better)\n",
    "# =========================================================\n",
    "def score_park_access(priority_park_access: float, pk_500m_in: float) -> float:\n",
    "    item_score = 1.0 if (not pd.isna(pk_500m_in) and pk_500m_in > 0) else 0.0\n",
    "    return blend_with_priority(item_score, priority_park_access, neutral=0.5)\n",
    "\n",
    "def score_bus_access(priority_bus_access: float, bus_200: float, bus_500: float,\n",
    "                     alpha_200: float = 0.8, alpha_500: float = 0.4) -> float:\n",
    "    s200 = sat_count(bus_200, alpha_200)\n",
    "    s500 = sat_count(bus_500, alpha_500)\n",
    "    item_score = float(np.clip((2.0/3.0)*s200 + (1.0/3.0)*s500, 0.0, 1.0))\n",
    "    return blend_with_priority(item_score, priority_bus_access, neutral=0.5)\n",
    "\n",
    "def score_mrt_access(priority_mrt_access: float, mrt_200: float, mrt_500: float,\n",
    "                     alpha_200: float = 2.0, alpha_500: float = 1.2) -> float:\n",
    "    s200 = sat_count(mrt_200, alpha_200)\n",
    "    s500 = sat_count(mrt_500, alpha_500)\n",
    "    item_score = float(np.clip((2.0/3.0)*s200 + (1.0/3.0)*s500, 0.0, 1.0))\n",
    "    return blend_with_priority(item_score, priority_mrt_access, neutral=0.5)\n",
    "\n",
    "def score_amenities(priority_amenities: float, hwkr_500m: float, mall_500m: float,\n",
    "                    alpha_hwkr: float = 0.7, alpha_mall: float = 0.6) -> float:\n",
    "    s_h = sat_count(hwkr_500m, alpha_hwkr)\n",
    "    s_m = sat_count(mall_500m, alpha_mall)\n",
    "    item_score = float(np.clip(0.25*s_h + 0.75*s_m, 0.0, 1.0))\n",
    "    return blend_with_priority(item_score, priority_amenities, neutral=0.5)\n",
    "\n",
    "def score_school_proximity(priority_school: float, gp_sch_1k: float, gp_sch_2k: float,\n",
    "                           alpha_1k: float = 0.9, alpha_2k: float = 0.5) -> float:\n",
    "    s1 = sat_count(gp_sch_1k, alpha_1k)\n",
    "    s2 = sat_count(gp_sch_2k, alpha_2k)\n",
    "    item_score = float(np.clip((2.0/3.0)*s1 + (1.0/3.0)*s2, 0.0, 1.0))\n",
    "    return blend_with_priority(item_score, priority_school, neutral=0.5)\n",
    "\n",
    "\n",
    "def compute_env_priority_scores(user_row: dict | pd.Series,\n",
    "                                item_row: dict | pd.Series,\n",
    "                                alphas: dict | None = None) -> dict:\n",
    "    \"\"\"\n",
    "    Safe version: all user priorities fetched via .get(..., np.nan),\n",
    "    so missing priorities are treated as neutral inside blend_with_priority().\n",
    "    \"\"\"\n",
    "    alphas = alphas or {\n",
    "        \"bus_200\": 0.8, \"bus_500\": 0.4,\n",
    "        \"mrt_200\": 2.0, \"mrt_500\": 1.2,\n",
    "        \"hwkr\": 0.7, \"mall\": 0.6,\n",
    "        \"sch_1k\": 0.9, \"sch_2k\": 0.5\n",
    "    }\n",
    "\n",
    "    # ---- safely get user priorities (missing -> NaN -> neutral 0.5) ----\n",
    "    p_park = user_row.get(\"Priority_Park_Access\", np.nan)\n",
    "    p_bus  = user_row.get(\"Priority_Bus_Access\", np.nan)\n",
    "    p_mrt  = user_row.get(\"Priority_MRT_Access\", np.nan)\n",
    "    p_am   = user_row.get(\"Priority_Amenities\", np.nan)\n",
    "    p_sch  = user_row.get(\"Priority_School_Proximity\", np.nan)\n",
    "\n",
    "    # ---- items (already .get with defaults) ----\n",
    "    s_park = score_park_access(\n",
    "        p_park,\n",
    "        item_row.get(\"PK_500M_IN\", 0)\n",
    "    )\n",
    "\n",
    "    s_bus = score_bus_access(\n",
    "        p_bus,\n",
    "        item_row.get(\"bus_200\", 0),\n",
    "        item_row.get(\"bus_500\", 0),\n",
    "        alpha_200=alphas[\"bus_200\"],\n",
    "        alpha_500=alphas[\"bus_500\"]\n",
    "    )\n",
    "\n",
    "    s_mrt = score_mrt_access(\n",
    "        p_mrt,\n",
    "        item_row.get(\"mrt_200\", 0),\n",
    "        item_row.get(\"mrt_500\", 0),\n",
    "        alpha_200=alphas[\"mrt_200\"],\n",
    "        alpha_500=alphas[\"mrt_500\"]\n",
    "    )\n",
    "\n",
    "    s_am = score_amenities(\n",
    "        p_am,\n",
    "        item_row.get(\"HWKR_500M\", 0),\n",
    "        item_row.get(\"MALL_500M\", 0),\n",
    "        alpha_hwkr=alphas[\"hwkr\"],\n",
    "        alpha_mall=alphas[\"mall\"]\n",
    "    )\n",
    "\n",
    "    s_sch = score_school_proximity(\n",
    "        p_sch,\n",
    "        item_row.get(\"GP_SCH_1K\", 0),\n",
    "        item_row.get(\"GP_SCH_2K\", 0),\n",
    "        alpha_1k=alphas[\"sch_1k\"],\n",
    "        alpha_2k=alphas[\"sch_2k\"]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"sim_park_access\": s_park,\n",
    "        \"sim_bus_access\":  s_bus,\n",
    "        \"sim_mrt_access\":  s_mrt,\n",
    "        \"sim_amenities\":   s_am,\n",
    "        \"sim_school\":      s_sch,\n",
    "    }\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 3) Budget affinity (asymmetric Gaussian)\n",
    "# =========================================================\n",
    "def _asymmetric_gaussian(x: float, center: float, sigma_left: float, sigma_right: float) -> float:\n",
    "    dx = float(x) - float(center)\n",
    "    sigma = float(sigma_right if dx >= 0 else sigma_left)\n",
    "    if sigma <= 0:\n",
    "        return 1.0 if np.isclose(dx, 0.0) else 0.0\n",
    "    return float(np.exp(-(dx * dx) / (2.0 * sigma * sigma)))\n",
    "\n",
    "def budget_affinity_score(budget_sgd: float, resale_price: float, #always low a bit\n",
    "                          target_under: float = 0.01, # bis a little\n",
    "                          sigma_below: float = 0.08,\n",
    "                          sigma_above: float = 0.12,\n",
    "                          hard_clip: float = 0.60) -> float:\n",
    "    \"\"\"Smooth satisfaction between budget and price in [0,1].\"\"\"\n",
    "    if pd.isna(budget_sgd) or budget_sgd <= 0 or pd.isna(resale_price) or resale_price <= 0:\n",
    "        return 0.0\n",
    "    d = (float(resale_price) - float(budget_sgd)) / float(budget_sgd)\n",
    "    d = float(np.clip(d, -hard_clip, hard_clip))\n",
    "    center = -abs(float(target_under))\n",
    "    score = _asymmetric_gaussian(d, center, sigma_below, sigma_above)\n",
    "    return float(np.clip(score, 0.0, 1.0))\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 4) Location similarity with sensitivity\n",
    "# =========================================================\n",
    "def _norm_place(x: Optional[Union[str, float]]) -> Optional[str]:\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "        return None\n",
    "    return str(x).strip().upper()\n",
    "\n",
    "def load_pa_similarity_matrix(path: str) -> pd.DataFrame:\n",
    "    if path.lower().endswith(\".csv\"):\n",
    "        df = pd.read_csv(path, index_col=0)\n",
    "    else:\n",
    "        df = pd.read_excel(path, index_col=0)\n",
    "    df.index = df.index.to_series().map(_norm_place)\n",
    "    df.columns = pd.Index([_norm_place(c) for c in df.columns])\n",
    "    common = df.index.intersection(df.columns)\n",
    "    df = df.loc[common, common].copy()\n",
    "    df = df.clip(0.0, 1.0)\n",
    "    df = 0.5 * (df + df.T)\n",
    "    np.fill_diagonal(df.values, 1.0)\n",
    "    return df\n",
    "\n",
    "def _temperature_blend(base_sim: float, sensitivity: float,\n",
    "                       neutral: float = 0.6, tau_low: float = 0.6, tau_high: float = 3.0) -> float:\n",
    "    p = float(np.clip(0.0 if sensitivity is None else sensitivity, 0.0, 1.0))\n",
    "    s = float(np.clip(0.0 if base_sim is None else base_sim, 0.0, 1.0))\n",
    "    tau = tau_low + (tau_high - tau_low) * p\n",
    "    s_temp = s ** tau\n",
    "    return float(np.clip((1.0 - p) * neutral + p * s_temp, 0.0, 1.0))\n",
    "\n",
    "def pa_location_similarity_with_sensitivity(\n",
    "    user_place: Optional[str],\n",
    "    item_place: Optional[str],\n",
    "    sim_df: pd.DataFrame,\n",
    "    distance_sensitivity: Optional[float],\n",
    "    alias_map_user: Optional[Dict[str, str]] = None,\n",
    "    alias_map_item: Optional[Dict[str, str]] = None,\n",
    "    default_when_missing: float = 0.0,\n",
    "    neutral: float = 0.6,\n",
    "    tau_low: float = 0.6,\n",
    "    tau_high: float = 3.0\n",
    ") -> float:\n",
    "    u = _norm_place(user_place)\n",
    "    v = _norm_place(item_place)\n",
    "    if alias_map_user and u is not None:\n",
    "        u = _norm_place(alias_map_user.get(u, u))\n",
    "    if alias_map_item and v is not None:\n",
    "        v = _norm_place(alias_map_item.get(v, v))\n",
    "    if u is None or v is None:\n",
    "        base = float(default_when_missing)\n",
    "    elif (u in sim_df.index) and (v in sim_df.columns):\n",
    "        base = float(np.clip(sim_df.loc[u, v], 0.0, 1.0))\n",
    "    else:\n",
    "        base = float(default_when_missing)\n",
    "    return _temperature_blend(base, distance_sensitivity, neutral, tau_low, tau_high)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 5) Candidate sampling & feature dropout\n",
    "# =========================================================\n",
    "def _banded_budget_sample(items_df: pd.DataFrame, budget: float,\n",
    "                          k_total: int = 30, band: float = 0.20, seed: int = 42) -> pd.DataFrame:\n",
    "    \"\"\"Retrieve k candidates within ±band of budget; fallback to global sample.\"\"\"\n",
    "    band_df = items_df[(items_df[\"resale_price\"] >= (1 - band) * budget) &\n",
    "                       (items_df[\"resale_price\"] <= (1 + band) * budget)]\n",
    "    if len(band_df) >= k_total:\n",
    "        return band_df.sample(k_total, random_state=seed)\n",
    "    k_band = min(len(band_df), int(0.7 * k_total))\n",
    "    part1 = band_df.sample(k_band, random_state=seed) if k_band > 0 else band_df.head(0)\n",
    "    k_rest = k_total - len(part1)\n",
    "    part2 = items_df.sample(min(k_rest, len(items_df)), random_state=seed)\n",
    "    return pd.concat([part1, part2]).drop_duplicates().head(k_total)\n",
    "\n",
    "# masking configuration\n",
    "GEO_MASK_OVERALL_PROB = 0.15\n",
    "MASK_NEUTRALS = {\"sim_budget\": 0.8, \"sim_location\": 0.6, \"default\": 0.5}\n",
    "\n",
    "def _apply_feature_dropout(feats_full: dict,\n",
    "                           user_row: pd.Series,\n",
    "                           item_row: pd.Series,\n",
    "                           sim_df_pa: pd.DataFrame,\n",
    "                           item_place_col: str,\n",
    "                           rng: np.random.Generator,\n",
    "                           neutral_vals: dict = MASK_NEUTRALS) -> dict:\n",
    "    \"\"\"\n",
    "    Simulate incomplete user inputs by masking some sim_* features and adding *_missing flags.\n",
    "    Budget is rarely masked; location masking is controlled via GEO_MASK_OVERALL_PROB.\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    # Always keep budget (or low prob)\n",
    "    out[\"sim_budget\"] = feats_full[\"sim_budget\"]\n",
    "    out[\"sim_budget_missing\"] = 0\n",
    "\n",
    "    # Location masking\n",
    "    if rng.random() < GEO_MASK_OVERALL_PROB:\n",
    "        out[\"sim_location\"] = neutral_vals[\"sim_location\"]\n",
    "        out[\"sim_location_missing\"] = 1\n",
    "    else:\n",
    "        out[\"sim_location\"] = feats_full[\"sim_location\"]\n",
    "        out[\"sim_location_missing\"] = 0\n",
    "\n",
    "    # Other channels (15% chance each)\n",
    "    for k in [\"sim_mrt_access\", \"sim_bus_access\", \"sim_amenities\", \"sim_school\",\n",
    "              \"sim_area\", \"sim_floor\", \"sim_newhome\",\"sim_park_access\"]:\n",
    "        if rng.random() < 0.15:\n",
    "            out[k] = neutral_vals[\"default\"]\n",
    "            out[f\"{k}_missing\"] = 1\n",
    "        else:\n",
    "            out[k] = feats_full[k]\n",
    "            out[f\"{k}_missing\"] = 0\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 6) Pair building & label shaping\n",
    "# =========================================================\n",
    "# def _weighted_label_from_feats(feats_full: dict, distance_sensitivity: float) -> float:\n",
    "#     \"\"\"Weighted mean: location weight grows with user's distance sensitivity.\"\"\"\n",
    "#     alpha = 0.2 + 0.5 * float(np.clip(distance_sensitivity, 0.0, 1.0))  # 0.2..0.7\n",
    "#     sim_loc = feats_full[\"sim_location\"]\n",
    "#     others = [v for k, v in feats_full.items() if k != \"sim_location\"]\n",
    "#     other_mean = float(np.mean(others)) if others else 0.0\n",
    "#     return float(alpha * sim_loc + (1.0 - alpha) * other_mean)\n",
    "\n",
    "def _weighted_label_from_feats(feats_full: dict, user: pd.Series | dict) -> float:\n",
    "    \"\"\"\n",
    "    Build weak label as a weighted mean of channels:\n",
    "      - Location weight from Priority_Distance_Proximity (已有逻辑)\n",
    "      - Env channels (MRT/Bus/Amenities/School/Park) 从相应 Priority_* 映射到权重\n",
    "      - 预算/户型/楼层/新旧 作为基础通道，给一个稳态权重\n",
    "    All weights归一化后求加权平均。\n",
    "    \"\"\"\n",
    "    # 1) base channels\n",
    "    w_budget = 1.0\n",
    "    w_area   = 0.8\n",
    "    w_floor  = 0.6\n",
    "    w_new    = 0.4\n",
    "\n",
    "    # 2) location channel\n",
    "    pdist = float(np.clip(user.get(\"Priority_Distance_Proximity\", 0.0), 0.0, 1.0))\n",
    "    w_loc = 0.6 + 1.4 * pdist   # 0.6..2.0\n",
    "\n",
    "    # 3) env channels weights from priorities (1..5 → 0..1)\n",
    "    def _wp(raw):  # weight in 0.2..1.5（放大差异）\n",
    "        p = norm_priority(raw)           # 0..1\n",
    "        return 0.2 + 1.3 * p             # 映射到 0.2..1.5\n",
    "\n",
    "    w_mrt = _wp(user.get(\"Priority_MRT_Access\", np.nan))\n",
    "    w_bus = _wp(user.get(\"Priority_Bus_Access\", np.nan))\n",
    "    w_am  = _wp(user.get(\"Priority_Amenities\", np.nan))\n",
    "    w_sch = _wp(user.get(\"Priority_School_Proximity\", np.nan))\n",
    "    w_park= _wp(user.get(\"Priority_Park_Access\", np.nan))\n",
    "\n",
    "    # 4) assemble & normalize\n",
    "    chans = {\n",
    "        \"sim_budget\": w_budget,\n",
    "        \"sim_area\": w_area,\n",
    "        \"sim_floor\": w_floor,\n",
    "        \"sim_newhome\": w_new,\n",
    "        \"sim_location\": w_loc,\n",
    "        \"sim_mrt_access\": w_mrt,\n",
    "        \"sim_bus_access\": w_bus,\n",
    "        \"sim_amenities\": w_am,\n",
    "        \"sim_school\": w_sch,\n",
    "        \"sim_park_access\": w_park,\n",
    "    }\n",
    "\n",
    "    # 注意：feats_full 里必须有以上 key（你的构造里已经有）\n",
    "    weights = np.array([chans[k] for k in chans], dtype=float)\n",
    "    values  = np.array([feats_full[k] for k in chans], dtype=float)\n",
    "    weights = weights / np.sum(weights)\n",
    "\n",
    "    return float(np.dot(weights, values))\n",
    "\n",
    "\n",
    "def _weighted_label_from_feats(feats_full: dict, user: dict | pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Build weak label as a weighted mean of similarity channels.\n",
    "    - Budget is the anchor (weight cap = 1.00).\n",
    "    - Location is forced to be the second most influential (cap = 0.90 * budget).\n",
    "    - All other channels are capped at 0.75 * budget.\n",
    "    \"\"\"\n",
    "    # ---- anchors & caps ----\n",
    "    w_budget = 1.00                          # 100% baseline\n",
    "    loc_cap  = 1.55 * w_budget               # location upper bound\n",
    "    oth_cap  = 0.60 * w_budget               # all other channels' upper bound\n",
    "\n",
    "    # priority 1..5 -> 0..1\n",
    "    def _p(raw):\n",
    "        if pd.isna(raw): return 0.5\n",
    "        return float(np.clip((float(raw) - 1.0) / 4.0, 0.0, 1.0))\n",
    "\n",
    "    # distance sensitivity 0..1\n",
    "    pdist = float(np.clip(user.get(\"Priority_Distance_Proximity\", 0.0), 0.0, 1.0))\n",
    "\n",
    "    # ---- base weights (before capping) ----\n",
    "    # keep budget as 1.0; location grows with sensitivity\n",
    "    w_loc   = 0.90 + 0.80 * pdist            # 0.90..1.70  (then capped to 0.90)\n",
    "\n",
    "    # others: moderate ranges, driven by priorities (or mild constants)\n",
    "    w_area  = 0.60 + 0.60 * _p(user.get(\"Preferred_Flat_Area\", 3))  # proxy; no explicit 'flat' priority\n",
    "    w_floor = 0.60 + 0.60 * _p(user.get(\"Floor_Preference\", 3))\n",
    "    w_new   = 0.40                            # new vs resale: weaker by design\n",
    "\n",
    "    w_mrt   = 0.50 + 0.80 * _p(user.get(\"Priority_MRT_Access\", 3))\n",
    "    w_bus   = 0.40 + 0.60 * _p(user.get(\"Priority_Bus_Access\", 3))\n",
    "    w_am    = 0.40 + 0.60 * _p(user.get(\"Priority_Amenities\", 3))\n",
    "    w_sch   = 0.50 + 0.70 * _p(user.get(\"Priority_School_Proximity\", 3))\n",
    "    w_park  = 0.30 + 0.40 * _p(user.get(\"Priority_Park_Access\", 3))    # keep smallest\n",
    "\n",
    "    # ---- apply caps: location > others by construction ----\n",
    "    weights = {\n",
    "        \"sim_budget\":      w_budget,\n",
    "        \"sim_location\":    min(w_loc, loc_cap),\n",
    "        \"sim_area\":   min(w_area, 0.8),\n",
    "        \"sim_floor\":       min(w_floor, oth_cap),\n",
    "        \"sim_newhome\":     min(w_new, oth_cap),\n",
    "        \"sim_mrt_access\":  min(w_mrt, oth_cap),\n",
    "        \"sim_bus_access\":  min(w_bus, oth_cap),\n",
    "        \"sim_amenities\":   min(w_am, oth_cap),\n",
    "        \"sim_school\":      min(w_sch, oth_cap),\n",
    "        \"sim_park_access\": min(w_park, 0.45),\n",
    "    }\n",
    "\n",
    "    # ---- normalize & aggregate ----\n",
    "    w = np.array(list(weights.values()), dtype=float)\n",
    "    v = np.array([feats_full.get(k, 0.0) for k in weights], dtype=float)\n",
    "    w /= (w.sum() if w.sum() > 0 else 1.0)\n",
    "    return float(np.dot(w, v))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_pairs(users_df: pd.DataFrame, items_df: pd.DataFrame, sim_df_pa: pd.DataFrame,\n",
    "                item_place_col: str = \"pa\", k_candidates: int = 30, rng_seed: int = 42) -> pd.DataFrame:\n",
    "    \"\"\"Create (user,item) samples with masked inputs and weak labels.\"\"\"\n",
    "    rows = []\n",
    "    rng = np.random.default_rng(rng_seed)\n",
    "\n",
    "    for _, u in users_df.iterrows():\n",
    "        uid = int(u[\"Buyer_ID\"])\n",
    "        budget = float(u[\"Budget_SGD\"])\n",
    "        cand = _banded_budget_sample(items_df, budget, k_total=k_candidates, seed=uid)\n",
    "\n",
    "        for _, it in cand.iterrows():\n",
    "            feats_full = {}\n",
    "            feats_full[\"sim_budget\"] = budget_affinity_score(u[\"Budget_SGD\"], it[\"resale_price\"])\n",
    "            feats_full |= compute_match_scores_gaussian(u, it)\n",
    "            feats_full |= compute_env_priority_scores(u, it)\n",
    "            feats_full[\"sim_location\"] = pa_location_similarity_with_sensitivity(\n",
    "                user_place=u.get(\"Preferred_Place\", None),\n",
    "                item_place=it.get(item_place_col, None),\n",
    "                sim_df=sim_df_pa,\n",
    "                distance_sensitivity=u.get(\"Priority_Distance_Proximity\", 0.0),\n",
    "                default_when_missing=0.0,\n",
    "                neutral=0.6\n",
    "            )\n",
    "\n",
    "            #label = _weighted_label_from_feats(feats_full, u.get(\"Priority_Distance_Proximity\", 0.0))\n",
    "            label = _weighted_label_from_feats(feats_full, user=u)\n",
    "            feats_in = _apply_feature_dropout(feats_full, u, it, sim_df_pa, item_place_col, rng, MASK_NEUTRALS)\n",
    "\n",
    "            row = {\"user_id\": uid, \"item_id\": it.get(\"item_id\", it.get(\"id\", _)), \"label\": label}\n",
    "            row.update(feats_in)\n",
    "            rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def grade_relevance_per_user(df: pd.DataFrame, label_col: str = \"label\",\n",
    "                             cuts=(0.4, 0.7, 0.9), out_col: str = \"rel\") -> pd.DataFrame:\n",
    "    \"\"\"Per-user quantile bucketing to 0/1/2/3 relevance.\"\"\"\n",
    "    df = df.copy()\n",
    "    rel_vals = np.zeros(len(df), dtype=int)\n",
    "    pos = 0\n",
    "    for _, g in df.groupby(\"user_id\", sort=False):\n",
    "        if len(g) < 4:\n",
    "            order = np.argsort(g[label_col].values)\n",
    "            grades = np.zeros(len(g), dtype=int)\n",
    "            if len(g) >= 2: grades[order[-1]] = 3\n",
    "            if len(g) >= 3: grades[order[-2]] = 2\n",
    "            if len(g) >= 4: grades[order[-3]] = 1\n",
    "        else:\n",
    "            q1, q2, q3 = g[label_col].quantile(list(cuts)).values\n",
    "            v = g[label_col].values\n",
    "            grades = np.where(v < q1, 0, np.where(v < q2, 1, np.where(v < q3, 2, 3)))\n",
    "        rel_vals[pos:pos+len(g)] = grades\n",
    "        pos += len(g)\n",
    "    df[out_col] = rel_vals\n",
    "    return df\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 7) Training & evaluation\n",
    "# =========================================================\n",
    "def train_ranker_intlabels(pairs_df: pd.DataFrame, feature_prefix: str = \"sim_\",\n",
    "                           test_size: float = 0.2, rng_seed: int = 123):\n",
    "    \"\"\"Train LGBMRanker (lambdarank) with discrete 0..3 labels; returns model, feature_cols, splits.\"\"\"\n",
    "    feature_cols = [c for c in pairs_df.columns if c.startswith(feature_prefix) or c.endswith(\"_missing\")]\n",
    "\n",
    "    # split by user (queries)\n",
    "    qids = pairs_df[\"user_id\"].unique()\n",
    "    q_train, q_valid = train_test_split(qids, test_size=test_size, random_state=rng_seed)\n",
    "    train_df = pairs_df[pairs_df[\"user_id\"].isin(q_train)].copy()\n",
    "    valid_df = pairs_df[pairs_df[\"user_id\"].isin(q_valid)].copy()\n",
    "\n",
    "    # discretize labels\n",
    "    train_df = grade_relevance_per_user(train_df, label_col=\"label\", cuts=(0.4, 0.7, 0.9), out_col=\"rel\")\n",
    "    valid_df = grade_relevance_per_user(valid_df, label_col=\"label\", cuts=(0.4, 0.7, 0.9), out_col=\"rel\")\n",
    "\n",
    "    X_train, y_train = train_df[feature_cols], train_df[\"rel\"].astype(int)\n",
    "    X_valid, y_valid = valid_df[feature_cols], valid_df[\"rel\"].astype(int)\n",
    "\n",
    "    train_group = [len(g) for _, g in train_df.groupby(\"user_id\")]\n",
    "    valid_group = [[len(g) for _, g in valid_df.groupby(\"user_id\")]]\n",
    "\n",
    "    ranker = lgb.LGBMRanker(\n",
    "        objective=\"lambdarank\",\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=63,\n",
    "        min_data_in_leaf=20,\n",
    "        n_estimators=800,\n",
    "        metric=\"ndcg\",\n",
    "        random_state=42,\n",
    "        verbose=-1\n",
    "    )\n",
    "    ranker.set_params(label_gain=[0, 1, 3, 7])\n",
    "\n",
    "    ranker.fit(\n",
    "        X_train, y_train,\n",
    "        group=train_group,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        eval_group=valid_group,\n",
    "        eval_at=[5, 10],\n",
    "        callbacks=[lgb.early_stopping(60), lgb.log_evaluation(50)]\n",
    "    )\n",
    "    return ranker, feature_cols, (train_df, valid_df)\n",
    "\n",
    "def _ndcg_at_k(labels, preds, k=10):\n",
    "    order = np.argsort(-preds)\n",
    "    gains = (2 ** labels[order] - 1)[:k]\n",
    "    discounts = np.log2(np.arange(2, k + 2))\n",
    "    dcg = np.sum(gains / discounts)\n",
    "    ideal_order = np.argsort(-labels)\n",
    "    ideal_gains = (2 ** labels[ideal_order] - 1)[:k]\n",
    "    idcg = np.sum(ideal_gains / discounts)\n",
    "    return float(dcg / idcg) if idcg > 0 else 0.0\n",
    "\n",
    "def mean_ndcg_by_user(df: pd.DataFrame, preds: np.ndarray, label_col: str = \"rel\", k=10) -> float:\n",
    "    df = df.copy(); df[\"pred\"] = preds\n",
    "    scores = [ _ndcg_at_k(g[label_col].values, g[\"pred\"].values, k) for _, g in df.groupby(\"user_id\") ]\n",
    "    return float(np.mean(scores)) if scores else 0.0\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 8) Main pipeline\n",
    "# =========================================================\n",
    "def main(users_path: str,\n",
    "         items_path: str,\n",
    "         pa_sim_path: str,\n",
    "         item_place_col: str = \"pa\",\n",
    "         out_pairs_path: str | None = None,\n",
    "         k_candidates: int = 30):\n",
    "    \"\"\"Load → build pairs → train → evaluate. Returns artifacts.\"\"\"\n",
    "    users_df = pd.read_excel(users_path)\n",
    "    items_df = pd.read_csv(items_path)\n",
    "    sim_df_pa = load_pa_similarity_matrix(pa_sim_path)\n",
    "\n",
    "    pairs_df = build_pairs(users_df, items_df, sim_df_pa,\n",
    "                           item_place_col=item_place_col,\n",
    "                           k_candidates=k_candidates, rng_seed=42)\n",
    "    if out_pairs_path:\n",
    "        pairs_df.to_csv(out_pairs_path, index=False)\n",
    "        print(f\"[INFO] Built pairs: {pairs_df.shape} → saved to {out_pairs_path}\")\n",
    "    else:\n",
    "        print(f\"[INFO] Built pairs: {pairs_df.shape}\")\n",
    "\n",
    "    model, feature_cols, (train_df, valid_df) = train_ranker_intlabels(pairs_df)\n",
    "\n",
    "    pred_valid = model.predict(valid_df[feature_cols])\n",
    "    ndcg10 = mean_ndcg_by_user(valid_df, pred_valid, label_col=\"rel\", k=10)\n",
    "    ndcg5  = mean_ndcg_by_user(valid_df, pred_valid, label_col=\"rel\", k=5)\n",
    "    print(f\"[RESULT] Mean NDCG@5={ndcg5:.4f}, NDCG@10={ndcg10:.4f}\")\n",
    "\n",
    "    return {\"model\": model, \"feature_cols\": feature_cols, \"pairs_df\": pairs_df,\n",
    "            \"train_df\": train_df, \"valid_df\": valid_df, \"ndcg5\": ndcg5, \"ndcg10\": ndcg10}\n",
    "\n",
    "\n",
    "# Example (comment out in library use)\n",
    "if __name__ == \"__main__\":\n",
    "    artifacts = main(\n",
    "        users_path=r\"D:\\SelfStudy\\NUS_ISS\\Practise_Moudle\\Recommdation_Model\\user_profiles_expanded_All_with_area_jitter.xlsx\",\n",
    "        items_path=r\"D:\\SelfStudy\\NUS_ISS\\Practise_Moudle\\Recommdation_Model\\item_matrix_merged.csv\",\n",
    "        pa_sim_path=r\"D:\\SelfStudy\\NUS_ISS\\Practise_Moudle\\Recommdation_Model\\PA_centroid_similarity_0_1.csv\",\n",
    "        item_place_col=\"Plan\",\n",
    "        out_pairs_path=r\"D:\\SelfStudy\\NUS_ISS\\Practise_Moudle\\Recommdation_Model\\train_pairs.csv\",\n",
    "        k_candidates=50\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25591ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239e066c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da830a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5924ee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Inference / Validation (Cleaned)\n",
    "#  - Neutral defaults & small utils\n",
    "#  - Budget-banded candidate retrieval\n",
    "#  - Feature computation (same as training, no masking)\n",
    "#  - Feature alignment to model columns\n",
    "#  - Optional location-sensitive re-ranking\n",
    "#  - Recommend & pretty-print\n",
    "# ============================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---- import the mapping funcs used at training time ----\n",
    "# from mappings import (\n",
    "#     budget_affinity_score, compute_match_scores_gaussian,\n",
    "#     compute_env_priority_scores, load_pa_similarity_matrix,\n",
    "#     pa_location_similarity_with_sensitivity\n",
    "# )\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 0) Small utilities\n",
    "# --------------------------------------------------------\n",
    "def _neutral_defaults() -> dict:\n",
    "    \"\"\"Neutral fallbacks when a feature is missing at inference.\"\"\"\n",
    "    return {\"sim_budget\": 0.8, \"sim_location\": 0.6, \"default\": 0.5}\n",
    "\n",
    "def _pick(row, *candidates, default=\"\"):\n",
    "    \"\"\"Pick the first present column from candidates.\"\"\"\n",
    "    for c in candidates:\n",
    "        if c in row and pd.notna(row[c]):\n",
    "            return row[c]\n",
    "    return default\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 1) Candidate retrieval (budget band ±20%)\n",
    "# --------------------------------------------------------\n",
    "def build_inference_candidates(items_df: pd.DataFrame,\n",
    "                               budget: float,\n",
    "                               k_candidates: int = 300,\n",
    "                               seed: int = 2025) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Retrieve k candidates within ±20% of budget; fallback to global sample.\n",
    "    \"\"\"\n",
    "    band = items_df[(items_df[\"resale_price\"] >= 0.80 * budget) &\n",
    "                    (items_df[\"resale_price\"] <= 1.20 * budget)]\n",
    "    if len(band) < k_candidates:\n",
    "        return items_df.sample(min(k_candidates, len(items_df)), random_state=seed)\n",
    "    return band.sample(k_candidates, random_state=seed)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 2) Feature computation (same sims as training; no masking)\n",
    "# --------------------------------------------------------\n",
    "def compute_features_for_user_items(user_row: pd.Series | dict,\n",
    "                                    items_df: pd.DataFrame,\n",
    "                                    sim_df_pa: pd.DataFrame,\n",
    "                                    item_place_col: str = \"Plan\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build the sim_* features on each (user, item) and keep rich item attributes\n",
    "    for explanation. No masking at inference.\n",
    "    \"\"\"\n",
    "    user = pd.Series(user_row) if not isinstance(user_row, pd.Series) else user_row\n",
    "    rows = []\n",
    "    neutr = _neutral_defaults()\n",
    "\n",
    "    for _, it in items_df.iterrows():\n",
    "        # --- sims used by model ---\n",
    "        feats = {}\n",
    "        feats[\"sim_budget\"] = budget_affinity_score(user.get(\"Budget_SGD\"), it[\"resale_price\"])\n",
    "        feats |= compute_match_scores_gaussian(user, it)     # sim_area, sim_floor, sim_newhome\n",
    "        feats |= compute_env_priority_scores(user, it)       # sim_park_access, sim_bus_access, sim_mrt_access, sim_amenities, sim_school\n",
    "        feats[\"sim_location\"] = pa_location_similarity_with_sensitivity(\n",
    "            user_place=user.get(\"Preferred_Place\", None),\n",
    "            item_place=it.get(item_place_col, None),\n",
    "            sim_df=sim_df_pa,\n",
    "            distance_sensitivity=user.get(\"Priority_Distance_Proximity\", None),\n",
    "            default_when_missing=0.0,\n",
    "            neutral=neutr[\"sim_location\"]\n",
    "        )\n",
    "\n",
    "        # --- carry item attributes for printing ---\n",
    "        block  = _pick(it, \"block\")\n",
    "        street = _pick(it, \"street_name\", \"street_nam\")\n",
    "        town   = _pick(it, \"town\")\n",
    "        pa     = _pick(it, item_place_col)\n",
    "        storey = _pick(it, \"storey_range\")\n",
    "        area   = _pick(it, \"floor_area_sqm\")\n",
    "        lease  = _pick(it, \"remaining_lease\", \"remaining_lease_mths\", \"remaining_lease_months\")\n",
    "\n",
    "        # nearby facility counts / flags\n",
    "        def _int(x): \n",
    "            return int(x) if pd.notna(x) else 0\n",
    "        rows.append({\n",
    "            \"item_id\": it.get(\"item_id\", it.get(\"id\", _)),\n",
    "            \"block\": block, \"street\": street, \"town\": town, \"pa\": pa,\n",
    "            \"storey_range\": storey,\n",
    "            \"floor_area_sqm\": area, \"remaining_lease\": lease,\n",
    "            \"resale_price\": it.get(\"resale_price\", np.nan),\n",
    "            \"mrt_200\": _int(it.get(\"mrt_200\", np.nan)),\n",
    "            \"mrt_500\": _int(it.get(\"mrt_500\", np.nan)),\n",
    "            \"bus_200\": _int(it.get(\"bus_200\", np.nan)),\n",
    "            \"bus_500\": _int(it.get(\"bus_500\", np.nan)),\n",
    "            \"MALL_500M\": _int(it.get(\"MALL_500M\", np.nan)),\n",
    "            \"HWKR_500M\": _int(it.get(\"HWKR_500M\", np.nan)),\n",
    "            \"HOSP_1K\": _int(it.get(\"HOSP_1K\", np.nan)),\n",
    "            \"GP_SCH_1K\": _int(it.get(\"GP_SCH_1K\", np.nan)),\n",
    "            \"GP_SCH_2K\": _int(it.get(\"GP_SCH_2K\", np.nan)),\n",
    "            \"PK_500M_IN\": _int(it.get(\"PK_500M_IN\", np.nan)),\n",
    "            # model features (no masking at inference)\n",
    "            **feats,\n",
    "            \"sim_budget_missing\": 0,\n",
    "            \"sim_location_missing\": 0,\n",
    "            \"sim_mrt_access_missing\": 0,\n",
    "            \"sim_bus_access_missing\": 0,\n",
    "            \"sim_amenities_missing\": 0,\n",
    "            \"sim_school_missing\": 0,\n",
    "            \"sim_area_missing\": 0,\n",
    "            \"sim_floor_missing\": 0,\n",
    "            \"sim_newhome_missing\": 0,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 3) Ensure feature alignment to model columns\n",
    "# --------------------------------------------------------\n",
    "def ensure_feature_alignment(df_feats: pd.DataFrame, feature_cols: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Guarantee df contains every model feature; fill sims with neutrals and flags with 0.\n",
    "    \"\"\"\n",
    "    neutr = _neutral_defaults()\n",
    "    for c in feature_cols:\n",
    "        if c not in df_feats.columns:\n",
    "            if c.endswith(\"_missing\"):\n",
    "                df_feats[c] = 0\n",
    "            elif c == \"sim_budget\":\n",
    "                df_feats[c] = neutr[\"sim_budget\"]\n",
    "            elif c == \"sim_location\":\n",
    "                df_feats[c] = neutr[\"sim_location\"]\n",
    "            else:\n",
    "                df_feats[c] = neutr[\"default\"]\n",
    "    return df_feats[feature_cols]\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 4) Optional: location-sensitive re-ranking (inference-time)\n",
    "# --------------------------------------------------------\n",
    "def rerank_with_location_sensitivity(df_scored: pd.DataFrame,\n",
    "                                     user_distance_sensitivity: float,\n",
    "                                     loc_col: str = \"sim_location\",\n",
    "                                     pred_col: str = \"score\",\n",
    "                                     out_col: str = \"score_final\",\n",
    "                                     hard_pref_place: str | None = None,\n",
    "                                     boost_threshold: float = 0.75,\n",
    "                                     boost_value: float = 0.05):\n",
    "    \"\"\"\n",
    "    Blend model score with location similarity:\n",
    "        score_final = (1 - alpha) * score + alpha * sim_location\n",
    "    where alpha grows with user sensitivity. Optionally boost near-preferred places.\n",
    "    \"\"\"\n",
    "    alpha = 0.3 + 0.5 * float(np.clip(user_distance_sensitivity or 0.0, 0.0, 1.0))\n",
    "    df = df_scored.copy()\n",
    "    df[out_col] = (1.0 - alpha) * df[pred_col] + alpha * df[loc_col]\n",
    "\n",
    "    if hard_pref_place is not None:\n",
    "        mask = df[loc_col] >= float(boost_threshold)\n",
    "        df.loc[mask, out_col] += float(boost_value)\n",
    "    return df.sort_values(out_col, ascending=False), alpha\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- Utility helpers ----------\n",
    "def _pick_metric(row: pd.Series, candidates: list[str]) -> float:\n",
    "    \"\"\"Try several possible column names; return the first valid float value.\"\"\"\n",
    "    for c in candidates:\n",
    "        if c in row and pd.notna(row[c]):\n",
    "            try:\n",
    "                return float(row[c])\n",
    "            except Exception:\n",
    "                pass\n",
    "    return np.nan\n",
    "\n",
    "def _should_block_top1(row: pd.Series,\n",
    "                       sim_threshold: float = 0.30,\n",
    "                       model_threshold: float = 1.0,\n",
    "                       na_counts_as_fail: bool = True) -> tuple[bool, dict]:\n",
    "    \"\"\"Return (should_block, value_dict).\"\"\"\n",
    "    budget = _pick_metric(row, [\"sim_budget\", \"budget\", \"budget_sim\"])\n",
    "    loc    = _pick_metric(row, [\"sim_location\", \"location\", \"loc\"])\n",
    "    area   = _pick_metric(row, [\"sim_area\", \"area\", \"area_sim\"])\n",
    "    model  = _pick_metric(row, [\"score\", \"Model\", \"model\", \"pred\", \"predict_score\"])\n",
    "\n",
    "    vals = {\"budget\": budget, \"loc\": loc, \"area\": area, \"model\": model}\n",
    "\n",
    "    if na_counts_as_fail and (np.isnan(model) or any(np.isnan(v) for v in [budget, loc, area])):\n",
    "        return True, vals\n",
    "\n",
    "    bad_sim   = any(v < sim_threshold for v in [budget, loc, area] if not np.isnan(v))\n",
    "    bad_model = (not np.isnan(model)) and (model < model_threshold)\n",
    "    return (bad_sim or bad_model), vals\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 5) Recommend & pretty-print\n",
    "# --------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# ---------- Helper functions ----------\n",
    "def _pick_metric(row: pd.Series, candidates: list[str]) -> float:\n",
    "    \"\"\"Try multiple candidate column names and return the first valid float value.\"\"\"\n",
    "    for c in candidates:\n",
    "        if c in row and pd.notna(row[c]):\n",
    "            try:\n",
    "                return float(row[c])\n",
    "            except Exception:\n",
    "                pass\n",
    "    return np.nan\n",
    "\n",
    "def _should_block_top1(row: pd.Series,\n",
    "                       sim_threshold: float = 0.30,\n",
    "                       model_threshold: float = 1.0,\n",
    "                       na_counts_as_fail: bool = True) -> tuple[bool, dict]:\n",
    "    \"\"\"Check whether Top-1 should be blocked based on similarity and model thresholds.\"\"\"\n",
    "    budget = _pick_metric(row, [\"sim_budget\", \"budget\", \"budget_sim\"])\n",
    "    loc    = _pick_metric(row, [\"sim_location\", \"location\", \"loc\"])\n",
    "    area   = _pick_metric(row, [\"sim_area\", \"area\", \"area_sim\"])\n",
    "    model  = _pick_metric(row, [\"score\", \"Model\", \"model\", \"pred\", \"predict_score\"])\n",
    "    vals = {\"budget\": budget, \"loc\": loc, \"area\": area, \"model\": model}\n",
    "\n",
    "    # If NaNs exist, optionally count as failure\n",
    "    if na_counts_as_fail and (np.isnan(model) or any(np.isnan(v) for v in [budget, loc, area])):\n",
    "        return True, vals\n",
    "\n",
    "    bad_sim   = any(v < sim_threshold for v in [budget, loc, area] if not np.isnan(v))\n",
    "    bad_model = (not np.isnan(model)) and (model < model_threshold)\n",
    "    return (bad_sim or bad_model), vals\n",
    "\n",
    "\n",
    "# ---------- Main function ----------\n",
    "def recommend_for_user(model,\n",
    "                       feature_cols: list[str],\n",
    "                       user_input: dict,\n",
    "                       items_df: pd.DataFrame,\n",
    "                       sim_df_pa: pd.DataFrame,\n",
    "                       item_place_col: str = \"Plan\",\n",
    "                       topn: int = 10,\n",
    "                       k_candidates: int = 300,\n",
    "                       seed: int = 2025,\n",
    "                       use_location_rerank: bool = True,\n",
    "                       sim_threshold=0.4,\n",
    "                       model_threshold=1.0,\n",
    "                       warn_threshold: float = 0.30) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Full inference pipeline:\n",
    "      1. Retrieve candidate properties\n",
    "      2. Compute user-item features\n",
    "      3. Predict ranking scores\n",
    "      4. (Optional) location-sensitive re-ranking\n",
    "      5. Produce a structured JSON-like payload for LLMs (and print summary)\n",
    "    \"\"\"\n",
    "    # 1) Candidate retrieval\n",
    "    budget = float(user_input[\"Budget_SGD\"])\n",
    "    cand = build_inference_candidates(items_df, budget, k_candidates=k_candidates, seed=seed)\n",
    "\n",
    "    # 2) Feature computation\n",
    "    feats_df = compute_features_for_user_items(user_input, cand, sim_df_pa, item_place_col=item_place_col)\n",
    "\n",
    "    # 3) Model prediction\n",
    "    X = ensure_feature_alignment(feats_df.copy(), feature_cols)\n",
    "    feats_df[\"score\"] = model.predict(X)\n",
    "\n",
    "    # 4) Optional location re-ranking\n",
    "    if use_location_rerank:\n",
    "        user_p = float(user_input.get(\"Priority_Distance_Proximity\", 0.0))\n",
    "        pref_place = user_input.get(\"Preferred_Place\", None)\n",
    "        feats_df, alpha_used = rerank_with_location_sensitivity(\n",
    "            feats_df, user_distance_sensitivity=user_p,\n",
    "            loc_col=\"sim_location\", pred_col=\"score\", out_col=\"score_final\",\n",
    "            hard_pref_place=pref_place, boost_threshold=0.75, boost_value=0.05\n",
    "        )\n",
    "        rank_col = \"score_final\"\n",
    "    else:\n",
    "        alpha_used = None\n",
    "        rank_col = \"score\"\n",
    "\n",
    "    recs = feats_df.sort_values(rank_col, ascending=False).head(topn).copy()\n",
    "\n",
    "    # ---------- Construct base structured payload ----------\n",
    "    user_summary = {\n",
    "        k: user_input.get(k, None) for k in [\n",
    "            \"Budget_SGD\",\"Preferred_Flat_Area\",\"Preferred_Place\",\"Floor_Preference\",\"NewHome_Preference\",\n",
    "            \"Priority_MRT_Access\",\"Priority_Bus_Access\",\"Priority_Amenities\",\n",
    "            \"Priority_School_Proximity\",\"Priority_Park_Access\",\"Priority_Distance_Proximity\"\n",
    "        ]\n",
    "    }\n",
    "    result_payload = {\n",
    "        \"status\": None,\n",
    "        \"meta\": {\n",
    "            \"topn\": int(topn),\n",
    "            \"use_location_rerank\": bool(use_location_rerank),\n",
    "            \"location_alpha\": float(alpha_used) if alpha_used is not None else None,\n",
    "            \"thresholds\": {\n",
    "                \"block_sim_threshold\": float(sim_threshold),\n",
    "                \"block_model_threshold\": float(model_threshold),\n",
    "                \"warn_threshold\": float(warn_threshold),\n",
    "            },\n",
    "            \"user\": user_summary,\n",
    "        },\n",
    "        \"fail_reasons\": None,   # Explanation if blocked or no result\n",
    "        \"items\": []        # Structured property results\n",
    "    }\n",
    "\n",
    "    # ---------- Step 1: No candidates ----------\n",
    "    if recs.empty:\n",
    "        result_payload[\"status\"] = \"no_result\"\n",
    "        result_payload[\"fail_reasons\"] = {\n",
    "            \"type\": \"no_candidates_after_rerank\",\n",
    "            \"message\": \"No suitable properties found under current preferences. Try increasing budget or relaxing filters.\"\n",
    "        }\n",
    "        print(json.dumps(result_payload, ensure_ascii=False, indent=2))\n",
    "        return recs\n",
    "\n",
    "    # ---------- Step 2: Top-1 fails quality threshold ----------\n",
    "    need_block, vals = _should_block_top1(recs.iloc[0],\n",
    "                                          sim_threshold=sim_threshold,\n",
    "                                          model_threshold=model_threshold)\n",
    "    if need_block:\n",
    "        result_payload[\"status\"] = \"blocked_top1\"\n",
    "        result_payload[\"reasons\"] = {\n",
    "            \"type\": \"top1_fails_quality_threshold\",\n",
    "            \"triggered_values\": {k: (None if np.isnan(v) else float(v)) for k, v in vals.items()},\n",
    "            \"required\": {\"sim_min\": float(sim_threshold), \"model_min\": float(model_threshold)},\n",
    "            \"message\": \"Top-1 fails quality threshold; consider increasing budget, expanding preferred location, or loosening size/type preference.\"\n",
    "        }\n",
    "        print(json.dumps(result_payload, ensure_ascii=False, indent=2))\n",
    "        return recs.head(0)\n",
    "\n",
    "    # ---------- Step 3: Build structured items ----------\n",
    "    def _safe_get(obj, name, default=None):\n",
    "        try:\n",
    "            v = getattr(obj, name)\n",
    "            return v if v is not None else default\n",
    "        except Exception:\n",
    "            return default\n",
    "\n",
    "    sim_fields = [\n",
    "        \"sim_budget\",\"sim_location\",\"sim_area\",\n",
    "        \"sim_mrt_access\",\"sim_bus_access\",\"sim_amenities\",\"sim_school\",\"sim_floor\",\"sim_newhome\"\n",
    "    ]\n",
    "\n",
    "    # Small helper to pack nearby-facilities info\n",
    "    nearby_pack = lambda r: {\n",
    "        \"mrt_200\": int(_safe_get(r, \"mrt_200\", 0) or 0),\n",
    "        \"mrt_500\": int(_safe_get(r, \"mrt_500\", 0) or 0),\n",
    "        \"bus_200\": int(_safe_get(r, \"bus_200\", 0) or 0),\n",
    "        \"bus_500\": int(_safe_get(r, \"bus_500\", 0) or 0),\n",
    "        \"hawker_500m\": int(_safe_get(r, \"HWKR_500M\", 0) or 0),\n",
    "        \"mall_500m\": int(_safe_get(r, \"MALL_500M\", 0) or 0),\n",
    "        \"school_1km\": int(_safe_get(r, \"GP_SCH_1K\", 0) or 0),\n",
    "        \"school_2km\": int(_safe_get(r, \"GP_SCH_2K\", 0) or 0),\n",
    "        \"park_500m_in\": int(_safe_get(r, \"PK_500M_IN\", 0) or 0),\n",
    "    }\n",
    "\n",
    "    items_struct = []\n",
    "    for i, r in enumerate(recs.itertuples(index=False), 1):\n",
    "        addr = \" \".join(str(x) for x in [_safe_get(r, \"block\", \"\"), _safe_get(r, \"street\", \"\")] if str(x))\n",
    "        loc  = _safe_get(r, \"pa\", \"\") or _safe_get(r, \"town\", \"\")\n",
    "\n",
    "        # Collect similarity scores\n",
    "        sims = {}\n",
    "        for s in sim_fields:\n",
    "            if s in recs.columns:\n",
    "                val = getattr(r, s, np.nan)\n",
    "                sims[s.replace(\"sim_\", \"\")] = None if pd.isna(val) else float(val)\n",
    "\n",
    "        base_score  = _safe_get(r, \"score\", np.nan)\n",
    "        final_score = _safe_get(r, rank_col, np.nan)\n",
    "\n",
    "        # Identify features below warn threshold\n",
    "        warn_keys = [\"mrt_access\", \"bus_access\", \"amenities\", \"school\", \"floor\"]\n",
    "        low_flags = [k for k in warn_keys if (k in sims and sims[k] is not None and sims[k] < float(warn_threshold))]\n",
    "\n",
    "        item_entry = {\n",
    "            \"rank\": i,\n",
    "            \"attributes\": {\n",
    "                \"address\": addr,\n",
    "                \"location\": loc,\n",
    "                \"flat_type\": _safe_get(r, \"flat_type\", \"\"),\n",
    "                \"storey_range\": _safe_get(r, \"storey_range\", \"\"),\n",
    "                \"floor_area_sqm\": _safe_get(r, \"floor_area_sqm\", None),\n",
    "                \"remaining_lease\": _safe_get(r, \"remaining_lease\", None),\n",
    "                \"resale_price\": None if pd.isna(_safe_get(r, \"resale_price\", np.nan)) else float(_safe_get(r, \"resale_price\", np.nan)),\n",
    "                \"nearby\": nearby_pack(r),\n",
    "            },\n",
    "            \"scores\": {\n",
    "                \"model\": None if pd.isna(base_score) else float(base_score),\n",
    "                \"final\": None if pd.isna(final_score) else float(final_score),\n",
    "                \"loc\": None if pd.isna(_safe_get(r, \"sim_location\", np.nan)) else float(_safe_get(r, \"sim_location\", np.nan)),\n",
    "                \"sims\": sims,\n",
    "                \"low_flags\": low_flags,  # which features fall below warn_threshold\n",
    "            }\n",
    "        }\n",
    "        items_struct.append(item_entry)\n",
    "\n",
    "    result_payload[\"status\"] = \"ok\"\n",
    "    result_payload[\"items\"] = items_struct\n",
    "\n",
    "    # ---------- Print structured payload and human-readable preview ----------\n",
    "    print(json.dumps(result_payload, ensure_ascii=False, indent=2))\n",
    "\n",
    "    print(\"\\n=== Human-readable preview ===\")\n",
    "    print(f\"User: budget={user_summary['Budget_SGD']}, place={user_summary['Preferred_Place']}, \"\n",
    "          f\"area={user_summary['Preferred_Flat_Area']}, floor_pref={user_summary['Floor_Preference']}, \"\n",
    "          f\"newhome_pref={user_summary['NewHome_Preference']}\")\n",
    "    if use_location_rerank:\n",
    "        print(f\"location alpha: {alpha_used:.2f}\")\n",
    "    print(f\"TOP-{topn} recommendations\")\n",
    "\n",
    "    for item in items_struct:\n",
    "        a, s = item[\"attributes\"], item[\"scores\"]\n",
    "        print(f\"\\n#{item['rank']} | {a['address']} [{a['location']}]\")\n",
    "        print(f\"   Type/Floor: {a['flat_type']} / {a['storey_range']}\")\n",
    "        if a[\"floor_area_sqm\"] or a[\"remaining_lease\"]:\n",
    "            print(f\"   Area: {a['floor_area_sqm']} sqm   Lease: {a['remaining_lease']}\")\n",
    "        print(f\"   Price: ${0 if a['resale_price'] is None else a['resale_price']:,.0f} | \"\n",
    "              f\"Model: {s['model']:.4f} | Loc: {0 if s['loc'] is None else s['loc']:.2f} | Final: {s['final']:.4f}\")\n",
    "\n",
    "        eval_keys = [\"mrt_access\",\"bus_access\",\"amenities\",\"school\",\"floor\"]\n",
    "        eval_pairs = []\n",
    "        for k in eval_keys:\n",
    "            val = s[\"sims\"].get(k)\n",
    "            if val is None:\n",
    "                eval_pairs.append(f\"{k}: NA\")\n",
    "            else:\n",
    "                eval_pairs.append(f\"{k}: {val:.2f}\")\n",
    "\n",
    "        print(\"   match eval → \" + \" | \".join(eval_pairs))\n",
    "        if s[\"low_flags\"]:\n",
    "            print(f\"   ⚠ unmet features (sim<{warn_threshold:.2f}): {', '.join(s['low_flags'])}\")\n",
    "\n",
    "    # Return DataFrame (you can change to 'return result_payload' if you want to return structured data directly)\n",
    "    return recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9778a2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model saved to: D:\\SelfStudy\\NUS_ISS\\Practise_Moudle\\Recommdation_Model\\Deployment_Coding\\ranker_lgbm.joblib\n"
     ]
    }
   ],
   "source": [
    "if artifacts is not None:\n",
    "    model = artifacts[\"model\"]\n",
    "    feature_cols = artifacts[\"feature_cols\"]\n",
    "\n",
    "    # --- Save model to deployment path for future backend loading ---\n",
    "    deploy_path = r\"D:\\SelfStudy\\NUS_ISS\\Practise_Moudle\\Recommdation_Model\\Deployment_Coding\\ranker_lgbm.joblib\"\n",
    "    try:\n",
    "        import joblib\n",
    "        joblib.dump(model, deploy_path)\n",
    "        print(f\"[INFO] Model saved to: {deploy_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARNING] Failed to save model to {deploy_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2224c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5f5dca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7f51ed77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status\": \"ok\",\n",
      "  \"meta\": {\n",
      "    \"topn\": 10,\n",
      "    \"use_location_rerank\": true,\n",
      "    \"location_alpha\": 0.7,\n",
      "    \"thresholds\": {\n",
      "      \"block_sim_threshold\": 0.4,\n",
      "      \"block_model_threshold\": 1.0,\n",
      "      \"warn_threshold\": 0.3\n",
      "    },\n",
      "    \"user\": {\n",
      "      \"Budget_SGD\": 1100000,\n",
      "      \"Preferred_Flat_Area\": 100,\n",
      "      \"Preferred_Place\": \"JURONG EAST\",\n",
      "      \"Floor_Preference\": 2,\n",
      "      \"NewHome_Preference\": 0.5,\n",
      "      \"Priority_MRT_Access\": 5,\n",
      "      \"Priority_Bus_Access\": 5,\n",
      "      \"Priority_Amenities\": 5,\n",
      "      \"Priority_School_Proximity\": 5,\n",
      "      \"Priority_Park_Access\": 5,\n",
      "      \"Priority_Distance_Proximity\": 0.8\n",
      "    }\n",
      "  },\n",
      "  \"reasons\": null,\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"rank\": 1,\n",
      "      \"attributes\": {\n",
      "        \"address\": \"459 CLEMENTI AVE 3\",\n",
      "        \"location\": \"CLEMENTI\",\n",
      "        \"flat_type\": \"\",\n",
      "        \"storey_range\": \"16 TO 18\",\n",
      "        \"floor_area_sqm\": 110.0,\n",
      "        \"remaining_lease\": \"77 years 01 month\",\n",
      "        \"resale_price\": 1020000.0,\n",
      "        \"nearby\": {\n",
      "          \"mrt_200\": 0,\n",
      "          \"mrt_500\": 1,\n",
      "          \"bus_200\": 5,\n",
      "          \"bus_500\": 16,\n",
      "          \"hawker_500m\": 1,\n",
      "          \"mall_500m\": 3,\n",
      "          \"school_1km\": 0,\n",
      "          \"school_2km\": 1,\n",
      "          \"park_500m_in\": 0\n",
      "        }\n",
      "      },\n",
      "      \"scores\": {\n",
      "        \"model\": 4.787092352168117,\n",
      "        \"final\": 2.0632191854124837,\n",
      "        \"loc\": 0.8244163996600694,\n",
      "        \"sims\": {\n",
      "          \"budget\": 0.735356931277276,\n",
      "          \"location\": 0.8244163996600694,\n",
      "          \"area\": 0.7066482778577162,\n",
      "          \"mrt_access\": 0.27299497329154265,\n",
      "          \"bus_access\": 0.9141503634023178,\n",
      "          \"amenities\": 0.714097581703064,\n",
      "          \"school\": 0.1864829797480872,\n",
      "          \"floor\": 0.9231163463866359,\n",
      "          \"newhome\": 1.0\n",
      "        },\n",
      "        \"low_flags\": [\n",
      "          \"mrt_access\",\n",
      "          \"school\"\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 2,\n",
      "      \"attributes\": {\n",
      "        \"address\": \"440C CLEMENTI AVE 3\",\n",
      "        \"location\": \"CLEMENTI\",\n",
      "        \"flat_type\": \"\",\n",
      "        \"storey_range\": \"13 TO 15\",\n",
      "        \"floor_area_sqm\": 94.0,\n",
      "        \"remaining_lease\": \"94 years 05 months\",\n",
      "        \"resale_price\": 978000.0,\n",
      "        \"nearby\": {\n",
      "          \"mrt_200\": 0,\n",
      "          \"mrt_500\": 1,\n",
      "          \"bus_200\": 4,\n",
      "          \"bus_500\": 16,\n",
      "          \"hawker_500m\": 1,\n",
      "          \"mall_500m\": 2,\n",
      "          \"school_1km\": 1,\n",
      "          \"school_2km\": 1,\n",
      "          \"park_500m_in\": 0\n",
      "        }\n",
      "      },\n",
      "      \"scores\": {\n",
      "        \"model\": 4.07744674537795,\n",
      "        \"final\": 1.8503255033754338,\n",
      "        \"loc\": 0.8244163996600694,\n",
      "        \"sims\": {\n",
      "          \"budget\": 0.451346874713448,\n",
      "          \"location\": 0.8244163996600694,\n",
      "          \"area\": 0.8824969025845955,\n",
      "          \"mrt_access\": 0.27299497329154265,\n",
      "          \"bus_access\": 0.9014306431848597,\n",
      "          \"amenities\": 0.6274643128502966,\n",
      "          \"school\": 0.5227601725617476,\n",
      "          \"floor\": 1.0,\n",
      "          \"newhome\": 1.0\n",
      "        },\n",
      "        \"low_flags\": [\n",
      "          \"mrt_access\"\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 3,\n",
      "      \"attributes\": {\n",
      "        \"address\": \"2 TOH YI DR\",\n",
      "        \"location\": \"BUKIT TIMAH\",\n",
      "        \"flat_type\": \"\",\n",
      "        \"storey_range\": \"13 TO 15\",\n",
      "        \"floor_area_sqm\": 150.0,\n",
      "        \"remaining_lease\": \"68 years 05 months\",\n",
      "        \"resale_price\": 1038000.0,\n",
      "        \"nearby\": {\n",
      "          \"mrt_200\": 0,\n",
      "          \"mrt_500\": 1,\n",
      "          \"bus_200\": 4,\n",
      "          \"bus_500\": 12,\n",
      "          \"hawker_500m\": 2,\n",
      "          \"mall_500m\": 3,\n",
      "          \"school_1km\": 1,\n",
      "          \"school_2km\": 1,\n",
      "          \"park_500m_in\": 1\n",
      "        }\n",
      "      },\n",
      "      \"scores\": {\n",
      "        \"model\": 4.228770032819926,\n",
      "        \"final\": 1.7547051401294758,\n",
      "        \"loc\": 0.694391614690711,\n",
      "        \"sims\": {\n",
      "          \"budget\": 0.8454075443048926,\n",
      "          \"location\": 0.694391614690711,\n",
      "          \"area\": 0.00016985667656141068,\n",
      "          \"mrt_access\": 0.27299497329154265,\n",
      "          \"bus_access\": 0.8995696560817034,\n",
      "          \"amenities\": 0.7672201039211471,\n",
      "          \"school\": 0.5227601725617476,\n",
      "          \"floor\": 1.0,\n",
      "          \"newhome\": 1.0\n",
      "        },\n",
      "        \"low_flags\": [\n",
      "          \"mrt_access\"\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 4,\n",
      "      \"attributes\": {\n",
      "        \"address\": \"311C CLEMENTI AVE 4\",\n",
      "        \"location\": \"CLEMENTI\",\n",
      "        \"flat_type\": \"\",\n",
      "        \"storey_range\": \"37 TO 39\",\n",
      "        \"floor_area_sqm\": 105.0,\n",
      "        \"remaining_lease\": \"91 years 02 months\",\n",
      "        \"resale_price\": 1150000.0,\n",
      "        \"nearby\": {\n",
      "          \"mrt_200\": 0,\n",
      "          \"mrt_500\": 0,\n",
      "          \"bus_200\": 1,\n",
      "          \"bus_500\": 13,\n",
      "          \"hawker_500m\": 0,\n",
      "          \"mall_500m\": 0,\n",
      "          \"school_1km\": 1,\n",
      "          \"school_2km\": 1,\n",
      "          \"park_500m_in\": 0\n",
      "        }\n",
      "      },\n",
      "      \"scores\": {\n",
      "        \"model\": 3.587638433633132,\n",
      "        \"final\": 1.7033830098519884,\n",
      "        \"loc\": 0.8244163996600694,\n",
      "        \"sims\": {\n",
      "          \"budget\": 0.8987251612306125,\n",
      "          \"location\": 0.8244163996600694,\n",
      "          \"area\": 0.9168553557320289,\n",
      "          \"mrt_access\": 0.075,\n",
      "          \"bus_access\": 0.6688172270810254,\n",
      "          \"amenities\": 0.075,\n",
      "          \"school\": 0.5227601725617476,\n",
      "          \"floor\": 0.04393693362340742,\n",
      "          \"newhome\": 1.0\n",
      "        },\n",
      "        \"low_flags\": [\n",
      "          \"mrt_access\",\n",
      "          \"amenities\",\n",
      "          \"floor\"\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 5,\n",
      "      \"attributes\": {\n",
      "        \"address\": \"425 CLEMENTI AVE 1\",\n",
      "        \"location\": \"CLEMENTI\",\n",
      "        \"flat_type\": \"\",\n",
      "        \"storey_range\": \"28 TO 30\",\n",
      "        \"floor_area_sqm\": 100.0,\n",
      "        \"remaining_lease\": \"88 years 02 months\",\n",
      "        \"resale_price\": 1006666.0,\n",
      "        \"nearby\": {\n",
      "          \"mrt_200\": 0,\n",
      "          \"mrt_500\": 0,\n",
      "          \"bus_200\": 2,\n",
      "          \"bus_500\": 11,\n",
      "          \"hawker_500m\": 0,\n",
      "          \"mall_500m\": 0,\n",
      "          \"school_1km\": 0,\n",
      "          \"school_2km\": 3,\n",
      "          \"park_500m_in\": 0\n",
      "        }\n",
      "      },\n",
      "      \"scores\": {\n",
      "        \"model\": 3.392437640096425,\n",
      "        \"final\": 1.6448227717909762,\n",
      "        \"loc\": 0.8244163996600694,\n",
      "        \"sims\": {\n",
      "          \"budget\": 0.6455281640509275,\n",
      "          \"location\": 0.8244163996600694,\n",
      "          \"area\": 1.0,\n",
      "          \"mrt_access\": 0.075,\n",
      "          \"bus_access\": 0.8071133934971592,\n",
      "          \"amenities\": 0.075,\n",
      "          \"school\": 0.2951131212912782,\n",
      "          \"floor\": 0.23574607655586347,\n",
      "          \"newhome\": 1.0\n",
      "        },\n",
      "        \"low_flags\": [\n",
      "          \"mrt_access\",\n",
      "          \"amenities\",\n",
      "          \"school\",\n",
      "          \"floor\"\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 6,\n",
      "      \"attributes\": {\n",
      "        \"address\": \"440C CLEMENTI AVE 3\",\n",
      "        \"location\": \"CLEMENTI\",\n",
      "        \"flat_type\": \"\",\n",
      "        \"storey_range\": \"34 TO 36\",\n",
      "        \"floor_area_sqm\": 112.0,\n",
      "        \"remaining_lease\": \"95 years 04 months\",\n",
      "        \"resale_price\": 1180000.0,\n",
      "        \"nearby\": {\n",
      "          \"mrt_200\": 0,\n",
      "          \"mrt_500\": 1,\n",
      "          \"bus_200\": 4,\n",
      "          \"bus_500\": 16,\n",
      "          \"hawker_500m\": 1,\n",
      "          \"mall_500m\": 2,\n",
      "          \"school_1km\": 1,\n",
      "          \"school_2km\": 1,\n",
      "          \"park_500m_in\": 0\n",
      "        }\n",
      "      },\n",
      "      \"scores\": {\n",
      "        \"model\": 3.2369310970448573,\n",
      "        \"final\": 1.598170808875506,\n",
      "        \"loc\": 0.8244163996600694,\n",
      "        \"sims\": {\n",
      "          \"budget\": 0.7884928016133167,\n",
      "          \"location\": 0.8244163996600694,\n",
      "          \"area\": 0.6065306597126334,\n",
      "          \"mrt_access\": 0.27299497329154265,\n",
      "          \"bus_access\": 0.9014306431848597,\n",
      "          \"amenities\": 0.6274643128502966,\n",
      "          \"school\": 0.5227601725617476,\n",
      "          \"floor\": 0.1353352832366127,\n",
      "          \"newhome\": 1.0\n",
      "        },\n",
      "        \"low_flags\": [\n",
      "          \"mrt_access\",\n",
      "          \"floor\"\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 7,\n",
      "      \"attributes\": {\n",
      "        \"address\": \"1C CANTONMENT RD\",\n",
      "        \"location\": \"OUTRAM\",\n",
      "        \"flat_type\": \"\",\n",
      "        \"storey_range\": \"19 TO 21\",\n",
      "        \"floor_area_sqm\": 93.0,\n",
      "        \"remaining_lease\": \"86 years 08 months\",\n",
      "        \"resale_price\": 1155000.0,\n",
      "        \"nearby\": {\n",
      "          \"mrt_200\": 0,\n",
      "          \"mrt_500\": 3,\n",
      "          \"bus_200\": 2,\n",
      "          \"bus_500\": 22,\n",
      "          \"hawker_500m\": 2,\n",
      "          \"mall_500m\": 3,\n",
      "          \"school_1km\": 0,\n",
      "          \"school_2km\": 0,\n",
      "          \"park_500m_in\": 0\n",
      "        }\n",
      "      },\n",
      "      \"scores\": {\n",
      "        \"model\": 3.8004704467203867,\n",
      "        \"final\": 1.485750874230963,\n",
      "        \"loc\": 0.4937282003069242,\n",
      "        \"sims\": {\n",
      "          \"budget\": 0.8824969025845953,\n",
      "          \"location\": 0.4937282003069242,\n",
      "          \"area\": 0.8435476490642344,\n",
      "          \"mrt_access\": 0.3505916119732671,\n",
      "          \"bus_access\": 0.8105492654317514,\n",
      "          \"amenities\": 0.7672201039211471,\n",
      "          \"school\": 0.075,\n",
      "          \"floor\": 0.726149037073691,\n",
      "          \"newhome\": 1.0\n",
      "        },\n",
      "        \"low_flags\": [\n",
      "          \"school\"\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 8,\n",
      "      \"attributes\": {\n",
      "        \"address\": \"1A CANTONMENT RD\",\n",
      "        \"location\": \"OUTRAM\",\n",
      "        \"flat_type\": \"\",\n",
      "        \"storey_range\": \"22 TO 24\",\n",
      "        \"floor_area_sqm\": 107.0,\n",
      "        \"remaining_lease\": \"88 years 05 months\",\n",
      "        \"resale_price\": 1100000.0,\n",
      "        \"nearby\": {\n",
      "          \"mrt_200\": 0,\n",
      "          \"mrt_500\": 4,\n",
      "          \"bus_200\": 2,\n",
      "          \"bus_500\": 21,\n",
      "          \"hawker_500m\": 1,\n",
      "          \"mall_500m\": 2,\n",
      "          \"school_1km\": 0,\n",
      "          \"school_2km\": 0,\n",
      "          \"park_500m_in\": 0\n",
      "        }\n",
      "      },\n",
      "      \"scores\": {\n",
      "        \"model\": 3.7433319236619815,\n",
      "        \"final\": 1.4686093173134416,\n",
      "        \"loc\": 0.4937282003069242,\n",
      "        \"sims\": {\n",
      "          \"budget\": 0.9965337989703691,\n",
      "          \"location\": 0.4937282003069242,\n",
      "          \"area\": 0.8435476490642344,\n",
      "          \"mrt_access\": 0.35600157166944435,\n",
      "          \"bus_access\": 0.8105282607278445,\n",
      "          \"amenities\": 0.6274643128502966,\n",
      "          \"school\": 0.075,\n",
      "          \"floor\": 0.6065306597126334,\n",
      "          \"newhome\": 1.0\n",
      "        },\n",
      "        \"low_flags\": [\n",
      "          \"school\"\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 9,\n",
      "      \"attributes\": {\n",
      "        \"address\": \"138B LOR 1A TOA PAYOH\",\n",
      "        \"location\": \"TOA PAYOH\",\n",
      "        \"flat_type\": \"\",\n",
      "        \"storey_range\": \"13 TO 15\",\n",
      "        \"floor_area_sqm\": 110.0,\n",
      "        \"remaining_lease\": \"86 years 07 months\",\n",
      "        \"resale_price\": 1068888.0,\n",
      "        \"nearby\": {\n",
      "          \"mrt_200\": 0,\n",
      "          \"mrt_500\": 2,\n",
      "          \"bus_200\": 2,\n",
      "          \"bus_500\": 21,\n",
      "          \"hawker_500m\": 1,\n",
      "          \"mall_500m\": 0,\n",
      "          \"school_1km\": 1,\n",
      "          \"school_2km\": 3,\n",
      "          \"park_500m_in\": 0\n",
      "        }\n",
      "      },\n",
      "      \"scores\": {\n",
      "        \"model\": 3.755949373670275,\n",
      "        \"final\": 1.4439090040368714,\n",
      "        \"loc\": 0.4530345599082698,\n",
      "        \"sims\": {\n",
      "          \"budget\": 0.9742215741053858,\n",
      "          \"location\": 0.4530345599082698,\n",
      "          \"area\": 0.7066482778577162,\n",
      "          \"mrt_access\": 0.33262991323466645,\n",
      "          \"bus_access\": 0.8105282607278445,\n",
      "          \"amenities\": 0.1819756229443255,\n",
      "          \"school\": 0.6313903141049386,\n",
      "          \"floor\": 1.0,\n",
      "          \"newhome\": 1.0\n",
      "        },\n",
      "        \"low_flags\": [\n",
      "          \"amenities\"\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 10,\n",
      "      \"attributes\": {\n",
      "        \"address\": \"20 JLN MEMBINA\",\n",
      "        \"location\": \"BUKIT MERAH\",\n",
      "        \"flat_type\": \"\",\n",
      "        \"storey_range\": \"16 TO 18\",\n",
      "        \"floor_area_sqm\": 110.0,\n",
      "        \"remaining_lease\": \"80 years\",\n",
      "        \"resale_price\": 1000000.0,\n",
      "        \"nearby\": {\n",
      "          \"mrt_200\": 1,\n",
      "          \"mrt_500\": 1,\n",
      "          \"bus_200\": 2,\n",
      "          \"bus_500\": 13,\n",
      "          \"hawker_500m\": 3,\n",
      "          \"mall_500m\": 1,\n",
      "          \"school_1km\": 0,\n",
      "          \"school_2km\": 0,\n",
      "          \"park_500m_in\": 0\n",
      "        }\n",
      "      },\n",
      "      \"scores\": {\n",
      "        \"model\": 3.3605781465377667,\n",
      "        \"final\": 1.3863821812475265,\n",
      "        \"loc\": 0.5402981961231379,\n",
      "        \"sims\": {\n",
      "          \"budget\": 0.5996385616804464,\n",
      "          \"location\": 0.5402981961231379,\n",
      "          \"area\": 0.7066482778577162,\n",
      "          \"mrt_access\": 0.7629716461241287,\n",
      "          \"bus_access\": 0.8090289465504796,\n",
      "          \"amenities\": 0.5491105909862993,\n",
      "          \"school\": 0.075,\n",
      "          \"floor\": 0.9231163463866359,\n",
      "          \"newhome\": 1.0\n",
      "        },\n",
      "        \"low_flags\": [\n",
      "          \"school\"\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "=== Human-readable preview ===\n",
      "User: budget=1100000, place=JURONG EAST, area=100, floor_pref=2, newhome_pref=0.5\n",
      "location alpha: 0.70\n",
      "TOP-10 recommendations\n",
      "\n",
      "#1 | 459 CLEMENTI AVE 3 [CLEMENTI]\n",
      "   Type/Floor:  / 16 TO 18\n",
      "   Area: 110.0 sqm   Lease: 77 years 01 month\n",
      "   Price: $1,020,000 | Model: 4.7871 | Loc: 0.82 | Final: 2.0632\n",
      "   match eval → mrt_access: 0.27 | bus_access: 0.91 | amenities: 0.71 | school: 0.19 | floor: 0.92\n",
      "   ⚠ unmet features (sim<0.30): mrt_access, school\n",
      "\n",
      "#2 | 440C CLEMENTI AVE 3 [CLEMENTI]\n",
      "   Type/Floor:  / 13 TO 15\n",
      "   Area: 94.0 sqm   Lease: 94 years 05 months\n",
      "   Price: $978,000 | Model: 4.0774 | Loc: 0.82 | Final: 1.8503\n",
      "   match eval → mrt_access: 0.27 | bus_access: 0.90 | amenities: 0.63 | school: 0.52 | floor: 1.00\n",
      "   ⚠ unmet features (sim<0.30): mrt_access\n",
      "\n",
      "#3 | 2 TOH YI DR [BUKIT TIMAH]\n",
      "   Type/Floor:  / 13 TO 15\n",
      "   Area: 150.0 sqm   Lease: 68 years 05 months\n",
      "   Price: $1,038,000 | Model: 4.2288 | Loc: 0.69 | Final: 1.7547\n",
      "   match eval → mrt_access: 0.27 | bus_access: 0.90 | amenities: 0.77 | school: 0.52 | floor: 1.00\n",
      "   ⚠ unmet features (sim<0.30): mrt_access\n",
      "\n",
      "#4 | 311C CLEMENTI AVE 4 [CLEMENTI]\n",
      "   Type/Floor:  / 37 TO 39\n",
      "   Area: 105.0 sqm   Lease: 91 years 02 months\n",
      "   Price: $1,150,000 | Model: 3.5876 | Loc: 0.82 | Final: 1.7034\n",
      "   match eval → mrt_access: 0.07 | bus_access: 0.67 | amenities: 0.07 | school: 0.52 | floor: 0.04\n",
      "   ⚠ unmet features (sim<0.30): mrt_access, amenities, floor\n",
      "\n",
      "#5 | 425 CLEMENTI AVE 1 [CLEMENTI]\n",
      "   Type/Floor:  / 28 TO 30\n",
      "   Area: 100.0 sqm   Lease: 88 years 02 months\n",
      "   Price: $1,006,666 | Model: 3.3924 | Loc: 0.82 | Final: 1.6448\n",
      "   match eval → mrt_access: 0.07 | bus_access: 0.81 | amenities: 0.07 | school: 0.30 | floor: 0.24\n",
      "   ⚠ unmet features (sim<0.30): mrt_access, amenities, school, floor\n",
      "\n",
      "#6 | 440C CLEMENTI AVE 3 [CLEMENTI]\n",
      "   Type/Floor:  / 34 TO 36\n",
      "   Area: 112.0 sqm   Lease: 95 years 04 months\n",
      "   Price: $1,180,000 | Model: 3.2369 | Loc: 0.82 | Final: 1.5982\n",
      "   match eval → mrt_access: 0.27 | bus_access: 0.90 | amenities: 0.63 | school: 0.52 | floor: 0.14\n",
      "   ⚠ unmet features (sim<0.30): mrt_access, floor\n",
      "\n",
      "#7 | 1C CANTONMENT RD [OUTRAM]\n",
      "   Type/Floor:  / 19 TO 21\n",
      "   Area: 93.0 sqm   Lease: 86 years 08 months\n",
      "   Price: $1,155,000 | Model: 3.8005 | Loc: 0.49 | Final: 1.4858\n",
      "   match eval → mrt_access: 0.35 | bus_access: 0.81 | amenities: 0.77 | school: 0.07 | floor: 0.73\n",
      "   ⚠ unmet features (sim<0.30): school\n",
      "\n",
      "#8 | 1A CANTONMENT RD [OUTRAM]\n",
      "   Type/Floor:  / 22 TO 24\n",
      "   Area: 107.0 sqm   Lease: 88 years 05 months\n",
      "   Price: $1,100,000 | Model: 3.7433 | Loc: 0.49 | Final: 1.4686\n",
      "   match eval → mrt_access: 0.36 | bus_access: 0.81 | amenities: 0.63 | school: 0.07 | floor: 0.61\n",
      "   ⚠ unmet features (sim<0.30): school\n",
      "\n",
      "#9 | 138B LOR 1A TOA PAYOH [TOA PAYOH]\n",
      "   Type/Floor:  / 13 TO 15\n",
      "   Area: 110.0 sqm   Lease: 86 years 07 months\n",
      "   Price: $1,068,888 | Model: 3.7559 | Loc: 0.45 | Final: 1.4439\n",
      "   match eval → mrt_access: 0.33 | bus_access: 0.81 | amenities: 0.18 | school: 0.63 | floor: 1.00\n",
      "   ⚠ unmet features (sim<0.30): amenities\n",
      "\n",
      "#10 | 20 JLN MEMBINA [BUKIT MERAH]\n",
      "   Type/Floor:  / 16 TO 18\n",
      "   Area: 110.0 sqm   Lease: 80 years\n",
      "   Price: $1,000,000 | Model: 3.3606 | Loc: 0.54 | Final: 1.3864\n",
      "   match eval → mrt_access: 0.76 | bus_access: 0.81 | amenities: 0.55 | school: 0.07 | floor: 0.92\n",
      "   ⚠ unmet features (sim<0.30): school\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Inference main\n",
    "# =========================\n",
    "import json\n",
    "from joblib import load as joblib_load\n",
    "\n",
    "def main_infer(\n",
    "    # Fallback paths if artifacts is None:\n",
    "    model_path: str | None = None,              # e.g. \"ranker_lgbm.joblib\"\n",
    "    feature_cols: str | None = None,\n",
    "    # Data sources:\n",
    "    items_path: str = r\"D:\\SelfStudy\\NUS_ISS\\Practise_Moudle\\Recommdation_Model\\item_matrix_merged.csv\",\n",
    "    pa_sim_path: str = r\"D:\\SelfStudy\\NUS_ISS\\Practise_Moudle\\Recommdation_Model\\PA_centroid_similarity_0_1.csv\",\n",
    "    item_place_col: str = \"PLAN\",\n",
    "    # Inference options:\n",
    "    topn: int = 10,\n",
    "    k_candidates: int = 300,\n",
    "    seed: int = 2025,\n",
    "    use_location_rerank: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run a full inference pass with a partially specified user profile.\n",
    "    - If `artifacts` is provided (from training), it uses it directly.\n",
    "    - Otherwise it loads model and feature_cols from disk.\n",
    "    \"\"\"\n",
    "    # 1) Load model + feature_cols\n",
    "    model = joblib_load(model_path)\n",
    "            \n",
    "        \n",
    "\n",
    "    # 2) Load item matrix & PA similarity\n",
    "    items_df = pd.read_csv(items_path)\n",
    "    sim_df_pa = load_pa_similarity_matrix(pa_sim_path)\n",
    "\n",
    "    # 3) Mock a partially specified user (some fields intentionally omitted)\n",
    "    #    - Missing fields will be handled by neutral defaults inside feature builders.\n",
    "    user_input = {\n",
    "        \"Budget_SGD\": 1100000,                 # known & reliable\n",
    "        \"Preferred_Flat_Area\": 100,              # wants 90 sqr\n",
    "        \"Preferred_Place\": \"JURONG EAST\",      # explicit place\n",
    "        \"Priority_Distance_Proximity\": 0.8,  # very distance-sensitive\n",
    "        # The following are partially specified / masked on purpose:\n",
    "        \"Floor_Preference\": 2,                # provided\n",
    "        \"NewHome_Preference\": 0.5,            # neutral on new vs resale\n",
    "        # priorities: leave some missing to test neutral handling\n",
    "        \"Priority_MRT_Access\": 5,\n",
    "        \"Priority_Bus_Access\": 5,\n",
    "        \"Priority_Amenities\": 5,\n",
    "        \"Priority_School_Proximity\": 5,\n",
    "        \"Priority_Park_Access\": 5\n",
    "    }\n",
    "\n",
    "    # 4) Run recommendation (this calls: retrieval → features → predict → rerank → print)\n",
    "    recs = recommend_for_user(\n",
    "        model=model,\n",
    "        feature_cols=feature_cols,\n",
    "        user_input=user_input,\n",
    "        items_df=items_df,\n",
    "        sim_df_pa=sim_df_pa,\n",
    "        item_place_col=item_place_col,\n",
    "        topn=topn,\n",
    "        k_candidates=k_candidates,\n",
    "        seed=seed,\n",
    "        use_location_rerank=True,\n",
    "    )\n",
    "\n",
    "    \n",
    "    #fi = pd.DataFrame({\"feature\": feature_cols, \"gain\": model.feature_importances_}).sort_values(\"gain\", ascending=False)\n",
    "    \n",
    "    imp_gain  = model.booster_.feature_importance(importance_type=\"gain\")\n",
    "    imp_split = model.booster_.feature_importance(importance_type=\"split\")\n",
    "    names     = model.booster_.feature_name()\n",
    "\n",
    "    importance_df = pd.DataFrame({\n",
    "    \"feature\": names,\n",
    "    \"gain\": imp_gain,\n",
    "    \"split\": imp_split\n",
    "    }).sort_values(\"gain\", ascending=False)\n",
    "\n",
    "#     print(\"\\n============================\")\n",
    "#     print(\"Feature Importance (sorted by gain)\")\n",
    "#     print(\"============================\")\n",
    "#     print(importance_df.to_string(index=False))\n",
    "\n",
    "    return {\"user_input\": user_input, \"recs\": recs, \"feature_cols\": feature_cols, \"model\": model}\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Script entry (example)\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Case A: you just trained in the same session\n",
    "    # from training_baseline import main as train_main\n",
    "    # artifacts = train_main(...)\n",
    "\n",
    "    # If you already have `artifacts` in memory from training:\n",
    "    try:\n",
    "        artifacts  # noqa: F821\n",
    "    except NameError:\n",
    "        artifacts = None\n",
    "        \n",
    "    feature_cols=['sim_budget', 'sim_budget_missing', 'sim_location', 'sim_location_missing', 'sim_mrt_access', 'sim_mrt_access_missing', 'sim_bus_access', 'sim_bus_access_missing', 'sim_amenities', 'sim_amenities_missing', 'sim_school', 'sim_school_missing', 'sim_area', 'sim_area_missing', 'sim_floor', 'sim_floor_missing', 'sim_newhome', 'sim_newhome_missing', 'sim_park_access', 'sim_park_access_missing']\n",
    "    deploy_path = r\"D:\\SelfStudy\\NUS_ISS\\Practise_Moudle\\Recommdation_Model\\Deployment_Coding\\ranker_lgbm.joblib\"\n",
    "    result = main_infer(\n",
    "        model_path=deploy_path,\n",
    "        feature_cols=feature_cols,\n",
    "        items_path=r\"D:\\SelfStudy\\NUS_ISS\\Practise_Moudle\\Recommdation_Model\\item_matrix_merged.csv\",\n",
    "        pa_sim_path=r\"D:\\SelfStudy\\NUS_ISS\\Practise_Moudle\\Recommdation_Model\\PA_centroid_similarity_0_1.csv\", # Call the distance matrix table\n",
    "        item_place_col=\"Plan\",\n",
    "        topn=10,\n",
    "        k_candidates=300,\n",
    "        use_location_rerank=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4291fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b3dd43e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sim_budget', 'sim_budget_missing', 'sim_location', 'sim_location_missing', 'sim_mrt_access', 'sim_mrt_access_missing', 'sim_bus_access', 'sim_bus_access_missing', 'sim_amenities', 'sim_amenities_missing', 'sim_school', 'sim_school_missing', 'sim_area', 'sim_area_missing', 'sim_floor', 'sim_floor_missing', 'sim_newhome', 'sim_newhome_missing', 'sim_park_access', 'sim_park_access_missing']\n"
     ]
    }
   ],
   "source": [
    "print(artifacts[\"feature_cols\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61306d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc66455",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_ai_study",
   "language": "python",
   "name": "torch_ai_study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
