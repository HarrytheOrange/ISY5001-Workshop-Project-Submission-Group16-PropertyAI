{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee20f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from typing import Optional, Dict, Union\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "from joblib import load as joblib_load\n",
    "\n",
    "# =========================================================\n",
    "# 0) Utils\n",
    "# =========================================================\n",
    "def _norm_text(x) -> Optional[str]:\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    return str(x).strip().upper()\n",
    "\n",
    "def gaussian_sim(user_val: float, item_val: float, sigma: float = 1.0) -> float:\n",
    "    \"\"\"Smooth 'closeness is better' similarity in [0,1].\"\"\"\n",
    "    u, v = float(user_val), float(item_val)\n",
    "    if sigma <= 0:\n",
    "        return 1.0 if np.isclose(u, v) else 0.0\n",
    "    d = u - v\n",
    "    return float(np.exp(-(d * d) / (2.0 * sigma * sigma)))\n",
    "\n",
    "def _clip_area(a: float, lo: float = 30.0, hi: float = 200.0) -> float:\n",
    "    \"\"\"Clamp area into the valid domain.\"\"\"\n",
    "    if pd.isna(a):\n",
    "        return np.nan\n",
    "    return float(np.clip(float(a), lo, hi))\n",
    "\n",
    "def gaussian_rel(delta: float, sigma: float) -> float:\n",
    "    \"\"\"Gaussian on a relative delta; returns score in [0,1].\"\"\"\n",
    "    if sigma <= 0:\n",
    "        return 1.0 if np.isclose(delta, 0.0) else 0.0\n",
    "    return float(np.exp(-(delta * delta) / (2.0 * sigma * sigma)))\n",
    "\n",
    "def norm_priority(priority_raw: float) -> float:\n",
    "    \"\"\"Map raw priority in [1,5] → [0,1].\"\"\"\n",
    "    if pd.isna(priority_raw):\n",
    "        return 0.5\n",
    "    return float(np.clip((float(priority_raw) - 1.0) / 4.0, 0.0, 1.0))\n",
    "\n",
    "def sat_count(x: float, alpha: float = 1.0) -> float:\n",
    "    \"\"\"Monotonic saturation in [0,1]: s=1-exp(-alpha*x).\"\"\"\n",
    "    if pd.isna(x) or x <= 0:\n",
    "        return 0.0\n",
    "    return float(1.0 - np.exp(-alpha * float(x)))\n",
    "\n",
    "def blend_with_priority(item_score: float, priority_raw: float, neutral: float = 0.5, contrast: float = 1.0) -> float:\n",
    "    \"\"\"\n",
    "    Make priority effect stronger:\n",
    "      - map item_score from [0,1] to [-1,1] by s' = 2*s - 1\n",
    "      - interpolate between neutral' (=0) and s' by p (0..1), then map back.\n",
    "      - contrast>1 slightly amplifies the effect.\n",
    "    \"\"\"\n",
    "    p = norm_priority(priority_raw)      # 0..1\n",
    "    s = float(np.clip(item_score, 0.0, 1.0))\n",
    "    s_ = (2*s - 1) * contrast            # [-contrast, +contrast]\n",
    "    out_ = p * s_                        # 0→neutral(0), 1→s_\n",
    "    out = (out_ / contrast + 1) / 2      # back to [0,1]\n",
    "    # 混一点点原本 neutral，避免极端：\n",
    "    return float(0.15 * neutral + 0.85 * out)\n",
    "\n",
    "# =========================================================\n",
    "# 1) Feature mappings — flat / floor / newhome (Gaussian)\n",
    "# =========================================================\n",
    "# ============================================\n",
    "# 2) storey_range ↔ Floor_Preference (Gaussian)\n",
    "#    HDB storey buckets expanded to 1..5 scale\n",
    "# ============================================\n",
    "\n",
    "_FLAT_TYPE_TO_NUM = {\n",
    "    \"1 ROOM\": 1, \"2 ROOM\": 2, \"3 ROOM\": 3, \"4 ROOM\": 4, \"5 ROOM\": 5,\n",
    "    \"EXECUTIVE\": 6, \"MULTI-GENERATION\": 5\n",
    "}\n",
    "\n",
    "\n",
    "def flat_type_to_num(flat_type: str, default_num: int = 3) -> int:\n",
    "    key = _norm_text(flat_type)\n",
    "    return _FLAT_TYPE_TO_NUM.get(key, default_num)\n",
    "\n",
    "def score_flat_type(user_pref_flat_num: float, item_flat_type: str, sigma: float = 0.8) -> float:\n",
    "    \"\"\"Preferred_Flat_Num (1..7) vs flat_type (mapped) → [0,1].\"\"\"\n",
    "    item_num = flat_type_to_num(item_flat_type)\n",
    "    return gaussian_sim(user_pref_flat_num, item_num, sigma=sigma)\n",
    "\n",
    "\n",
    "_STOREY_TO_LEVEL = {\n",
    "    \"01 TO 03\": 1.0,\n",
    "    \"04 TO 06\": 1.2,\n",
    "    \"07 TO 09\": 1.5,\n",
    "    \"10 TO 12\": 1.7,\n",
    "    \"13 TO 15\": 2.0,\n",
    "    \"16 TO 18\": 2.4,\n",
    "    \"19 TO 21\": 2.8,\n",
    "    \"22 TO 24\": 3.0,\n",
    "    \"25 TO 27\": 3.3,\n",
    "    \"28 TO 30\": 3.7,\n",
    "    \"31 TO 33\": 4.0,\n",
    "    \"34 TO 36\": 4.0,\n",
    "    \"37 TO 39\": 4.5,\n",
    "    \"40 TO 42\": 4.5,\n",
    "    \"43 TO 45\": 5.0,\n",
    "    \"46 TO 48\": 5.0,\n",
    "    \"49 TO 51\": 5.0,\n",
    "    \"52 TO 54\": 5.0,\n",
    "    \"55 TO 57\": 5.0\n",
    "}\n",
    "\n",
    "# --- 相对高斯：越接近越好（仅保留 rel_sigma 一个参数） ---\n",
    "def score_area_closeness(user_area: float,\n",
    "                         item_area: float,\n",
    "                         rel_sigma: float = 0.12) -> float:\n",
    "    \"\"\"\n",
    "    Return a similarity in [0,1] using a relative Gaussian on percentage diff:\n",
    "        rel = (item - user) / user\n",
    "        sim = exp( - rel^2 / (2 * rel_sigma^2) )\n",
    "    仅一个超参数：rel_sigma（相对容差），默认 0.12 ≈ 12%。\n",
    "    \"\"\"\n",
    "    # ——最小清洗：转成数值并裁剪到[30,200]，避免字符串/越界导致NaN——\n",
    "    ua = pd.to_numeric(user_area, errors=\"coerce\")\n",
    "    ia = pd.to_numeric(item_area, errors=\"coerce\")\n",
    "    if not pd.isna(ua):\n",
    "        ua = float(np.clip(ua, 30.0, 200.0))\n",
    "    if not pd.isna(ia):\n",
    "        ia = float(np.clip(ia, 30.0, 200.0))\n",
    "\n",
    "    # === 临时调试：打印并“打断” ===\n",
    "    # print(f\"[DEBUG] area inputs -> user_area(ua)={ua}, item_area(ia)={ia}\")\n",
    "    # 方式A（推荐在notebook/脚本临时用）：打印后直接返回一个占位分数，观察输入是否为NaN\n",
    "    # return 0.5  # ← 调试完成后删掉这一行\n",
    "\n",
    "    # 方式B（强力中断）：打印后直接中止执行\n",
    "    #raise SystemExit(\"DEBUG BREAK after printing ua/ia\")\n",
    "\n",
    "    # ——正式计算——\n",
    "    if pd.isna(ua) or pd.isna(ia) or ua <= 0:\n",
    "        return 0.5  # 缺值兜底（这就是你之前看到全是0.5的触发条件）\n",
    "\n",
    "    rel = (ia - ua) / ua\n",
    "    if rel_sigma <= 0:\n",
    "        return 1.0 if np.isclose(rel, 0.0) else 0.0\n",
    "    return float(np.exp(-(rel * rel) / (2.0 * rel_sigma * rel_sigma)))\n",
    "\n",
    "def storey_to_level(storey_range: str, default_level: float = 2.0) -> float:\n",
    "    \"\"\"\n",
    "    Map textual 'storey_range' to a continuous level in {1..5}.\n",
    "    Unknown/missing values → default_level (mid-level = 2.5).\n",
    "    \"\"\"\n",
    "    key = _norm_text(storey_range)\n",
    "    if key in _STOREY_TO_LEVEL:\n",
    "        return _STOREY_TO_LEVEL[key]\n",
    "    # Try partial match (e.g. \"35 TO 37\" not in dict but similar)\n",
    "    if isinstance(key, str):\n",
    "        try:\n",
    "            low = int(key.split(\" TO \")[0])\n",
    "            if low <= 6: return 1.0\n",
    "            elif low <= 12: return 2.0\n",
    "            elif low <= 21: return 3.0\n",
    "            elif low <= 33: return 4.0\n",
    "            else: return 5.0\n",
    "        except Exception:\n",
    "            return default_level\n",
    "    return default_level\n",
    "\n",
    "def score_floor(user_floor_pref: float,\n",
    "                item_storey_range: str,\n",
    "                sigma: float = 1.2) -> float:\n",
    "    \"\"\"\n",
    "    Gaussian similarity between user's floor preference (1..5)\n",
    "    and property's level (1..5).\n",
    "    Slightly larger sigma to tolerate close floors.\n",
    "    Returns a value in [0, 1].\n",
    "    \"\"\"\n",
    "    item_level = storey_to_level(item_storey_range)\n",
    "    return gaussian_sim(user_floor_pref, item_level, sigma=sigma)\n",
    "\n",
    "def score_newhome(user_newhome_pref: float, sigma: float = 0.25) -> float:\n",
    "    \"\"\"\n",
    "    NewHome_Preference: 1=new, 0.5=neutral, 0=resale.\n",
    "    For HDB resale, item=0.0; neutral returns 1.0.\n",
    "    \"\"\"\n",
    "    if pd.isna(user_newhome_pref):\n",
    "        return 1.0\n",
    "    val = float(user_newhome_pref)\n",
    "    if np.isclose(val, 0.5):\n",
    "        return 1.0\n",
    "    return gaussian_sim(val, 0.0, sigma=sigma)\n",
    "\n",
    "# def compute_match_scores_gaussian(user_row: dict | pd.Series,\n",
    "#                                   item_row: dict | pd.Series,\n",
    "#                                   sigmas: dict | None = None) -> dict:\n",
    "#     \"\"\"Return sim_area, sim_floor, sim_newhome in [0,1]（接口保持原样）.\"\"\"\n",
    "#     #s = sigmas or {\"area\": 0.12, \"floor\": 1.0, \"newhome\": 0.25}\n",
    "    \n",
    "#     s = sigmas or {\"flat\": 0.8, \"floor\": 1.0, \"newhome\": 0.25}\n",
    "#     return {\n",
    "#         \"\"\"Return sim_flat_type, sim_floor, sim_newhome in [0,1].\"\"\"\n",
    "#         \"sim_area\":    score_area_closeness(user_row[\"Preferred_Flat_Num\"],\n",
    "#                                             item_row[\"flat_type\"],\n",
    "#                                             s[\"flat\"]),\n",
    "#         \"sim_floor\":   score_floor(user_row[\"Floor_Preference\"],\n",
    "#                                    item_row[\"storey_range\"],\n",
    "#                                    s[\"floor\"]),\n",
    "#         \"sim_newhome\": score_newhome(user_row[\"NewHome_Preference\"],\n",
    "#                                      s[\"newhome\"]),\n",
    "#     }\n",
    "\n",
    "def compute_match_scores_gaussian(user_row: dict | pd.Series,\n",
    "                                  item_row: dict | pd.Series,\n",
    "                                  sigmas: dict | None = None) -> dict:\n",
    "    \"\"\"Return sim_flat_type, sim_floor, sim_newhome in [0,1].\"\"\"\n",
    "    s = sigmas or {\"flat\": 0.8, \"floor\": 1.0, \"newhome\": 0.25}\n",
    "    return {\n",
    "        \"sim_flat_type\": score_flat_type(user_row[\"Preferred_Flat_Num\"], item_row[\"flat_type\"], s[\"flat\"]),\n",
    "        \"sim_floor\":     score_floor(user_row[\"Floor_Preference\"],item_row[\"storey_range\"],s[\"floor\"]),\n",
    "        \"sim_newhome\":   score_newhome(user_row[\"NewHome_Preference\"], s[\"newhome\"]),\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 2) Feature mappings — facility accessibility environment (higher is better)\n",
    "# =========================================================\n",
    "def score_park_access(priority_park_access: float, pk_500m_in: float) -> float:\n",
    "    item_score = 1.0 if (not pd.isna(pk_500m_in) and pk_500m_in > 0) else 0.0\n",
    "    return blend_with_priority(item_score, priority_park_access, neutral=0.5)\n",
    "\n",
    "def score_bus_access(priority_bus_access: float, bus_200: float, bus_500: float,\n",
    "                     alpha_200: float = 0.8, alpha_500: float = 0.4) -> float:\n",
    "    s200 = sat_count(bus_200, alpha_200)\n",
    "    s500 = sat_count(bus_500, alpha_500)\n",
    "    item_score = float(np.clip((2.0/3.0)*s200 + (1.0/3.0)*s500, 0.0, 1.0))\n",
    "    return blend_with_priority(item_score, priority_bus_access, neutral=0.5)\n",
    "\n",
    "def score_mrt_access(priority_mrt_access: float, mrt_200: float, mrt_500: float,\n",
    "                     alpha_200: float = 2.0, alpha_500: float = 1.2) -> float:\n",
    "    s200 = sat_count(mrt_200, alpha_200)\n",
    "    s500 = sat_count(mrt_500, alpha_500)\n",
    "    item_score = float(np.clip((2.0/3.0)*s200 + (1.0/3.0)*s500, 0.0, 1.0))\n",
    "    return blend_with_priority(item_score, priority_mrt_access, neutral=0.5)\n",
    "\n",
    "def score_amenities(priority_amenities: float, hwkr_500m: float, mall_500m: float,\n",
    "                    alpha_hwkr: float = 0.7, alpha_mall: float = 0.6) -> float:\n",
    "    s_h = sat_count(hwkr_500m, alpha_hwkr)\n",
    "    s_m = sat_count(mall_500m, alpha_mall)\n",
    "    item_score = float(np.clip(0.25*s_h + 0.75*s_m, 0.0, 1.0))\n",
    "    return blend_with_priority(item_score, priority_amenities, neutral=0.5)\n",
    "\n",
    "def score_school_proximity(priority_school: float, gp_sch_1k: float, gp_sch_2k: float,\n",
    "                           alpha_1k: float = 0.9, alpha_2k: float = 0.5) -> float:\n",
    "    s1 = sat_count(gp_sch_1k, alpha_1k)\n",
    "    s2 = sat_count(gp_sch_2k, alpha_2k)\n",
    "    item_score = float(np.clip((2.0/3.0)*s1 + (1.0/3.0)*s2, 0.0, 1.0))\n",
    "    return blend_with_priority(item_score, priority_school, neutral=0.5)\n",
    "\n",
    "def compute_env_priority_scores(user_row: dict | pd.Series,\n",
    "                                item_row: dict | pd.Series,\n",
    "                                alphas: dict | None = None) -> dict:\n",
    "    \"\"\"\n",
    "    Safe version: all user priorities fetched via .get(..., np.nan),\n",
    "    so missing priorities are treated as neutral inside blend_with_priority().\n",
    "    \"\"\"\n",
    "    alphas = alphas or {\n",
    "        \"bus_200\": 0.8, \"bus_500\": 0.4,\n",
    "        \"mrt_200\": 2.0, \"mrt_500\": 1.2,\n",
    "        \"hwkr\": 0.7, \"mall\": 0.6,\n",
    "        \"sch_1k\": 0.9, \"sch_2k\": 0.5\n",
    "    }\n",
    "\n",
    "    # ---- safely get user priorities (missing -> NaN -> neutral 0.5) ----\n",
    "    p_park = user_row.get(\"Priority_Park_Access\", np.nan)\n",
    "    p_bus  = user_row.get(\"Priority_Bus_Access\", np.nan)\n",
    "    p_mrt  = user_row.get(\"Priority_MRT_Access\", np.nan)\n",
    "    p_am   = user_row.get(\"Priority_Amenities\", np.nan)\n",
    "    p_sch  = user_row.get(\"Priority_School_Proximity\", np.nan)\n",
    "\n",
    "    # ---- items (already .get with defaults) ----\n",
    "    s_park = score_park_access(\n",
    "        p_park,\n",
    "        item_row.get(\"PK_500M_IN\", 0)\n",
    "    )\n",
    "\n",
    "    s_bus = score_bus_access(\n",
    "        p_bus,\n",
    "        item_row.get(\"bus_200\", 0),\n",
    "        item_row.get(\"bus_500\", 0),\n",
    "        alpha_200=alphas[\"bus_200\"],\n",
    "        alpha_500=alphas[\"bus_500\"]\n",
    "    )\n",
    "\n",
    "    s_mrt = score_mrt_access(\n",
    "        p_mrt,\n",
    "        item_row.get(\"mrt_200\", 0),\n",
    "        item_row.get(\"mrt_500\", 0),\n",
    "        alpha_200=alphas[\"mrt_200\"],\n",
    "        alpha_500=alphas[\"mrt_500\"]\n",
    "    )\n",
    "\n",
    "    s_am = score_amenities(\n",
    "        p_am,\n",
    "        item_row.get(\"HWKR_500M\", 0),\n",
    "        item_row.get(\"MALL_500M\", 0),\n",
    "        alpha_hwkr=alphas[\"hwkr\"],\n",
    "        alpha_mall=alphas[\"mall\"]\n",
    "    )\n",
    "\n",
    "    s_sch = score_school_proximity(\n",
    "        p_sch,\n",
    "        item_row.get(\"GP_SCH_1K\", 0),\n",
    "        item_row.get(\"GP_SCH_2K\", 0),\n",
    "        alpha_1k=alphas[\"sch_1k\"],\n",
    "        alpha_2k=alphas[\"sch_2k\"]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"sim_park_access\": s_park,\n",
    "        \"sim_bus_access\":  s_bus,\n",
    "        \"sim_mrt_access\":  s_mrt,\n",
    "        \"sim_amenities\":   s_am,\n",
    "        \"sim_school\":      s_sch,\n",
    "    }\n",
    "\n",
    "# =========================================================\n",
    "# 3) Budget affinity (asymmetric Gaussian)\n",
    "# =========================================================\n",
    "def _asymmetric_gaussian(x: float, center: float, sigma_left: float, sigma_right: float) -> float:\n",
    "    dx = float(x) - float(center)\n",
    "    sigma = float(sigma_right if dx >= 0 else sigma_left)\n",
    "    if sigma <= 0:\n",
    "        return 1.0 if np.isclose(dx, 0.0) else 0.0\n",
    "    return float(np.exp(-(dx * dx) / (2.0 * sigma * sigma)))\n",
    "\n",
    "def budget_affinity_score(budget_sgd: float, resale_price: float, #always low a bit\n",
    "                          target_under: float = 0.01, # bis a little\n",
    "                          sigma_below: float = 0.08,\n",
    "                          sigma_above: float = 0.12,\n",
    "                          hard_clip: float = 0.60) -> float:\n",
    "    \"\"\"Smooth satisfaction between budget and price in [0,1].\"\"\"\n",
    "    if pd.isna(budget_sgd) or budget_sgd <= 0 or pd.isna(resale_price) or resale_price <= 0:\n",
    "        return 0.0\n",
    "    d = (float(resale_price) - float(budget_sgd)) / float(budget_sgd)\n",
    "    d = float(np.clip(d, -hard_clip, hard_clip))\n",
    "    center = -abs(float(target_under))\n",
    "    score = _asymmetric_gaussian(d, center, sigma_below, sigma_above)\n",
    "    return float(np.clip(score, 0.0, 1.0))\n",
    "\n",
    "# =========================================================\n",
    "# 4) Location similarity with sensitivity\n",
    "# =========================================================\n",
    "def _norm_place(x: Optional[Union[str, float]]) -> Optional[str]:\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "        return None\n",
    "    return str(x).strip().upper()\n",
    "\n",
    "def load_pa_similarity_matrix(path: str) -> pd.DataFrame:\n",
    "    if path.lower().endswith(\".csv\"):\n",
    "        df = pd.read_csv(path, index_col=0)\n",
    "    else:\n",
    "        df = pd.read_excel(path, index_col=0)\n",
    "    df.index = df.index.to_series().map(_norm_place)\n",
    "    df.columns = pd.Index([_norm_place(c) for c in df.columns])\n",
    "    common = df.index.intersection(df.columns)\n",
    "    df = df.loc[common, common].copy()\n",
    "    df = df.clip(0.0, 1.0)\n",
    "    df = 0.5 * (df + df.T)\n",
    "    np.fill_diagonal(df.values, 1.0)\n",
    "    return df\n",
    "\n",
    "def _temperature_blend(base_sim: float, sensitivity: float,\n",
    "                       neutral: float = 0.6, tau_low: float = 0.6, tau_high: float = 3.0) -> float:\n",
    "    p = float(np.clip(0.0 if sensitivity is None else sensitivity, 0.0, 1.0))\n",
    "    s = float(np.clip(0.0 if base_sim is None else base_sim, 0.0, 1.0))\n",
    "    tau = tau_low + (tau_high - tau_low) * p\n",
    "    s_temp = s ** tau\n",
    "    return float(np.clip((1.0 - p) * neutral + p * s_temp, 0.0, 1.0))\n",
    "\n",
    "def pa_location_similarity_with_sensitivity(\n",
    "    user_place: Optional[str],\n",
    "    item_place: Optional[str],\n",
    "    sim_df: pd.DataFrame,\n",
    "    distance_sensitivity: Optional[float],\n",
    "    alias_map_user: Optional[Dict[str, str]] = None,\n",
    "    alias_map_item: Optional[Dict[str, str]] = None,\n",
    "    default_when_missing: float = 0.0,\n",
    "    neutral: float = 0.6,\n",
    "    tau_low: float = 0.6,\n",
    "    tau_high: float = 3.0\n",
    ") -> float:\n",
    "    u = _norm_place(user_place)\n",
    "    v = _norm_place(item_place)\n",
    "    if alias_map_user and u is not None:\n",
    "        u = _norm_place(alias_map_user.get(u, u))\n",
    "    if alias_map_item and v is not None:\n",
    "        v = _norm_place(alias_map_item.get(v, v))\n",
    "    if u is None or v is None:\n",
    "        base = float(default_when_missing)\n",
    "    elif (u in sim_df.index) and (v in sim_df.columns):\n",
    "        base = float(np.clip(sim_df.loc[u, v], 0.0, 1.0))\n",
    "    else:\n",
    "        base = float(default_when_missing)\n",
    "    return _temperature_blend(base, distance_sensitivity, neutral, tau_low, tau_high)\n",
    "\n",
    "# =========================================================\n",
    "# 5) Candidate sampling & feature dropout\n",
    "# =========================================================\n",
    "def _banded_budget_sample(items_df: pd.DataFrame, budget: float,\n",
    "                          k_total: int = 30, band: float = 0.20, seed: int = 42) -> pd.DataFrame:\n",
    "    \"\"\"Retrieve k candidates within ±band of budget; fallback to global sample.\"\"\"\n",
    "    band_df = items_df[(items_df[\"resale_price\"] >= (1 - band) * budget) &\n",
    "                       (items_df[\"resale_price\"] <= (1 + band) * budget)]\n",
    "    if len(band_df) >= k_total:\n",
    "        return band_df.sample(k_total, random_state=seed)\n",
    "    k_band = min(len(band_df), int(0.7 * k_total))\n",
    "    part1 = band_df.sample(k_band, random_state=seed) if k_band > 0 else band_df.head(0)\n",
    "    k_rest = k_total - len(part1)\n",
    "    part2 = items_df.sample(min(k_rest, len(items_df)), random_state=seed)\n",
    "    return pd.concat([part1, part2]).drop_duplicates().head(k_total)\n",
    "\n",
    "# masking configuration\n",
    "GEO_MASK_OVERALL_PROB = 0.15\n",
    "MASK_NEUTRALS = {\"sim_budget\": 0.8, \"sim_location\": 0.6, \"default\": 0.5}\n",
    "\n",
    "def _apply_feature_dropout(feats_full: dict,\n",
    "                           user_row: pd.Series,\n",
    "                           item_row: pd.Series,\n",
    "                           sim_df_pa: pd.DataFrame,\n",
    "                           item_place_col: str,\n",
    "                           rng: np.random.Generator,\n",
    "                           neutral_vals: dict = MASK_NEUTRALS) -> dict:\n",
    "    \"\"\"\n",
    "    Simulate incomplete user inputs by masking some sim_* features and adding *_missing flags.\n",
    "    Budget is rarely masked; location masking is controlled via GEO_MASK_OVERALL_PROB.\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    # Always keep budget (or low prob)\n",
    "    out[\"sim_budget\"] = feats_full[\"sim_budget\"]\n",
    "    out[\"sim_budget_missing\"] = 0\n",
    "\n",
    "    # Location masking\n",
    "    if rng.random() < GEO_MASK_OVERALL_PROB:\n",
    "        out[\"sim_location\"] = neutral_vals[\"sim_location\"]\n",
    "        out[\"sim_location_missing\"] = 1\n",
    "    else:\n",
    "        out[\"sim_location\"] = feats_full[\"sim_location\"]\n",
    "        out[\"sim_location_missing\"] = 0\n",
    "\n",
    "    # Other channels (15% chance each)\n",
    "    for k in [\"sim_mrt_access\", \"sim_bus_access\", \"sim_amenities\", \"sim_school\",\n",
    "              \"sim_flat_type\", \"sim_floor\", \"sim_newhome\",\"sim_park_access\"]:\n",
    "        if rng.random() < 0.15:\n",
    "            out[k] = neutral_vals[\"default\"]\n",
    "            out[f\"{k}_missing\"] = 1\n",
    "        else:\n",
    "            out[k] = feats_full[k]\n",
    "            out[f\"{k}_missing\"] = 0\n",
    "\n",
    "    return out\n",
    "\n",
    "def _weighted_label_from_feats(feats_full: dict, user: dict | pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Build weak label as a weighted mean of similarity channels.\n",
    "    - Budget is the anchor (weight cap = 1.00).\n",
    "    - Location is forced to be the second most influential (cap = 0.90 * budget).\n",
    "    - All other channels are capped at 0.75 * budget.\n",
    "    \"\"\"\n",
    "    # ---- anchors & caps ----\n",
    "    w_budget = 1.00                          # 100% baseline\n",
    "    loc_cap  = 1.55 * w_budget               # location upper bound\n",
    "    oth_cap  = 0.60 * w_budget               # all other channels' upper bound\n",
    "\n",
    "    # priority 1..5 -> 0..1\n",
    "    def _p(raw):\n",
    "        if pd.isna(raw): return 0.5\n",
    "        return float(np.clip((float(raw) - 1.0) / 4.0, 0.0, 1.0))\n",
    "\n",
    "    # distance sensitivity 0..1\n",
    "    pdist = float(np.clip(user.get(\"Priority_Distance_Proximity\", 0.0), 0.0, 1.0))\n",
    "\n",
    "    # ---- base weights (before capping) ----\n",
    "    # keep budget as 1.0; location grows with sensitivity\n",
    "    w_loc   = 0.90 + 0.80 * pdist            # 0.90..1.70  (then capped to 0.90)\n",
    "\n",
    "    # others: moderate ranges, driven by priorities (or mild constants)\n",
    "    w_flat_type  = 0.60 + 0.60 * _p(user.get(\"Preferred_Flat_Num\", 3))  # proxy; no explicit 'flat' priority\n",
    "    w_floor = 0.60 + 0.60 * _p(user.get(\"Floor_Preference\", 3))\n",
    "    w_new   = 0.40                            # new vs resale: weaker by design\n",
    "\n",
    "    w_mrt   = 0.50 + 0.80 * _p(user.get(\"Priority_MRT_Access\", 3))\n",
    "    w_bus   = 0.40 + 0.60 * _p(user.get(\"Priority_Bus_Access\", 3))\n",
    "    w_am    = 0.40 + 0.60 * _p(user.get(\"Priority_Amenities\", 3))\n",
    "    w_sch   = 0.50 + 0.70 * _p(user.get(\"Priority_School_Proximity\", 3))\n",
    "    w_park  = 0.30 + 0.40 * _p(user.get(\"Priority_Park_Access\", 3))    # keep smallest\n",
    "\n",
    "    # ---- apply caps: location > others by construction ----\n",
    "    weights = {\n",
    "        \"sim_budget\":      w_budget,\n",
    "        \"sim_location\":    min(w_loc, loc_cap),\n",
    "        \"sim_flat_type\":   min(w_flat_type, 0.7),\n",
    "        \"sim_floor\":       min(w_floor, oth_cap),\n",
    "        \"sim_newhome\":     min(w_new, oth_cap),\n",
    "        \"sim_mrt_access\":  min(w_mrt, oth_cap),\n",
    "        \"sim_bus_access\":  min(w_bus, oth_cap),\n",
    "        \"sim_amenities\":   min(w_am, oth_cap),\n",
    "        \"sim_school\":      min(w_sch, oth_cap),\n",
    "        \"sim_park_access\": min(w_park, 0.45),\n",
    "    }\n",
    "\n",
    "    # ---- normalize & aggregate ----\n",
    "    w = np.array(list(weights.values()), dtype=float)\n",
    "    v = np.array([feats_full.get(k, 0.0) for k in weights], dtype=float)\n",
    "    w /= (w.sum() if w.sum() > 0 else 1.0)\n",
    "    return float(np.dot(w, v))\n",
    "\n",
    "def build_pairs(users_df: pd.DataFrame, items_df: pd.DataFrame, sim_df_pa: pd.DataFrame,\n",
    "                item_place_col: str = \"pa\", k_candidates: int = 30, rng_seed: int = 42) -> pd.DataFrame:\n",
    "    \"\"\"Create (user,item) samples with masked inputs and weak labels.\"\"\"\n",
    "    rows = []\n",
    "    rng = np.random.default_rng(rng_seed)\n",
    "\n",
    "    for _, u in users_df.iterrows():\n",
    "        uid = int(u[\"Buyer_ID\"])\n",
    "        budget = float(u[\"Budget_SGD\"])\n",
    "        cand = _banded_budget_sample(items_df, budget, k_total=k_candidates, seed=uid)\n",
    "\n",
    "        for _, it in cand.iterrows():\n",
    "            feats_full = {}\n",
    "            feats_full[\"sim_budget\"] = budget_affinity_score(u[\"Budget_SGD\"], it[\"resale_price\"])\n",
    "            feats_full |= compute_match_scores_gaussian(u, it)\n",
    "            feats_full |= compute_env_priority_scores(u, it)\n",
    "            feats_full[\"sim_location\"] = pa_location_similarity_with_sensitivity(\n",
    "                user_place=u.get(\"Preferred_Place\", None),\n",
    "                item_place=it.get(item_place_col, None),\n",
    "                sim_df=sim_df_pa,\n",
    "                distance_sensitivity=u.get(\"Priority_Distance_Proximity\", 0.0),\n",
    "                default_when_missing=0.0,\n",
    "                neutral=0.6\n",
    "            )\n",
    "\n",
    "            #label = _weighted_label_from_feats(feats_full, u.get(\"Priority_Distance_Proximity\", 0.0))\n",
    "            label = _weighted_label_from_feats(feats_full, user=u)\n",
    "            feats_in = _apply_feature_dropout(feats_full, u, it, sim_df_pa, item_place_col, rng, MASK_NEUTRALS)\n",
    "\n",
    "            row = {\"user_id\": uid, \"item_id\": it.get(\"item_id\", it.get(\"id\", _)), \"label\": label}\n",
    "            row.update(feats_in)\n",
    "            rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def grade_relevance_per_user(df: pd.DataFrame, label_col: str = \"label\",\n",
    "                             cuts=(0.4, 0.7, 0.9), out_col: str = \"rel\") -> pd.DataFrame:\n",
    "    \"\"\"Per-user quantile bucketing to 0/1/2/3 relevance.\"\"\"\n",
    "    df = df.copy()\n",
    "    rel_vals = np.zeros(len(df), dtype=int)\n",
    "    pos = 0\n",
    "    for _, g in df.groupby(\"user_id\", sort=False):\n",
    "        if len(g) < 4:\n",
    "            order = np.argsort(g[label_col].values)\n",
    "            grades = np.zeros(len(g), dtype=int)\n",
    "            if len(g) >= 2: grades[order[-1]] = 3\n",
    "            if len(g) >= 3: grades[order[-2]] = 2\n",
    "            if len(g) >= 4: grades[order[-3]] = 1\n",
    "        else:\n",
    "            q1, q2, q3 = g[label_col].quantile(list(cuts)).values\n",
    "            v = g[label_col].values\n",
    "            grades = np.where(v < q1, 0, np.where(v < q2, 1, np.where(v < q3, 2, 3)))\n",
    "        rel_vals[pos:pos+len(g)] = grades\n",
    "        pos += len(g)\n",
    "    df[out_col] = rel_vals\n",
    "    return df\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 7) Training & evaluation\n",
    "# =========================================================\n",
    "def train_ranker_intlabels(pairs_df: pd.DataFrame, feature_prefix: str = \"sim_\",\n",
    "                           test_size: float = 0.2, rng_seed: int = 123):\n",
    "    \"\"\"Train LGBMRanker (lambdarank) with discrete 0..3 labels; returns model, feature_cols, splits.\"\"\"\n",
    "    feature_cols = [c for c in pairs_df.columns if c.startswith(feature_prefix) or c.endswith(\"_missing\")]\n",
    "\n",
    "    # split by user (queries)\n",
    "    qids = pairs_df[\"user_id\"].unique()\n",
    "    q_train, q_valid = train_test_split(qids, test_size=test_size, random_state=rng_seed)\n",
    "    train_df = pairs_df[pairs_df[\"user_id\"].isin(q_train)].copy()\n",
    "    valid_df = pairs_df[pairs_df[\"user_id\"].isin(q_valid)].copy()\n",
    "\n",
    "    # discretize labels\n",
    "    train_df = grade_relevance_per_user(train_df, label_col=\"label\", cuts=(0.4, 0.7, 0.9), out_col=\"rel\")\n",
    "    valid_df = grade_relevance_per_user(valid_df, label_col=\"label\", cuts=(0.4, 0.7, 0.9), out_col=\"rel\")\n",
    "\n",
    "    X_train, y_train = train_df[feature_cols], train_df[\"rel\"].astype(int)\n",
    "    X_valid, y_valid = valid_df[feature_cols], valid_df[\"rel\"].astype(int)\n",
    "\n",
    "    train_group = [len(g) for _, g in train_df.groupby(\"user_id\")]\n",
    "    valid_group = [[len(g) for _, g in valid_df.groupby(\"user_id\")]]\n",
    "\n",
    "    ranker = lgb.LGBMRanker(\n",
    "        objective=\"lambdarank\",\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=63,\n",
    "        min_data_in_leaf=20,\n",
    "        n_estimators=800,\n",
    "        metric=\"ndcg\",\n",
    "        random_state=42,\n",
    "        verbose=-1\n",
    "    )\n",
    "    ranker.set_params(label_gain=[0, 1, 3, 7])\n",
    "\n",
    "    ranker.fit(\n",
    "        X_train, y_train,\n",
    "        group=train_group,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        eval_group=valid_group,\n",
    "        eval_at=[5, 10],\n",
    "        callbacks=[lgb.early_stopping(60), lgb.log_evaluation(50)]\n",
    "    )\n",
    "    return ranker, feature_cols, (train_df, valid_df)\n",
    "\n",
    "def _ndcg_at_k(labels, preds, k=10):\n",
    "    order = np.argsort(-preds)\n",
    "    gains = (2 ** labels[order] - 1)[:k]\n",
    "    discounts = np.log2(np.arange(2, k + 2))\n",
    "    dcg = np.sum(gains / discounts)\n",
    "    ideal_order = np.argsort(-labels)\n",
    "    ideal_gains = (2 ** labels[ideal_order] - 1)[:k]\n",
    "    idcg = np.sum(ideal_gains / discounts)\n",
    "    return float(dcg / idcg) if idcg > 0 else 0.0\n",
    "\n",
    "def mean_ndcg_by_user(df: pd.DataFrame, preds: np.ndarray, label_col: str = \"rel\", k=10) -> float:\n",
    "    df = df.copy(); df[\"pred\"] = preds\n",
    "    scores = [ _ndcg_at_k(g[label_col].values, g[\"pred\"].values, k) for _, g in df.groupby(\"user_id\") ]\n",
    "    return float(np.mean(scores)) if scores else 0.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 8) Main pipeline\n",
    "# =========================================================\n",
    "def main(users_path: str,\n",
    "         items_path: str,\n",
    "         pa_sim_path: str,\n",
    "         item_place_col: str = \"pa\",\n",
    "         out_pairs_path: str | None = None,\n",
    "         k_candidates: int = 30):\n",
    "    \"\"\"Load → build pairs → train → evaluate. Returns artifacts.\"\"\"\n",
    "    users_df = pd.read_excel(users_path)\n",
    "    items_df = pd.read_csv(items_path)\n",
    "    sim_df_pa = load_pa_similarity_matrix(pa_sim_path)\n",
    "\n",
    "    pairs_df = build_pairs(users_df, items_df, sim_df_pa,\n",
    "                           item_place_col=item_place_col,\n",
    "                           k_candidates=k_candidates, rng_seed=42)\n",
    "    if out_pairs_path:\n",
    "        pairs_df.to_csv(out_pairs_path, index=False)\n",
    "        print(f\"[INFO] Built pairs: {pairs_df.shape} → saved to {out_pairs_path}\")\n",
    "    else:\n",
    "        print(f\"[INFO] Built pairs: {pairs_df.shape}\")\n",
    "\n",
    "    model, feature_cols, (train_df, valid_df) = train_ranker_intlabels(pairs_df)\n",
    "\n",
    "    pred_valid = model.predict(valid_df[feature_cols])\n",
    "    ndcg10 = mean_ndcg_by_user(valid_df, pred_valid, label_col=\"rel\", k=10)\n",
    "    ndcg5  = mean_ndcg_by_user(valid_df, pred_valid, label_col=\"rel\", k=5)\n",
    "    print(f\"[RESULT] Mean NDCG@5={ndcg5:.4f}, NDCG@10={ndcg10:.4f}\")\n",
    "    \n",
    "    \n",
    "    deploy_path = r\"ranker_lgbm_HDB_falt_type.joblib\"\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        import joblib\n",
    "        joblib.dump(model, deploy_path)\n",
    "        print(f\"[INFO] Model saved to: {deploy_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARNING] Failed to save model to {deploy_path}: {e}\")\n",
    "\n",
    "    return {\"model\": model, \"feature_cols\": feature_cols, \"pairs_df\": pairs_df,\n",
    "            \"train_df\": train_df, \"valid_df\": valid_df, \"ndcg5\": ndcg5, \"ndcg10\": ndcg10}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c516023",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example (comment out in library use)\n",
    "if __name__ == \"__main__\":\n",
    "    main(\n",
    "        users_path=r\"D:\\SelfStudy\\NUS_ISS\\Practise_Moudle\\Recommdation_Model\\user_profiles_expanded_All.xlsx\",\n",
    "        items_path=r\"D:\\SelfStudy\\NUS_ISS\\Practise_Moudle\\Recommdation_Model\\Deployment_Coding\\ToHarry_Recommedation\\item_matrix_merged.csv\",\n",
    "        pa_sim_path=r\"D:\\SelfStudy\\NUS_ISS\\Practise_Moudle\\Recommdation_Model\\Deployment_Coding\\ToHarry_Recommedation\\PA_centroid_similarity_0_1.csv\",\n",
    "        item_place_col=\"Plan\",\n",
    "        out_pairs_path=r\"D:\\SelfStudy\\NUS_ISS\\Practise_Moudle\\Recommdation_Model\\Deployment_Coding\\ToHarry_Recommedation\\train_pairs.csv\",\n",
    "        k_candidates=120\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b648e285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6400e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df36600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# Inference-time candidate generation & feature computation\n",
    "# --------------------------------------------------------\n",
    "# 0) Small utilities\n",
    "# --------------------------------------------------------\n",
    "def _neutral_defaults() -> dict:\n",
    "    \"\"\"Neutral fallbacks when a feature is missing at inference.\"\"\"\n",
    "    return {\"sim_budget\": 0.8, \"sim_location\": 0.6, \"default\": 0.5}\n",
    "\n",
    "def _pick(row, *candidates, default=\"\"):\n",
    "    \"\"\"Pick the first present column from candidates.\"\"\"\n",
    "    for c in candidates:\n",
    "        if c in row and pd.notna(row[c]):\n",
    "            return row[c]\n",
    "    return default\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 1) Candidate retrieval (budget band ±20%)\n",
    "# --------------------------------------------------------\n",
    "def build_inference_candidates(items_df: pd.DataFrame,\n",
    "                               budget: float,\n",
    "                               k_candidates: int = 300,\n",
    "                               seed: int = 2025) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Retrieve k candidates within ±20% of budget; fallback to global sample.\n",
    "    \"\"\"\n",
    "    band = items_df[(items_df[\"resale_price\"] >= 0.80 * budget) &\n",
    "                    (items_df[\"resale_price\"] <= 1.20 * budget)]\n",
    "    if len(band) < k_candidates:\n",
    "        return items_df.sample(min(k_candidates, len(items_df)), random_state=seed)\n",
    "    return band.sample(k_candidates, random_state=seed)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 2) Feature computation (same sims as training; no masking)\n",
    "# --------------------------------------------------------\n",
    "def compute_features_for_user_items(user_row: pd.Series | dict,\n",
    "                                    items_df: pd.DataFrame,\n",
    "                                    sim_df_pa: pd.DataFrame,\n",
    "                                    item_place_col: str = \"Plan\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build the sim_* features on each (user, item) and keep rich item attributes\n",
    "    for explanation. No masking at inference.\n",
    "    \"\"\"\n",
    "    user = pd.Series(user_row) if not isinstance(user_row, pd.Series) else user_row\n",
    "    rows = []\n",
    "    neutr = _neutral_defaults()\n",
    "\n",
    "    for _, it in items_df.iterrows():\n",
    "        # --- sims used by model ---\n",
    "        feats = {}\n",
    "        feats[\"sim_budget\"] = budget_affinity_score(user.get(\"Budget_SGD\"), it[\"resale_price\"])\n",
    "        feats |= compute_match_scores_gaussian(user, it)     # sim_flat_type, sim_floor, sim_newhome\n",
    "        feats |= compute_env_priority_scores(user, it)       # sim_park_access, sim_bus_access, sim_mrt_access, sim_amenities, sim_school\n",
    "        feats[\"sim_location\"] = pa_location_similarity_with_sensitivity(\n",
    "            user_place=user.get(\"Preferred_Place\", None),\n",
    "            item_place=it.get(item_place_col, None),\n",
    "            sim_df=sim_df_pa,\n",
    "            distance_sensitivity=user.get(\"Priority_Distance_Proximity\", None),\n",
    "            default_when_missing=0.0,\n",
    "            neutral=neutr[\"sim_location\"]\n",
    "        )\n",
    "\n",
    "        # --- carry item attributes for printing ---\n",
    "        block  = _pick(it, \"block\")\n",
    "        street = _pick(it, \"street_name\", \"street_nam\")\n",
    "        town   = _pick(it, \"town\")\n",
    "        pa     = _pick(it, item_place_col)\n",
    "        storey = _pick(it, \"storey_range\")\n",
    "        flat_type   = _pick(it, \"flat_type\")\n",
    "        #lease  = _pick(it, \"remaining_lease\", \"remaining_lease_mths\", \"remaining_lease_months\")\n",
    "\n",
    "        # nearby facility counts / flags\n",
    "        def _int(x): \n",
    "            return int(x) if pd.notna(x) else 0\n",
    "        rows.append({\n",
    "            \"item_id\": it.get(\"item_id\", it.get(\"id\", _)),\n",
    "            \"block\": block, \"street\": street, \"town\": town, \"pa\": pa,\n",
    "            \"storey_range\": storey,\n",
    "            \"flat_type\": flat_type,\n",
    "            \"resale_price\": it.get(\"resale_price\", np.nan),\n",
    "            \"mrt_200\": _int(it.get(\"mrt_200\", np.nan)),\n",
    "            \"mrt_500\": _int(it.get(\"mrt_500\", np.nan)),\n",
    "            \"bus_200\": _int(it.get(\"bus_200\", np.nan)),\n",
    "            \"bus_500\": _int(it.get(\"bus_500\", np.nan)),\n",
    "            \"MALL_500M\": _int(it.get(\"MALL_500M\", np.nan)),\n",
    "            \"HWKR_500M\": _int(it.get(\"HWKR_500M\", np.nan)),\n",
    "            \"HOSP_1K\": _int(it.get(\"HOSP_1K\", np.nan)),\n",
    "            \"GP_SCH_1K\": _int(it.get(\"GP_SCH_1K\", np.nan)),\n",
    "            \"GP_SCH_2K\": _int(it.get(\"GP_SCH_2K\", np.nan)),\n",
    "            \"PK_500M_IN\": _int(it.get(\"PK_500M_IN\", np.nan)),\n",
    "            # model features (no masking at inference)\n",
    "            **feats,\n",
    "            \"sim_budget_missing\": 0,\n",
    "            \"sim_location_missing\": 0,\n",
    "            \"sim_mrt_access_missing\": 0,\n",
    "            \"sim_bus_access_missing\": 0,\n",
    "            \"sim_amenities_missing\": 0,\n",
    "            \"sim_school_missing\": 0,\n",
    "            \"sim_flat_type_missing\": 0,\n",
    "            \"sim_floor_missing\": 0,\n",
    "            \"sim_newhome_missing\": 0,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 3) Ensure feature alignment to model columns\n",
    "# --------------------------------------------------------\n",
    "def ensure_feature_alignment(df_feats: pd.DataFrame, feature_cols: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Guarantee df contains every model feature; fill sims with neutrals and flags with 0.\n",
    "    \"\"\"\n",
    "    neutr = _neutral_defaults()\n",
    "    for c in feature_cols:\n",
    "        if c not in df_feats.columns:\n",
    "            if c.endswith(\"_missing\"):\n",
    "                df_feats[c] = 0\n",
    "            elif c == \"sim_budget\":\n",
    "                df_feats[c] = neutr[\"sim_budget\"]\n",
    "            elif c == \"sim_location\":\n",
    "                df_feats[c] = neutr[\"sim_location\"]\n",
    "            else:\n",
    "                df_feats[c] = neutr[\"default\"]\n",
    "    return df_feats[feature_cols]\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 4) Optional: location-sensitive re-ranking (inference-time)\n",
    "# --------------------------------------------------------\n",
    "def rerank_with_location_sensitivity(df_scored: pd.DataFrame,\n",
    "                                     user_distance_sensitivity: float,\n",
    "                                     loc_col: str = \"sim_location\",\n",
    "                                     pred_col: str = \"score\",\n",
    "                                     out_col: str = \"score_final\",\n",
    "                                     hard_pref_place: str | None = None,\n",
    "                                     boost_threshold: float = 0.75,\n",
    "                                     boost_value: float = 0.05):\n",
    "    \"\"\"\n",
    "    Blend model score with location similarity:\n",
    "        score_final = (1 - alpha) * score + alpha * sim_location\n",
    "    where alpha grows with user sensitivity. Optionally boost near-preferred places.\n",
    "    \"\"\"\n",
    "    alpha = 0.3 + 0.5 * float(np.clip(user_distance_sensitivity or 0.0, 0.0, 1.0))\n",
    "    df = df_scored.copy()\n",
    "    df[out_col] = (1.0 - alpha) * df[pred_col] + alpha * df[loc_col]\n",
    "\n",
    "    if hard_pref_place is not None:\n",
    "        mask = df[loc_col] >= float(boost_threshold)\n",
    "        df.loc[mask, out_col] += float(boost_value)\n",
    "    return df.sort_values(out_col, ascending=False), alpha\n",
    "\n",
    "# ---------- Utility helpers ----------\n",
    "def _pick_metric(row: pd.Series, candidates: list[str]) -> float:\n",
    "    \"\"\"Try several possible column names; return the first valid float value.\"\"\"\n",
    "    for c in candidates:\n",
    "        if c in row and pd.notna(row[c]):\n",
    "            try:\n",
    "                return float(row[c])\n",
    "            except Exception:\n",
    "                pass\n",
    "    return np.nan\n",
    "\n",
    "def _should_block_top1(row: pd.Series,\n",
    "                       sim_threshold: float = 0.30,\n",
    "                       model_threshold: float = 1.0,\n",
    "                       na_counts_as_fail: bool = True) -> tuple[bool, dict]:\n",
    "    \"\"\"Return (should_block, value_dict).\"\"\"\n",
    "    budget = _pick_metric(row, [\"sim_budget\", \"budget\", \"budget_sim\"])\n",
    "    loc    = _pick_metric(row, [\"sim_location\", \"location\", \"loc\"])\n",
    "    flat_type   = _pick_metric(row, [\"sim_flat_type\", \"flat_type\", \"flat_type_sim\"])\n",
    "    model  = _pick_metric(row, [\"score\", \"Model\", \"model\", \"pred\", \"predict_score\"])\n",
    "\n",
    "    vals = {\"budget\": budget, \"loc\": loc, \"flat_type\": flat_type, \"model\": model}\n",
    "\n",
    "    if na_counts_as_fail and (np.isnan(model) or any(np.isnan(v) for v in [budget, loc, flat_type])):\n",
    "        return True, vals\n",
    "\n",
    "    bad_sim   = any(v < sim_threshold for v in [budget, loc, flat_type] if not np.isnan(v))\n",
    "    bad_model = (not np.isnan(model)) and (model < model_threshold)\n",
    "    return (bad_sim or bad_model), vals\n",
    "\n",
    "# ---------- Helper functions ----------\n",
    "def _pick_metric(row: pd.Series, candidates: list[str]) -> float:\n",
    "    \"\"\"Try multiple candidate column names and return the first valid float value.\"\"\"\n",
    "    for c in candidates:\n",
    "        if c in row and pd.notna(row[c]):\n",
    "            try:\n",
    "                return float(row[c])\n",
    "            except Exception:\n",
    "                pass\n",
    "    return np.nan\n",
    "\n",
    "def _should_block_top1(row: pd.Series,\n",
    "                       sim_threshold: float = 0.30,\n",
    "                       model_threshold: float = 1.0,\n",
    "                       na_counts_as_fail: bool = True) -> tuple[bool, dict]:\n",
    "    \"\"\"Check whether Top-1 should be blocked based on similarity and model thresholds.\"\"\"\n",
    "    budget = _pick_metric(row, [\"sim_budget\", \"budget\", \"budget_sim\"])\n",
    "    loc    = _pick_metric(row, [\"sim_location\", \"location\", \"loc\"])\n",
    "    flat_type   = _pick_metric(row, [\"sim_flat_type\", \"flat_type\", \"flat_type_sim\"])\n",
    "    model  = _pick_metric(row, [\"score\", \"Model\", \"model\", \"pred\", \"predict_score\"])\n",
    "    vals = {\"budget\": budget, \"loc\": loc, \"flat_type\": flat_type, \"model\": model}\n",
    "\n",
    "    # If NaNs exist, optionally count as failure\n",
    "    if na_counts_as_fail and (np.isnan(model) or any(np.isnan(v) for v in [budget, loc, flat_type])):\n",
    "        return True, vals\n",
    "\n",
    "    bad_sim   = any(v < sim_threshold for v in [budget, loc, flat_type] if not np.isnan(v))\n",
    "    bad_model = (not np.isnan(model)) and (model < model_threshold)\n",
    "    return (bad_sim or bad_model), vals\n",
    "\n",
    "# ---------- Main function ----------\n",
    "def recommend_for_user(model,\n",
    "                       feature_cols: list[str],\n",
    "                       user_input: dict,\n",
    "                       items_df: pd.DataFrame,\n",
    "                       sim_df_pa: pd.DataFrame,\n",
    "                       item_place_col: str = \"Plan\",\n",
    "                       topn: int = 10,\n",
    "                       k_candidates: int = 300,\n",
    "                       seed: int = 2025,\n",
    "                       use_location_rerank: bool = True,\n",
    "                       sim_threshold=0.4,\n",
    "                       model_threshold=1.0,\n",
    "                       warn_threshold: float = 0.30) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Full inference pipeline:\n",
    "      1. Retrieve candidate properties\n",
    "      2. Compute user-item features\n",
    "      3. Predict ranking scores\n",
    "      4. (Optional) location-sensitive re-ranking\n",
    "      5. Produce a structured JSON-like payload for LLMs (and print summary)\n",
    "    \"\"\"\n",
    "    # 1) Candidate retrieval\n",
    "    budget = float(user_input[\"Budget_SGD\"])\n",
    "    cand = build_inference_candidates(items_df, budget, k_candidates=k_candidates, seed=seed)\n",
    "\n",
    "    # 2) Feature computation\n",
    "    feats_df = compute_features_for_user_items(user_input, cand, sim_df_pa, item_place_col=item_place_col)\n",
    "\n",
    "    # 3) Model prediction\n",
    "    X = ensure_feature_alignment(feats_df.copy(), feature_cols)\n",
    "    feats_df[\"score\"] = model.predict(X)\n",
    "\n",
    "    # 4) Optional location re-ranking\n",
    "    if use_location_rerank:\n",
    "        user_p = float(user_input.get(\"Priority_Distance_Proximity\", 0.0))\n",
    "        pref_place = user_input.get(\"Preferred_Place\", None)\n",
    "        feats_df, alpha_used = rerank_with_location_sensitivity(\n",
    "            feats_df, user_distance_sensitivity=user_p,\n",
    "            loc_col=\"sim_location\", pred_col=\"score\", out_col=\"score_final\",\n",
    "            hard_pref_place=pref_place, boost_threshold=0.75, boost_value=0.05\n",
    "        )\n",
    "        rank_col = \"score_final\"\n",
    "    else:\n",
    "        alpha_used = None\n",
    "        rank_col = \"score\"\n",
    "\n",
    "    recs = feats_df.sort_values(rank_col, ascending=False).head(topn).copy()\n",
    "\n",
    "    # ---------- Construct base structured payload ----------\n",
    "    user_summary = {\n",
    "        k: user_input.get(k, None) for k in [\n",
    "            \"Budget_SGD\",\"Preferred_Flat_Num\",\"Preferred_Place\",\"Floor_Preference\",\"NewHome_Preference\",\n",
    "            \"Priority_MRT_Access\",\"Priority_Bus_Access\",\"Priority_Amenities\",\n",
    "            \"Priority_School_Proximity\",\"Priority_Park_Access\",\"Priority_Distance_Proximity\"\n",
    "        ]\n",
    "    }\n",
    "    result_payload = {\n",
    "        \"status\": None,\n",
    "        \"meta\": {\n",
    "            \"topn\": int(topn),\n",
    "            \"use_location_rerank\": bool(use_location_rerank),\n",
    "            \"location_alpha\": float(alpha_used) if alpha_used is not None else None,\n",
    "            \"thresholds\": {\n",
    "                \"block_sim_threshold\": float(sim_threshold),\n",
    "                \"block_model_threshold\": float(model_threshold),\n",
    "                \"warn_threshold\": float(warn_threshold),\n",
    "            },\n",
    "            \"user\": user_summary,\n",
    "        },\n",
    "        \"fail_reasons\": None,   # Explanation if blocked or no result\n",
    "        \"items\": []        # Structured property results\n",
    "    }\n",
    "\n",
    "    # ---------- Step 1: No candidates ----------\n",
    "    if recs.empty:\n",
    "        result_payload[\"status\"] = \"no_result\"\n",
    "        result_payload[\"fail_reasons\"] = {\n",
    "            \"type\": \"no_candidates_after_rerank\",\n",
    "            \"message\": \"No suitable properties found under current preferences. Try increasing budget or relaxing filters.\"\n",
    "        }\n",
    "        print(json.dumps(result_payload, ensure_ascii=False, indent=2))\n",
    "        return recs\n",
    "\n",
    "    # ---------- Step 2: Top-1 fails quality threshold ----------\n",
    "    need_block, vals = _should_block_top1(recs.iloc[0],\n",
    "                                          sim_threshold=sim_threshold,\n",
    "                                          model_threshold=model_threshold)\n",
    "    if need_block:\n",
    "        result_payload[\"status\"] = \"blocked_top1\"\n",
    "        result_payload[\"reasons\"] = {\n",
    "            \"type\": \"top1_fails_quality_threshold\",\n",
    "            \"triggered_values\": {k: (None if np.isnan(v) else float(v)) for k, v in vals.items()},\n",
    "            \"required\": {\"sim_min\": float(sim_threshold), \"model_min\": float(model_threshold)},\n",
    "            \"message\": \"Top-1 fails quality threshold; consider increasing budget, expanding preferred location, or loosening size/type preference.\"\n",
    "        }\n",
    "        print(json.dumps(result_payload, ensure_ascii=False, indent=2))\n",
    "        return recs.head(0)\n",
    "\n",
    "    # ---------- Step 3: Build structured items ----------\n",
    "    def _safe_get(obj, name, default=None):\n",
    "        try:\n",
    "            v = getattr(obj, name)\n",
    "            return v if v is not None else default\n",
    "        except Exception:\n",
    "            return default\n",
    "\n",
    "    sim_fields = [\n",
    "        \"sim_budget\",\"sim_location\",\"sim_flat_type\",\n",
    "        \"sim_mrt_access\",\"sim_bus_access\",\"sim_amenities\",\"sim_school\",\"sim_floor\",\"sim_newhome\"\n",
    "    ]\n",
    "\n",
    "    # Small helper to pack nearby-facilities info\n",
    "    nearby_pack = lambda r: {\n",
    "        \"mrt_200\": int(_safe_get(r, \"mrt_200\", 0) or 0),\n",
    "        \"mrt_500\": int(_safe_get(r, \"mrt_500\", 0) or 0),\n",
    "        \"bus_200\": int(_safe_get(r, \"bus_200\", 0) or 0),\n",
    "        \"bus_500\": int(_safe_get(r, \"bus_500\", 0) or 0),\n",
    "        \"hawker_500m\": int(_safe_get(r, \"HWKR_500M\", 0) or 0),\n",
    "        \"mall_500m\": int(_safe_get(r, \"MALL_500M\", 0) or 0),\n",
    "        \"school_1km\": int(_safe_get(r, \"GP_SCH_1K\", 0) or 0),\n",
    "        \"school_2km\": int(_safe_get(r, \"GP_SCH_2K\", 0) or 0),\n",
    "        \"park_500m_in\": int(_safe_get(r, \"PK_500M_IN\", 0) or 0),\n",
    "    }\n",
    "\n",
    "    items_struct = []\n",
    "    for i, r in enumerate(recs.itertuples(index=False), 1):\n",
    "        addr = \" \".join(str(x) for x in [_safe_get(r, \"block\", \"\"), _safe_get(r, \"street\", \"\")] if str(x))\n",
    "        loc  = _safe_get(r, \"pa\", \"\") or _safe_get(r, \"town\", \"\")\n",
    "\n",
    "        # Collect similarity scores\n",
    "        sims = {}\n",
    "        for s in sim_fields:\n",
    "            if s in recs.columns:\n",
    "                val = getattr(r, s, np.nan)\n",
    "                sims[s.replace(\"sim_\", \"\")] = None if pd.isna(val) else float(val)\n",
    "\n",
    "        base_score  = _safe_get(r, \"score\", np.nan)\n",
    "        final_score = _safe_get(r, rank_col, np.nan)\n",
    "\n",
    "        # Identify features below warn threshold\n",
    "        warn_keys = [\"mrt_access\", \"bus_access\", \"amenities\", \"school\", \"floor\"]\n",
    "        low_flags = [k for k in warn_keys if (k in sims and sims[k] is not None and sims[k] < float(warn_threshold))]\n",
    "\n",
    "        item_entry = {\n",
    "            \"rank\": i,\n",
    "            \"attributes\": {\n",
    "                \"address\": addr,\n",
    "                \"location\": loc,\n",
    "                \"flat_type\": _safe_get(r, \"flat_type\", \"\"),\n",
    "                \"storey_range\": _safe_get(r, \"storey_range\", \"\"),\n",
    "                #\"floor_area_sqm\": _safe_get(r, \"floor_area_sqm\", None),\n",
    "                #\"remaining_lease\": _safe_get(r, \"remaining_lease\", None),\n",
    "                \"resale_price\": None if pd.isna(_safe_get(r, \"resale_price\", np.nan)) else float(_safe_get(r, \"resale_price\", np.nan)),\n",
    "                \"nearby\": nearby_pack(r),\n",
    "            },\n",
    "            \"scores\": {\n",
    "                \"model\": None if pd.isna(base_score) else float(base_score),\n",
    "                \"final\": None if pd.isna(final_score) else float(final_score),\n",
    "                \"loc\": None if pd.isna(_safe_get(r, \"sim_location\", np.nan)) else float(_safe_get(r, \"sim_location\", np.nan)),\n",
    "                \"sims\": sims,\n",
    "                \"low_flags\": low_flags,  # which features fall below warn_threshold\n",
    "            }\n",
    "        }\n",
    "        items_struct.append(item_entry)\n",
    "\n",
    "    result_payload[\"status\"] = \"ok\"\n",
    "    result_payload[\"items\"] = items_struct\n",
    "\n",
    "    #---------- Print structured payload and human-readable preview ----------\n",
    "    print(json.dumps(result_payload, ensure_ascii=False, indent=2))\n",
    "\n",
    "    print(\"\\n=== Human-readable preview ===\")\n",
    "    print(f\"User: budget={user_summary['Budget_SGD']}, place={user_summary['Preferred_Place']}, \"\n",
    "          f\"flat_type={user_summary['Preferred_Flat_Num']}, floor_pref={user_summary['Floor_Preference']}, \"\n",
    "          f\"newhome_pref={user_summary['NewHome_Preference']}\")\n",
    "    if use_location_rerank:\n",
    "        print(f\"location alpha: {alpha_used:.2f}\")\n",
    "    print(f\"TOP-{topn} recommendations\")\n",
    "\n",
    "    for item in items_struct:\n",
    "        a, s = item[\"attributes\"], item[\"scores\"]\n",
    "        print(f\"\\n#{item['rank']} | {a['address']} [{a['location']}]\")\n",
    "        print(f\"  Flat Type: {a['flat_type']}\")\n",
    "        print(f\"  Floor Layer: {a['storey_range']}\")\n",
    "        if a[\"flat_type\"]:\n",
    "            print(f\"   Floor type: {a['flat_type']} num\")\n",
    "        print(f\"   Price: ${0 if a['resale_price'] is None else a['resale_price']:,.0f} | \"\n",
    "              f\"Model: {s['model']:.4f} | Loc: {0 if s['loc'] is None else s['loc']:.2f} | Final: {s['final']:.4f}\")\n",
    "\n",
    "        eval_keys = [\"mrt_access\",\"bus_access\",\"amenities\",\"school\",\"floor\"]\n",
    "        eval_pairs = []\n",
    "        for k in eval_keys:\n",
    "            val = s[\"sims\"].get(k)\n",
    "            if val is None:\n",
    "                eval_pairs.append(f\"{k}: NA\")\n",
    "            else:\n",
    "                eval_pairs.append(f\"{k}: {val:.2f}\")\n",
    "\n",
    "        print(\"   match eval → \" + \" | \".join(eval_pairs))\n",
    "        if s[\"low_flags\"]:\n",
    "            print(f\"   ⚠ unmet features (sim<{warn_threshold:.2f}): {', '.join(s['low_flags'])}\")\n",
    "\n",
    "    lines = []\n",
    "    # lines.append(\"\\n=== Human-readable preview ===\")\n",
    "    lines.append(\n",
    "        f\"User: budget={user_summary.get('Budget_SGD')}, \"\n",
    "        f\"place={user_summary.get('Preferred_Place')}, \"\n",
    "        f\"flat_type={user_summary.get('Preferred_Flat_Num')}, \"\n",
    "        f\"floor_pref={user_summary.get('Floor_Preference')}, \"\n",
    "        f\"newhome_pref={user_summary.get('NewHome_Preference')}\"\n",
    "    )\n",
    "    if use_location_rerank:\n",
    "        lines.append(f\"Location alpha: {alpha_used:.2f}\")\n",
    "    lines.append(f\"TOP-{topn} recommendations\")\n",
    "\n",
    "    for item in items_struct:\n",
    "        a, s = item[\"attributes\"], item[\"scores\"]\n",
    "        lines.append(f\"\\n#{item['rank']} | {a['address']} [{a['location']}]\")\n",
    "        lines.append(f\"   Type/Floor: {a['flat_type']} / {a['storey_range']}\")\n",
    "\n",
    "        resale_price = a.get(\"resale_price\")\n",
    "        resale_price_str = f\"${resale_price:,.0f}\" if resale_price else \"$0\"\n",
    "\n",
    "        lines.append(\n",
    "            f\"   Price: {resale_price_str} | \"\n",
    "            f\"Model: {s.get('model', 0):.4f} | \"\n",
    "            f\"Loc: {0 if s.get('loc') is None else s['loc']:.2f} | \"\n",
    "            f\"Final: {s.get('final', 0):.4f}\"\n",
    "        )\n",
    "\n",
    "        # Similarity evaluations\n",
    "        eval_keys = [\"mrt_access\", \"bus_access\", \"amenities\", \"school\", \"floor\"]\n",
    "        eval_pairs = []\n",
    "        for k in eval_keys:\n",
    "            val = s[\"sims\"].get(k)\n",
    "            if val is None:\n",
    "                eval_pairs.append(f\"{k}: NA\")\n",
    "            else:\n",
    "                eval_pairs.append(f\"{k}: {val:.2f}\")\n",
    "        lines.append(\"   match eval → \" + \" | \".join(eval_pairs))\n",
    "\n",
    "        if s.get(\"low_flags\"):\n",
    "            lines.append(\n",
    "                f\"   ⚠ unmet features (sim<{warn_threshold:.2f}): \"\n",
    "                + \", \".join(s[\"low_flags\"])\n",
    "            )\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def main_infer(\n",
    "    # Fallback paths if artifacts is None:\n",
    "    model_path: str | None = None,              # e.g. \"ranker_lgbm.joblib\"\n",
    "    feature_cols: str | None = None,\n",
    "    item_place_col: str = \"PLAN\",\n",
    "    topn: int = 5,\n",
    "    k_candidates: int = 300,\n",
    "    seed: int = 2025,\n",
    "    use_location_rerank: bool = True,\n",
    "    items_path: str = None,\n",
    "    pa_sim_path: str = None,\n",
    "    user_input: dict | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run a full inference pass with a partially specified user profile.\n",
    "    - If `artifacts` is provided (from training), it uses it directly.\n",
    "    - Otherwise it loads model and feature_cols from disk.\n",
    "    \"\"\"\n",
    "    # 1) Load model + feature_cols\n",
    "    model = joblib_load(deploy_path)\n",
    "    \n",
    "    \n",
    "    items_df = pd.read_csv(items_path)\n",
    "    sim_df_pa = load_pa_similarity_matrix(pa_sim_path)\n",
    "            \n",
    "    # print(model)    \n",
    "\n",
    "    # 2) Load item matrix & PA similarity\n",
    "    items_df = pd.read_csv(items_path)\n",
    "    sim_df_pa = load_pa_similarity_matrix(pa_sim_path)\n",
    "\n",
    "    # 3) Mock a partially specified user (some fields intentionally omitted)\n",
    "    #    - Missing fields will be handled by neutral defaults inside feature builders.\n",
    "    if user_input is None:\n",
    "        user_input = {\n",
    "            \"Budget_SGD\": 900000,                 # known & reliable\n",
    "            \"Preferred_Flat_Num\": 5,              # wants 90 sqr\n",
    "            \"Preferred_Place\": \"QUEENSTOWN\",#\"CLEMENTI\",#\"DOWNTOWN CORE\", #\"TOA PAYOH\",#\"DOWNTOWN CORE\",      # explicit place\n",
    "            \"Priority_Distance_Proximity\": 1,  # very distance-sensitive\n",
    "            # The following are partially specified / masked on purpose:\n",
    "            \"Floor_Preference\": 3,                # provided\n",
    "            \"NewHome_Preference\": 0.5,            # neutral on new vs resale\n",
    "            # priorities: leave some missing to test neutral handling\n",
    "            \"Priority_MRT_Access\": 5,\n",
    "            \"Priority_Bus_Access\": 5,\n",
    "            \"Priority_Amenities\": 5,\n",
    "            \"Priority_School_Proximity\": 5,\n",
    "            \"Priority_Park_Access\": 5\n",
    "        }\n",
    "\n",
    "    # 4) Run recommendation (this calls: retrieval → features → predict → rerank → print)\n",
    "    result = recommend_for_user(\n",
    "        model=model,\n",
    "        feature_cols=feature_cols,\n",
    "        user_input=user_input,\n",
    "        items_df=items_df,\n",
    "        sim_df_pa=sim_df_pa,\n",
    "        item_place_col=item_place_col,\n",
    "        topn=topn,\n",
    "        k_candidates=k_candidates,\n",
    "        seed=seed,\n",
    "        use_location_rerank=True,\n",
    "    )\n",
    "    return result\n",
    "\n",
    "    # 5) (Optional) Feature importance inspection\n",
    "    imp_gain  = model.booster_.feature_importance(importance_type=\"gain\")\n",
    "    imp_split = model.booster_.feature_importance(importance_type=\"split\")\n",
    "    names     = model.booster_.feature_name()\n",
    "\n",
    "    importance_df = pd.DataFrame({\n",
    "        \"feature\": names,\n",
    "        \"gain\": imp_gain,\n",
    "        \"split\": imp_split\n",
    "        }).sort_values(\"gain\", ascending=False)\n",
    "\n",
    "    return {\"user_input\": user_input, \"recs\": recs, \"feature_cols\": feature_cols, \"model\": model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdd819f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b1f75ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status\": \"ok\",\n",
      "  \"meta\": {\n",
      "    \"topn\": 5,\n",
      "    \"use_location_rerank\": true,\n",
      "    \"location_alpha\": 0.8,\n",
      "    \"thresholds\": {\n",
      "      \"block_sim_threshold\": 0.4,\n",
      "      \"block_model_threshold\": 1.0,\n",
      "      \"warn_threshold\": 0.3\n",
      "    },\n",
      "    \"user\": {\n",
      "      \"Budget_SGD\": 900000,\n",
      "      \"Preferred_Flat_Num\": 5,\n",
      "      \"Preferred_Place\": \"QUEENSTOWN\",\n",
      "      \"Floor_Preference\": 3,\n",
      "      \"NewHome_Preference\": 0.5,\n",
      "      \"Priority_MRT_Access\": 5,\n",
      "      \"Priority_Bus_Access\": 5,\n",
      "      \"Priority_Amenities\": 5,\n",
      "      \"Priority_School_Proximity\": 5,\n",
      "      \"Priority_Park_Access\": 5,\n",
      "      \"Priority_Distance_Proximity\": 1\n",
      "    }\n",
      "  },\n",
      "  \"fail_reasons\": null,\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"rank\": 1,\n",
      "      \"attributes\": {\n",
      "        \"address\": \"14 GHIM MOH RD\",\n",
      "        \"location\": \"QUEENSTOWN\",\n",
      "        \"flat_type\": \"5 ROOM\",\n",
      "        \"storey_range\": \"19 TO 21\",\n",
      "        \"resale_price\": 900000.0,\n",
      "        \"nearby\": {\n",
      "          \"mrt_200\": 0,\n",
      "          \"mrt_500\": 2,\n",
      "          \"bus_200\": 4,\n",
      "          \"bus_500\": 17,\n",
      "          \"hawker_500m\": 2,\n",
      "          \"mall_500m\": 2,\n",
      "          \"school_1km\": 1,\n",
      "          \"school_2km\": 2,\n",
      "          \"park_500m_in\": 0\n",
      "        }\n",
      "      },\n",
      "      \"scores\": {\n",
      "        \"model\": 7.275796097538823,\n",
      "        \"final\": 2.305159219507764,\n",
      "        \"loc\": 1.0,\n",
      "        \"sims\": {\n",
      "          \"budget\": 0.9965337989703691,\n",
      "          \"location\": 1.0,\n",
      "          \"flat_type\": 1.0,\n",
      "          \"mrt_access\": 0.33262991323466645,\n",
      "          \"bus_access\": 0.9015858481203697,\n",
      "          \"amenities\": 0.6805868350683798,\n",
      "          \"school\": 0.5903780178150851,\n",
      "          \"floor\": 0.9801986733067553,\n",
      "          \"newhome\": 1.0\n",
      "        },\n",
      "        \"low_flags\": []\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 2,\n",
      "      \"attributes\": {\n",
      "        \"address\": \"8 GHIM MOH RD\",\n",
      "        \"location\": \"QUEENSTOWN\",\n",
      "        \"flat_type\": \"5 ROOM\",\n",
      "        \"storey_range\": \"19 TO 21\",\n",
      "        \"resale_price\": 875000.0,\n",
      "        \"nearby\": {\n",
      "          \"mrt_200\": 0,\n",
      "          \"mrt_500\": 1,\n",
      "          \"bus_200\": 4,\n",
      "          \"bus_500\": 11,\n",
      "          \"hawker_500m\": 1,\n",
      "          \"mall_500m\": 1,\n",
      "          \"school_1km\": 1,\n",
      "          \"school_2km\": 2,\n",
      "          \"park_500m_in\": 0\n",
      "        }\n",
      "      },\n",
      "      \"scores\": {\n",
      "        \"model\": 6.575529998590698,\n",
      "        \"final\": 2.165105999718139,\n",
      "        \"loc\": 1.0,\n",
      "        \"sims\": {\n",
      "          \"budget\": 0.9756109800648459,\n",
      "          \"location\": 1.0,\n",
      "          \"flat_type\": 1.0,\n",
      "          \"mrt_access\": 0.2729949732915427,\n",
      "          \"bus_access\": 0.8984228381063896,\n",
      "          \"amenities\": 0.4696082049343837,\n",
      "          \"school\": 0.5903780178150851,\n",
      "          \"floor\": 0.9801986733067553,\n",
      "          \"newhome\": 1.0\n",
      "        },\n",
      "        \"low_flags\": [\n",
      "          \"mrt_access\"\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 3,\n",
      "      \"attributes\": {\n",
      "        \"address\": \"5 FARRER RD\",\n",
      "        \"location\": \"TANGLIN\",\n",
      "        \"flat_type\": \"5 ROOM\",\n",
      "        \"storey_range\": \"13 TO 15\",\n",
      "        \"resale_price\": 875000.0,\n",
      "        \"nearby\": {\n",
      "          \"mrt_200\": 1,\n",
      "          \"mrt_500\": 1,\n",
      "          \"bus_200\": 3,\n",
      "          \"bus_500\": 6,\n",
      "          \"hawker_500m\": 1,\n",
      "          \"mall_500m\": 0,\n",
      "          \"school_1km\": 1,\n",
      "          \"school_2km\": 1,\n",
      "          \"park_500m_in\": 1\n",
      "        }\n",
      "      },\n",
      "      \"scores\": {\n",
      "        \"model\": 6.916515081039933,\n",
      "        \"final\": 2.0594354372131116,\n",
      "        \"loc\": 0.7826655262564068,\n",
      "        \"sims\": {\n",
      "          \"budget\": 0.9756109800648459,\n",
      "          \"location\": 0.7826655262564068,\n",
      "          \"flat_type\": 1.0,\n",
      "          \"mrt_access\": 0.7629716461241288,\n",
      "          \"bus_access\": 0.8478897397039994,\n",
      "          \"amenities\": 0.1819756229443255,\n",
      "          \"school\": 0.5227601725617476,\n",
      "          \"floor\": 0.6065306597126334,\n",
      "          \"newhome\": 1.0\n",
      "        },\n",
      "        \"low_flags\": [\n",
      "          \"amenities\"\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 4,\n",
      "      \"attributes\": {\n",
      "        \"address\": \"23 GHIM MOH LINK\",\n",
      "        \"location\": \"QUEENSTOWN\",\n",
      "        \"flat_type\": \"4 ROOM\",\n",
      "        \"storey_range\": \"19 TO 21\",\n",
      "        \"resale_price\": 890000.0,\n",
      "        \"nearby\": {\n",
      "          \"mrt_200\": 0,\n",
      "          \"mrt_500\": 1,\n",
      "          \"bus_200\": 1,\n",
      "          \"bus_500\": 12,\n",
      "          \"hawker_500m\": 1,\n",
      "          \"mall_500m\": 2,\n",
      "          \"school_1km\": 2,\n",
      "          \"school_2km\": 2,\n",
      "          \"park_500m_in\": 0\n",
      "        }\n",
      "      },\n",
      "      \"scores\": {\n",
      "        \"model\": 5.628299990444377,\n",
      "        \"final\": 1.9756599980888754,\n",
      "        \"loc\": 1.0,\n",
      "        \"sims\": {\n",
      "          \"budget\": 0.9999035540339273,\n",
      "          \"location\": 1.0,\n",
      "          \"flat_type\": 0.4578333617716143,\n",
      "          \"mrt_access\": 0.2729949732915427,\n",
      "          \"bus_access\": 0.6680484920030186,\n",
      "          \"amenities\": 0.6274643128502967,\n",
      "          \"school\": 0.7270981216758587,\n",
      "          \"floor\": 0.9801986733067553,\n",
      "          \"newhome\": 1.0\n",
      "        },\n",
      "        \"low_flags\": [\n",
      "          \"mrt_access\"\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 5,\n",
      "      \"attributes\": {\n",
      "        \"address\": \"17 DOVER CRES\",\n",
      "        \"location\": \"QUEENSTOWN\",\n",
      "        \"flat_type\": \"5 ROOM\",\n",
      "        \"storey_range\": \"28 TO 30\",\n",
      "        \"resale_price\": 863888.0,\n",
      "        \"nearby\": {\n",
      "          \"mrt_200\": 0,\n",
      "          \"mrt_500\": 0,\n",
      "          \"bus_200\": 3,\n",
      "          \"bus_500\": 9,\n",
      "          \"hawker_500m\": 0,\n",
      "          \"mall_500m\": 0,\n",
      "          \"school_1km\": 1,\n",
      "          \"school_2km\": 2,\n",
      "          \"park_500m_in\": 0\n",
      "        }\n",
      "      },\n",
      "      \"scores\": {\n",
      "        \"model\": 5.169206383180188,\n",
      "        \"final\": 1.8838412766360375,\n",
      "        \"loc\": 1.0,\n",
      "        \"sims\": {\n",
      "          \"budget\": 0.9315577973910922,\n",
      "          \"location\": 1.0,\n",
      "          \"flat_type\": 1.0,\n",
      "          \"mrt_access\": 0.075,\n",
      "          \"bus_access\": 0.8658514384425999,\n",
      "          \"amenities\": 0.075,\n",
      "          \"school\": 0.5903780178150851,\n",
      "          \"floor\": 0.782704538241868,\n",
      "          \"newhome\": 1.0\n",
      "        },\n",
      "        \"low_flags\": [\n",
      "          \"mrt_access\",\n",
      "          \"amenities\"\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "=== Human-readable preview ===\n",
      "User: budget=900000, place=QUEENSTOWN, flat_type=5, floor_pref=3, newhome_pref=0.5\n",
      "location alpha: 0.80\n",
      "TOP-5 recommendations\n",
      "\n",
      "#1 | 14 GHIM MOH RD [QUEENSTOWN]\n",
      "  Flat Type: 5 ROOM\n",
      "  Floor Layer: 19 TO 21\n",
      "   Floor type: 5 ROOM num\n",
      "   Price: $900,000 | Model: 7.2758 | Loc: 1.00 | Final: 2.3052\n",
      "   match eval → mrt_access: 0.33 | bus_access: 0.90 | amenities: 0.68 | school: 0.59 | floor: 0.98\n",
      "\n",
      "#2 | 8 GHIM MOH RD [QUEENSTOWN]\n",
      "  Flat Type: 5 ROOM\n",
      "  Floor Layer: 19 TO 21\n",
      "   Floor type: 5 ROOM num\n",
      "   Price: $875,000 | Model: 6.5755 | Loc: 1.00 | Final: 2.1651\n",
      "   match eval → mrt_access: 0.27 | bus_access: 0.90 | amenities: 0.47 | school: 0.59 | floor: 0.98\n",
      "   ⚠ unmet features (sim<0.30): mrt_access\n",
      "\n",
      "#3 | 5 FARRER RD [TANGLIN]\n",
      "  Flat Type: 5 ROOM\n",
      "  Floor Layer: 13 TO 15\n",
      "   Floor type: 5 ROOM num\n",
      "   Price: $875,000 | Model: 6.9165 | Loc: 0.78 | Final: 2.0594\n",
      "   match eval → mrt_access: 0.76 | bus_access: 0.85 | amenities: 0.18 | school: 0.52 | floor: 0.61\n",
      "   ⚠ unmet features (sim<0.30): amenities\n",
      "\n",
      "#4 | 23 GHIM MOH LINK [QUEENSTOWN]\n",
      "  Flat Type: 4 ROOM\n",
      "  Floor Layer: 19 TO 21\n",
      "   Floor type: 4 ROOM num\n",
      "   Price: $890,000 | Model: 5.6283 | Loc: 1.00 | Final: 1.9757\n",
      "   match eval → mrt_access: 0.27 | bus_access: 0.67 | amenities: 0.63 | school: 0.73 | floor: 0.98\n",
      "   ⚠ unmet features (sim<0.30): mrt_access\n",
      "\n",
      "#5 | 17 DOVER CRES [QUEENSTOWN]\n",
      "  Flat Type: 5 ROOM\n",
      "  Floor Layer: 28 TO 30\n",
      "   Floor type: 5 ROOM num\n",
      "   Price: $863,888 | Model: 5.1692 | Loc: 1.00 | Final: 1.8838\n",
      "   match eval → mrt_access: 0.07 | bus_access: 0.87 | amenities: 0.07 | school: 0.59 | floor: 0.78\n",
      "   ⚠ unmet features (sim<0.30): mrt_access, amenities\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parents[0]      # 例如：notebook 的上一层当作项目根\n",
    "sys.path.insert(0, str(PROJECT_ROOT))     # 这样就能 `from utils ...` 了\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "# sys.path.insert(0, str(Path(__file__).resolve().parents[1] / \"utils\"))\n",
    "from utils.hdb_recommendation_utils import main_infer\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    deploy_path = r\"ranker_lgbm_HDB_falt_type.joblib\"\n",
    "    feature_cols = ['sim_budget', 'sim_budget_missing', 'sim_location', 'sim_location_missing', 'sim_mrt_access', 'sim_mrt_access_missing', 'sim_bus_access', 'sim_bus_access_missing', 'sim_amenities', 'sim_amenities_missing', 'sim_school', 'sim_school_missing', 'sim_flat_type', 'sim_flat_type_missing', 'sim_floor', 'sim_floor_missing', 'sim_newhome', 'sim_newhome_missing', 'sim_park_access', 'sim_park_access_missing']\n",
    "    items_path=r\"../../../data/item_matrix_merged.csv\"\n",
    "    pa_sim_path=r\"../../../data/PA_centroid_similarity_0_1.csv\"\n",
    "    \n",
    "    main_infer(\n",
    "        model_path=deploy_path,\n",
    "        feature_cols=feature_cols,\n",
    "        items_path=items_path,\n",
    "        pa_sim_path=pa_sim_path, # Call the distance matrix table\n",
    "        item_place_col=\"Plan\",\n",
    "        topn=5,\n",
    "        k_candidates=800,\n",
    "        use_location_rerank=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b940d82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f3c61e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "estate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
